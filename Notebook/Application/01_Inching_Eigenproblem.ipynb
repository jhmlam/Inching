{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Eigenproblem\n",
    "\n",
    "In this notebook we will get the Hessian and solve the first 64 modes of it using Inching-JDM. \n",
    "Note that the first-ever run of Inching on your computer may take additional time for compilation. On a laptop with an RTX3060, `1jj2`, a pretty small system with 98k atoms, takes around 4 minutes. The list `pdbavail` should contain a list of pdb you want to compute their normal mode. The string `Benchmark_folder` should contain the path to store output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:01<00:00, 58.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_neighbor within 8.0 angstrom Mean 99.97464051226368, Std 24.62011211610712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98543 [00:05<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start eigsh cupy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<?, ?it/s]\n",
      "100%|██████████| 1024/1024 [00:03<00:00, 287.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean number of Gaps > 100 is 17.998046875. Mean Gap Length Given Gap is 386.32246337493217\n",
      "Max number of Gaps > 100 is 41. Max Gap Length Given Gap is 5318\n",
      "Median number of Gaps > 100 is 19.0. Median Gap Length Given Gap is 224.0\n",
      "Total Entry Savings 684354138 which is 66.2311271111961 percent of a Rectangular Batch\n",
      "Nnz in Hessian (L+D) is 44776548.0. This will occupy 0.33030736818909645 GB for (L+D) data and at max 0.33030736818909645 GB for all indexings. Acceptable?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\MessLab\\Project-InchingLite\\Notebook\\Application\\../..\\InchingLite\\Fuel\\T1.py:180: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.frontal_gap_offset[i] = torch.tensor(frontal_gap_offset,dtype=torch.int32, device='cpu')#.clone().detach().cpu().requires_grad_(False) #hare_memory_()\n",
      "100%|██████████| 1024/1024 [00:20<00:00, 49.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44473934,)\n",
      "WARNING. Hotelling deflation not in use\n",
      "Start JDM Coarse Iter\n",
      "0, 12.079529687981827, 33.97494059313371, 1e-06, 0\n",
      "100, 0.8544897032975662, 2.4012954144571603, 1e-06, 0\n",
      "200, 0.013569297995192934, 1.0001799676113279, 1e-06, 1\n",
      "300, 1.9770407220015484e-13, 1.0056930046637298, 1e-06, 6\n",
      "300, 0.0002642042465916983, 1.0075024546461189, 1e-06, 7\n",
      "400, 5.278819739649337e-08, 1.0208027799014208, 1e-06, 14\n",
      "500, 2.2888660685547714e-06, 1.0398542605385386, 1e-06, 22\n",
      "600, 2.3168573798527376e-09, 1.055265600617888, 1e-06, 29\n",
      "700, 5.0290971209272616e-12, 1.067388727076183, 1e-06, 36\n",
      "800, 3.7464454936677796e-06, 1.084422735452767, 1e-06, 44\n",
      "900, 1.1141221281211578e-07, 1.0990411620366534, 1e-06, 51\n",
      "1000, 1.3675753682272196e-07, 1.1152570115371419, 1e-06, 58\n",
      "DONE. We went through 1079 coarse iter, 64 eigval converged\n",
      "RUNNNTIME 245.26331233978271\n",
      "0.9999999999999947 6.331547367522808e-13\n",
      "0.9999999999999988 3.099684976223204e-13\n",
      "0.9999999999999998 4.730767706650559e-13\n",
      "0.9999999999999999 3.2407877044927103e-13\n",
      "1.0000000000000004 3.476874818893632e-13\n",
      "1.0000000000000007 8.828955094218059e-13\n",
      "1.0008618196084125 2.0215634954423493e-13\n",
      "1.0013124193606737 1.8124820886409138e-13\n",
      "1.0056930046637298 1.9694547010747691e-13\n",
      "1.0075024490838405 6.955301093529634e-13\n",
      "1.0107647786911313 1.0317631710066704e-13\n",
      "1.0134473278316365 9.013389178058099e-13\n",
      "1.014129593053618 8.804224238844397e-13\n",
      "1.0188518231341652 3.6043922050177904e-13\n",
      "1.0208027799014168 9.677547085352364e-13\n",
      "1.0231512630694672 2.9984816699028395e-13\n",
      "1.0246367240918346 3.5449747296308446e-13\n",
      "1.0255001457955693 3.7253111171585895e-13\n",
      "1.0281092780122472 8.187690765542014e-13\n",
      "1.032246889768768 6.392114677361843e-13\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import platform\n",
    "\n",
    "# A list of pdb available at different sizes\n",
    "\n",
    "pdbavail = [ '../../DataRepo/PdbByAtomCount/1jj2.pdb' ] \n",
    "Benchmarking_folder = \"../../DataRepo/VisualizationExample1jj2/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "User_Platform = platform.system() # Windows Darwin Linux\n",
    "\n",
    "User_rc_Gamma = 8.0\n",
    "User_maxleafsize = 100\n",
    "User_n_mode = 64\n",
    "User_tol = 1e-15\n",
    "User_PlusI = 1.0\n",
    "PDBCIF = \"Pdb\"\n",
    "User_MaxIter = 15000\n",
    "\n",
    "# JDM Params\n",
    "User_GapEstimate = 1e-6\n",
    "User_SolverName = 'gmres'\n",
    "User_SolverMaxIter = 20\n",
    "User_EigTolerance = 1e-12\n",
    "\n",
    "\n",
    "\n",
    "PART00_Import = True\n",
    "if PART00_Import:\n",
    "   import os\n",
    "   import gc\n",
    "   import sys\n",
    "   import pickle\n",
    "\n",
    "   import numpy as np\n",
    "   import time\n",
    "   import tqdm\n",
    "\n",
    "   import torch \n",
    "\n",
    "\n",
    "   import platform\n",
    "\n",
    "\n",
    "   import time\n",
    "\n",
    "   import cupy\n",
    "   from cupy import cublas\n",
    "\n",
    "\n",
    "   from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "\n",
    "   sys.path.append('..')\n",
    "   sys.path.append('../../')\n",
    "   sys.path.append('../../InchingLite/Burn/')\n",
    "\n",
    "\n",
    "\n",
    "   import InchingLite.util\n",
    "   import InchingLite.Fuel.Coordinate.T1\n",
    "   import InchingLite.Fuel.Coordinate.T2\n",
    "   import InchingLite.Burn.Coordinate.T1\n",
    "   import InchingLite.Burn.Coordinate.T3\n",
    "\n",
    "   from InchingLite.Fuel.T1 import Xnumpy_SparseCupyMatrixUngappped\n",
    "\n",
    "   import InchingLite.Burn.Visualisation.T1\n",
    "   import InchingLite.Burn.Visualisation.T2\n",
    "\n",
    "   # ============================\n",
    "   # Some torch speed up tips\n",
    "   # =============================\n",
    "\n",
    "   # Turn on cuda optimizer\n",
    "   torch.backends.cudnn.is_available()\n",
    "   torch.backends.cudnn.enabled = True\n",
    "   torch.backends.cudnn.benchmark = True\n",
    "   # disable debugs NOTE use only after debugging\n",
    "   torch.autograd.set_detect_anomaly(False)\n",
    "   torch.autograd.profiler.profile(False)\n",
    "   torch.autograd.profiler.emit_nvtx(False)\n",
    "   # Disable gradient tracking\n",
    "   torch.no_grad()\n",
    "   torch.inference_mode()\n",
    "   torch.manual_seed(0)\n",
    "   cupy.random.seed(seed = 0)\n",
    "   os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" # NOTE In case any error showup\n",
    "   # Reset Cuda and Torch\n",
    "   device = torch.device(0)\n",
    "   torch.set_default_dtype(torch.float64)\n",
    "   torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "   try:\n",
    "      InchingLite.util.TorchEmptyCache()\n",
    "   except RuntimeError:\n",
    "      print(\"The GPU is free to use. THere is no existing occupant\")\n",
    "   try:\n",
    "      print(torch.cuda.memory_summary(device = 0, abbreviated=True))\n",
    "   except KeyError:\n",
    "      print(\"The GPU is free to use. THere is no existing occupant\")\n",
    "\n",
    "\n",
    "# =======================\n",
    "# Determine N_atoms\n",
    "# ==============================\n",
    "# NOTE 2 minutes\n",
    "PART01_ListOfPDB = False\n",
    "if PART01_ListOfPDB:\n",
    "   if os.path.exists(\"%s/%sSize.pkl\" %(Benchmarking_folder, PDBCIF)):\n",
    "      with open(\"%s/%sSize.pkl\" %( Benchmarking_folder, PDBCIF),\"rb\") as fn:\n",
    "         pdbavail, sizedict = pickle.load(fn)\n",
    "   else:\n",
    "\n",
    "      pdbavail = [InchingLite.util.WinFileDirLinux(i) for i in pdbavail]\n",
    "      size = []\n",
    "      for pdbfn in tqdm.tqdm(pdbavail):\n",
    "\n",
    "         X_df, X_top = InchingLite.util.BasicPdbCifLoading(pdbfn)\n",
    "         protein_xyz = X_df[['x','y','z']].to_numpy().astype(np.float64)\n",
    "         size.append(protein_xyz.shape[0])\n",
    "         del X_df, protein_xyz\n",
    "         gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "      pdbavail = [pdbavail[i] for i in np.argsort(size).tolist()]\n",
    "      print(\"Ranked file size in atom number\")\n",
    "      #print([os.path.getsize(i) for i in pdbavail])\n",
    "      sizedict = dict(zip([i.split(\"/\")[-1].split(\".\")[0] for i in pdbavail],sorted(size)))\n",
    "      print(dict(zip([i.split(\"/\")[-1].split(\".\")[0] for i in pdbavail],sorted(size))))\n",
    "\n",
    "      with open(\"%s/%sSize.pkl\" %(Benchmarking_folder, PDBCIF),\"wb\") as fn:\n",
    "         pickle.dump((pdbavail, dict(zip([i.split(\"/\")[-1].split(\".\")[0] for i in pdbavail],sorted(size)))),fn , protocol=4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for pdbfn in pdbavail:\n",
    "    \n",
    "\n",
    "\n",
    "    devices_ = [d for d in range(torch.cuda.device_count())]\n",
    "    device_names_  = [torch.cuda.get_device_name(d) for d in devices_]\n",
    "    User_Device =  device_names_[0]\n",
    "\n",
    "\n",
    "    pdbid = pdbfn.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "\n",
    "    st = time.time()\n",
    "\n",
    "    X_df, X_top = InchingLite.util.BasicPdbCifLoading(pdbfn)\n",
    "    protein_xyz = X_df[['x','y','z']].to_numpy().astype(np.float64)\n",
    "    # NOTE PDB format digit decimal do no destroy collinearity!\n",
    "    n_atoms = protein_xyz.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "    # ===============================================\n",
    "    # K-d Cuthill (NOTE CPU np array)\n",
    "    # ===================================\n",
    "    # NOTE Cuthill Order and Undo\n",
    "    st = time.time()\n",
    "    cuthill_order, cuthill_undoorder = InchingLite.Fuel.Coordinate.T1.X_KdCuthillMckeeOrder(protein_xyz,  \n",
    "                                rc_Gamma = User_rc_Gamma, Reverse = True,\n",
    "                                )\n",
    "    protein_xyz = protein_xyz[cuthill_order,:]\n",
    "    protein_tree = cKDTree(protein_xyz, leafsize=16, compact_nodes=True, copy_data=False, balanced_tree=True, boxsize=None)\n",
    "\n",
    "\n",
    "    from InchingLite.Burn.JacobiDavidsonHotellingDeflation.T1 import S_HeigvalJDMHD_HeigvecJDMHD\n",
    "    print('start eigsh cupy')\n",
    "\n",
    "    mempool = cupy.get_default_memory_pool()\n",
    "    pinned_mempool = cupy.get_default_pinned_memory_pool()\n",
    "\n",
    "    # ==================\n",
    "    # Cupy hessian\n",
    "    # =====================\n",
    "    PART03_MakeCupyHessian = True\n",
    "    if PART03_MakeCupyHessian:\n",
    "        # NOTE Nnz neighborhood after cuthill\n",
    "        NnzMinMaxDict, HalfNnz  = InchingLite.Fuel.Coordinate.T1.X_KdUngappedMinMaxNeighbor(protein_xyz, \n",
    "                                    rc_Gamma = User_rc_Gamma, \n",
    "                                    maxleafsize = User_maxleafsize,\n",
    "                                    CollectStat = False,\n",
    "                                    User_ReturnHalfNnz = True,\n",
    "                                    SliceForm= True)\n",
    "\n",
    "\n",
    "        # NOTE Pyotch tensor spend textra memory when dlpack has to be called and there are mmeleak\n",
    "        #X = torch.tensor(protein_xyz, device=device, requires_grad= False)\n",
    "        X = protein_xyz\n",
    "        Xnumpy_SparseCupyMatrixUngapppedC = Xnumpy_SparseCupyMatrixUngappped(X, batch_head = None, \n",
    "            maxleafsize = User_maxleafsize, rc_Gamma = User_rc_Gamma,\n",
    "            device  = torch.device(0), \n",
    "            User_PlusI = User_PlusI, \n",
    "            dtype_temp = torch.float64, \n",
    "            X_precision = torch.cuda.DoubleTensor,\n",
    "            NnzMinMaxDict = NnzMinMaxDict)\n",
    "\n",
    "        A = Xnumpy_SparseCupyMatrixUngapppedC.ReturnCupyHLowerTriangle(\n",
    "                        User_MaxHalfNnzBufferSize = HalfNnz)\n",
    "        print(A.data.shape)\n",
    "        \n",
    "        cupy.get_default_memory_pool().free_all_blocks()\n",
    "        cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    PART04_CalcualteEig = True\n",
    "    if PART04_CalcualteEig:\n",
    "        eigval, eigvec = S_HeigvalJDMHD_HeigvecJDMHD(A,\n",
    "                    k = User_n_mode,\n",
    "                    tol = User_EigTolerance,\n",
    "                    maxiter = User_MaxIter,\n",
    "                    User_CorrectionSolverMaxiter = User_SolverMaxIter,\n",
    "                    User_HalfMemMode= True,\n",
    "                    User_IntermediateConvergenceTol=1e-3, # NOTE Do not touch for this problem\n",
    "                    User_GapEstimate = User_GapEstimate, # NOTE This will be used for theta - gap_estimate\n",
    "                    User_FactoringToleranceOnCorrection = 1e-4, # NOTE Do not touch for this problem\n",
    "                    User_HD_Eigvec = None,\n",
    "                    User_HD_Eigval = None,\n",
    "                    User_HotellingShift = 40, # NOTE 40 is generally safe for first 64 modes, of course if you want to guarentee it you know a norm\n",
    "\n",
    "                    )\n",
    "        runtime = time.time() - st\n",
    "        print(\"RUNNNTIME %s\" %(runtime))\n",
    "        peak_mem = cupy.get_default_memory_pool().used_bytes() / 1024 / 1024\n",
    "\n",
    "\n",
    "        runtime = time.time() - st\n",
    "        peak_mem = cupy.get_default_memory_pool().used_bytes() / 1024 / 1024\n",
    "        with open(\"%s/Eigval_InchingJDM_%s_%s_%s.pkl\" %(\n",
    "                    Benchmarking_folder, pdbid, User_Platform, \n",
    "                    User_Device.replace(\" \",\"\")),\"wb\") as fn:\n",
    "            pickle.dump(cupy.asnumpy(eigval) - User_PlusI ,fn, protocol=4)\n",
    "        \n",
    "        with open(\"%s/Eigvec_InchingJDM_%s_%s_%s.pkl\" %(\n",
    "                    Benchmarking_folder, pdbid, User_Platform, \n",
    "                    User_Device.replace(\" \",\"\")),\"wb\") as fn:    \n",
    "            tempeigvec = cupy.asnumpy(eigvec)\n",
    "            tempeigvec = tempeigvec.T\n",
    "            tempeigvec = tempeigvec.reshape((int(User_n_mode),int(n_atoms),int(3)))\n",
    "            pickle.dump(tempeigvec[:,cuthill_undoorder,:] ,fn, protocol=4)\n",
    "\n",
    "        \n",
    "        del tempeigvec\n",
    "        gc.collect()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    PART05_Performance = True\n",
    "    if PART05_Performance:\n",
    "        #===================================\n",
    "        # Check correct\n",
    "        # =====================================\n",
    "        #print(eigval)\n",
    "        #print(eigvec.shape)\n",
    "        delta_lambda_list = []\n",
    "        for jj in range(User_n_mode):\n",
    "            B = A@eigvec[:,jj].T + A.T@eigvec[:,jj].T - cupy.multiply(A.diagonal(k=0), eigvec[:,jj])  - eigval[jj]* eigvec[:,jj].T\n",
    "            delta_lambda_list.append(cupy.asnumpy(cublas.nrm2(B)))\n",
    "            if jj < 20:\n",
    "                print(eigval[jj], cupy.asnumpy(cublas.nrm2(B)))\n",
    "        \n",
    "        eigval = cupy.asnumpy(eigval)\n",
    "        n_atoms = protein_xyz.shape[0]\n",
    "\n",
    "        GPU = \"%s %s\" %(User_Platform, User_Device.replace(\" GPU\", \"\"))\n",
    "\n",
    "        performance = [\"Inching (JDM %s)\" %(GPU), pdbfn, n_atoms, \n",
    "                        runtime, peak_mem, \n",
    "                        User_Platform, User_Device, \n",
    "                        User_maxleafsize]\n",
    "\n",
    "\n",
    "\n",
    "        longperformance = []\n",
    "        for i in range(len(delta_lambda_list)):\n",
    "            longperformance.append(performance + [i ,delta_lambda_list[i], eigval[i] - User_PlusI])\n",
    "        \n",
    "        with open(\"%s/PerformanceList_InchingJDM_%s_%s_%s.pkl\" %(Benchmarking_folder, \n",
    "            pdbid, User_Platform, User_Device.replace(\" \",\"\")),\"wb\") as fn:   \n",
    "            pickle.dump(longperformance,fn, protocol=4)\n",
    "\n",
    "\n",
    "        del X_df, protein_xyz\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "        B = None\n",
    "        A.data = None\n",
    "        A.indices = None\n",
    "        A.indptr = None\n",
    "        Q_HotellingDeflation = None\n",
    "        del Q_HotellingDeflation\n",
    "\n",
    "        del A.data, A.indices, A.indptr \n",
    "        del A, B\n",
    "        Xnumpy_SparseCupyMatrixUngapppedC.X, Xnumpy_SparseCupyMatrixUngapppedC.X_unsqueezed = None, None\n",
    "        del Xnumpy_SparseCupyMatrixUngapppedC.X, Xnumpy_SparseCupyMatrixUngapppedC.X_unsqueezed\n",
    "        Xnumpy_SparseCupyMatrixUngapppedC = None\n",
    "        del Xnumpy_SparseCupyMatrixUngapppedC\n",
    "        eigvec, eigval = None, None\n",
    "        del eigvec, eigval\n",
    "\n",
    "\n",
    "        cupy.get_default_memory_pool().free_all_blocks()\n",
    "        cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
    "        del X \n",
    "        torch.cuda.empty_cache()    \n",
    "        torch.cuda.reset_peak_memory_stats(0)\n",
    "        torch.cuda.memory_allocated(0)\n",
    "        torch.cuda.max_memory_allocated(0)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec6c2d9cbfbaa729ccdd92f31e2be6fcbb66830e090159c2cc22789694c7cf7c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('Inching2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
