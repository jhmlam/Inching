{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solving Eigenproblem\n",
    "\n",
    "In this notebook we will get the Hessian and solve the first 64 modes of it using Inching-JDMHD, by default the free modes are excluded from considerations.\n",
    "Note that the first-ever run of Inching on your computer may take additional time for compilation. On a laptop with an RTX3060, `1jj2`, a pretty small system with 98k atoms, takes around 4 minutes. The list `pdbavail` should contain a list of pdb you want to compute their normal mode. The string `Benchmark_folder` should contain the path to store output. \n",
    "\n",
    "# Remark on JDM\n",
    "Indeed, a simple rational filter `v = (A- \\theta I )^-1 (-r)` will also work. See the discussion by Voss on Caley transform c.f. the original `Solving (I - uu^T )(A  - \\theta I )(I - uu^T ) v  = -r`, though `(I - uu^T)` is 'satisfactorily' cheap. Also see the remark by Zhou in the Chebyshev Davidson paper, where they observed cases which `v = (A- \\theta I )^-1 (-r)` is superior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import platform\n",
    "\n",
    "# A list of pdb available at different sizes\n",
    "\n",
    "pdbavail = [ '../../DataRepo/PdbByAtomCount/1jj2.pdb' ] \n",
    "Benchmarking_folder = \"../../VisualizationRepo/\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No need to modify anything below, Press Run All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/homingla/anaconda3/envs/V0/envs/Inching23/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Warning: importing 'simtk.openmm' is deprecated.  Import 'openmm' instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The GPU is free to use. THere is no existing occupant\n",
      "The GPU is free to use. THere is no existing occupant\n"
     ]
    }
   ],
   "source": [
    "\n",
    "User_Platform = platform.system() # Windows Darwin Linux\n",
    "\n",
    "User_rc_Gamma = 8.0\n",
    "User_maxleafsize = 100\n",
    "User_n_mode = 64\n",
    "User_PlusI = 1.0\n",
    "PDBCIF = \"Pdb\" if (\".pdb\" in pdbavail[0]) else \"Cif\"\n",
    "User_MaxIter = 15000\n",
    "\n",
    "# JDM Params\n",
    "\n",
    "User_SolverName = 'gmres'\n",
    "User_SolverMaxIter = 20\n",
    "User_EigTolerance = 1e-12\n",
    "\n",
    "User_IntegerOfIndexing = \"INTEGER64\"\n",
    "\n",
    "PART00_Import = True\n",
    "if PART00_Import:\n",
    "   import os\n",
    "   import gc\n",
    "   import sys\n",
    "   import pickle\n",
    "\n",
    "   import numpy as np\n",
    "   import time\n",
    "   import tqdm\n",
    "\n",
    "   import torch \n",
    "\n",
    "\n",
    "   import platform\n",
    "\n",
    "\n",
    "   import time\n",
    "\n",
    "   import cupy\n",
    "   from cupy import cublas\n",
    "   import cupy as cp\n",
    "   import cupyx\n",
    "   from cupyx.scipy.sparse import linalg as cupylinalg\n",
    "   from cupyx.scipy import sparse as cupysparse\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "   sys.path.append('..')\n",
    "   sys.path.append('../../')\n",
    "   sys.path.append('../../InchingLiteInteger/Burn/')\n",
    "\n",
    "\n",
    "\n",
    "   import InchingLiteInteger.util\n",
    "\n",
    "   InchingLiteInteger.util.MkdirList([Benchmarking_folder])\n",
    "   \n",
    "   import InchingLiteInteger.Fuel.Coordinate.T1\n",
    "   import InchingLiteInteger.Fuel.Coordinate.T2\n",
    "   import InchingLiteInteger.Burn.Coordinate.T1\n",
    "   import InchingLiteInteger.Burn.Coordinate.T3\n",
    "\n",
    "   from InchingLiteInteger.Fuel.T1 import Xnumpy_SparseCupyMatrixUngappped\n",
    "\n",
    "   import InchingLiteInteger.Burn.Visualisation.T1\n",
    "   import InchingLiteInteger.Burn.Visualisation.T2\n",
    "\n",
    "\n",
    "   from InchingLiteInteger.Burn.JacobiDavidsonHotellingDeflation.T1 import S_HeigvalJDMHD_HeigvecJDMHD\n",
    "   from InchingLiteInteger.Burn.ThickRestartLanczosHotellingDeflation.T1 import S_HeigvalTRLMHD_HeigvecTRLMHD\n",
    "   from InchingLiteInteger.Burn.ChebyshevDavidsonSubspaceIteration.T1 import S_HeigvalCDSIHD_HeigvecCDSIHD\n",
    "\n",
    "\n",
    "   import InchingLiteInteger.Burn.HermitianLanczos.T2\n",
    "   import InchingLiteInteger.Burn.PolynomialFilters.T0\n",
    "   import InchingLiteInteger.Burn.PolynomialFilters.T2\n",
    "\n",
    "\n",
    "   # ============================\n",
    "   # Some torch speed up tips\n",
    "   # =============================\n",
    "\n",
    "   # Turn on cuda optimizer\n",
    "   torch.backends.cudnn.is_available()\n",
    "   torch.backends.cudnn.enabled = True\n",
    "   torch.backends.cudnn.benchmark = True\n",
    "   # disable debugs NOTE use only after debugging\n",
    "   torch.autograd.set_detect_anomaly(False)\n",
    "   torch.autograd.profiler.profile(False)\n",
    "   torch.autograd.profiler.emit_nvtx(False)\n",
    "   # Disable gradient tracking\n",
    "   torch.no_grad()\n",
    "   torch.inference_mode()\n",
    "   torch.manual_seed(0)\n",
    "   cupy.random.seed(seed = 0)\n",
    "   os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" # NOTE In case any error showup\n",
    "   # Reset Cuda and Torch\n",
    "   device = torch.device(0)\n",
    "   torch.set_default_dtype(torch.float64)\n",
    "   torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
    "   try:\n",
    "      InchingLiteInteger.util.TorchEmptyCache()\n",
    "   except RuntimeError:\n",
    "      print(\"The GPU is free to use. THere is no existing occupant\")\n",
    "   try:\n",
    "      print(torch.cuda.memory_summary(device = 0, abbreviated=True))\n",
    "   except KeyError:\n",
    "      print(\"The GPU is free to use. THere is no existing occupant\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:00<00:00, 170.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N_neighbor within 8.0 angstrom Mean 99.97464051226368, Std 24.62011211610712\n",
      "NN search in 0.5847101211547852 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/98543 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start eigsh cupy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:00<00:00, 7642290.56it/s]\n",
      "100%|██████████| 1024/1024 [00:01<00:00, 841.91it/s]\n",
      "/mnt/data0/homingla/Project-Inching/Inching-main/Notebook/Application20231128_DONE/../../InchingLiteInteger/Fuel/T1.py:218: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.frontal_gap_offset[i] = torch.tensor(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean number of Gaps > 100 is 17.998046875. Mean Gap Length Given Gap is 386.32246337493217\n",
      "Max number of Gaps > 100 is 41. Max Gap Length Given Gap is 5318\n",
      "Median number of Gaps > 100 is 19.0. Median Gap Length Given Gap is 224.0\n",
      "Total Entry Savings 684354138 which is 66.2311271111961 percent of a Rectangular Batch\n",
      "Nnz in Hessian (L+D) is 44776548.0. This will occupy 0.33030736818909645 GB for (L+D) data and at max 0.33030736818909645 GB for all indexings. Acceptable?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1024/1024 [00:04<00:00, 214.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix Index Datatype int64\n",
      "Matrix Datatype (44473934,)\n",
      "Start JDM Coarse Iter\n",
      "0, 12.079113263483398, 33.9753282673743, 1e-06, 0\n",
      "100, 0.000123689238630841, 1.0013109867764785, 1e-06, 0\n",
      "200, 2.453303266448456e-11, 1.007502449083835, 1e-06, 3\n",
      "300, 4.627123991473558e-07, 1.0246367240922498, 1e-06, 10\n",
      "400, 5.265411003733234e-13, 1.0433909465903395, 1e-06, 17\n",
      "400, 0.0037781366918755257, 1.0477358942135955, 1e-06, 18\n",
      "500, 4.961205955639797e-07, 1.058356527869882, 1e-06, 26\n",
      "600, 2.718582007423641e-13, 1.0720228377234622, 1e-06, 33\n",
      "600, 0.005887347956501346, 1.0750355372145382, 1e-06, 34\n",
      "700, 8.629725182048813e-09, 1.090970253130812, 1e-06, 42\n",
      "800, 0.000225949435666824, 1.110922179066228, 1e-06, 50\n",
      "900, 2.7447511688999206e-08, 1.1262197334896982, 1e-06, 58\n",
      "DONE. We went through 977 coarse iter, 64 eigval converged\n",
      "RUNNNTIME 69.89013338088989\n",
      "1.000861819608412 5.947441236156044e-13\n",
      "1.0013124193606726 8.959961946222426e-13\n",
      "1.0056930046637207 7.708477175239602e-13\n",
      "1.0075024490838351 8.845071693970939e-13\n",
      "1.0107647786911405 9.263348692447034e-13\n",
      "1.0134473278316352 4.874960882392969e-13\n",
      "1.0141295930536143 6.194660127644309e-13\n",
      "1.0188518231341697 3.1569409585861614e-13\n",
      "1.0208027799014165 8.266753080748426e-13\n",
      "1.0231512630694692 3.870592036202125e-13\n",
      "1.0246367240918393 4.749149568710755e-13\n",
      "1.0255001457955726 3.4363848422728765e-13\n",
      "1.0281092780122336 4.1173402051578524e-13\n",
      "1.0322468897687798 3.587024625144296e-13\n",
      "1.0332867394100032 4.3811595970392955e-13\n",
      "1.03744582246165 6.518908420079061e-13\n",
      "1.0398542605250947 5.482251604564864e-13\n",
      "1.0433909465903395 5.265103117167229e-13\n",
      "1.0477349746966418 8.959472837546847e-13\n",
      "1.0491306683137163 7.249324450862217e-13\n",
      "1.050154898897216 3.1831918947766085e-13\n",
      "1.0519956283628895 8.876821472377277e-13\n",
      "1.0528531464989646 4.008715412704197e-13\n",
      "1.055265600617876 2.5248216140034793e-13\n",
      "1.0574839281692716 4.9908833293541e-13\n",
      "1.0579668848961754 4.167809656986318e-13\n",
      "1.0583565278692748 7.596553557884565e-13\n",
      "1.0605278004634568 5.779241232169828e-13\n",
      "1.0619665288224125 2.4752857007008447e-13\n",
      "1.0640184000069883 8.064629162791252e-13\n",
      "1.0673887270761853 7.697083589359066e-13\n",
      "1.0685701617025662 6.092621061959666e-13\n",
      "1.070332751355066 7.049451756894171e-13\n",
      "1.0720228377234622 2.7183086817498604e-13\n",
      "1.0750336841486003 7.250730562164956e-13\n",
      "1.0758581311942492 6.72775535654401e-13\n",
      "1.0794139668904932 4.2356295064813837e-13\n",
      "1.0812059990350114 5.346871236524189e-13\n",
      "1.0844227354218559 5.255425014540399e-13\n",
      "1.0861547197069625 1.4480885546142979e-13\n",
      "1.088359725656386 7.629953106092487e-13\n",
      "1.0891128408871495 2.5694563500754294e-13\n",
      "1.090970253130812 2.5673703324758224e-13\n",
      "1.0918877163572722 3.4989683065796395e-13\n",
      "1.0960163155765257 2.4530106863396776e-13\n",
      "1.0990411620366278 9.184459605817398e-13\n",
      "1.1026613702563262 5.953115048920746e-13\n",
      "1.1047717340188212 5.723761433034448e-13\n",
      "1.1066646758693788 4.340977621529657e-13\n",
      "1.108780597079329 7.966373719490582e-13\n",
      "1.1109221497830624 3.6388736530027286e-13\n",
      "1.1125287700410167 6.458365907566486e-13\n",
      "1.1152570115371034 3.468008327068607e-13\n",
      "1.1161950880265417 5.669061150864039e-13\n",
      "1.11681617592341 1.777497468082664e-13\n",
      "1.1200253942539693 4.500271013971278e-13\n",
      "1.120579358959058 3.897782404336707e-13\n",
      "1.1241224079040626 8.498948123704347e-13\n",
      "1.1262197334896966 2.8978857938626137e-13\n",
      "1.1269619681335354 2.6176474000043547e-13\n",
      "1.129778378966458 4.0485284633583103e-13\n",
      "1.1306079991253462 8.678656420038227e-13\n",
      "1.1363335151613239 9.389405173403107e-13\n",
      "1.1375819924610446 2.9148506909263325e-13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "for pdbfn in pdbavail:\n",
    "    \n",
    "\n",
    "\n",
    "    devices_ = [d for d in range(torch.cuda.device_count())]\n",
    "    device_names_  = [torch.cuda.get_device_name(d) for d in devices_]\n",
    "    User_Device =  device_names_[0]\n",
    "\n",
    "\n",
    "    pdbid = pdbfn.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "\n",
    "    st = time.time()\n",
    "\n",
    "    X_df, X_top = InchingLiteInteger.util.BasicPdbCifLoading(pdbfn)\n",
    "    protein_xyz = X_df[['x','y','z']].to_numpy().astype(np.float64)\n",
    "    # NOTE PDB format digit decimal do no destroy collinearity!\n",
    "    n_atoms = protein_xyz.shape[0]\n",
    "\n",
    "\n",
    "\n",
    "    # ===============================================\n",
    "    # K-d Cuthill (NOTE CPU np array)\n",
    "    # ===================================\n",
    "    # NOTE Cuthill Order and Undo\n",
    "    st = time.time()\n",
    "    cuthill_order, cuthill_undoorder = InchingLiteInteger.Fuel.Coordinate.T1.X_KdCuthillMckeeOrder(protein_xyz,  \n",
    "                                rc_Gamma = User_rc_Gamma, Reverse = True,\n",
    "                                )\n",
    "    protein_xyz = protein_xyz[cuthill_order,:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('start eigsh cupy')\n",
    "\n",
    "    mempool = cupy.get_default_memory_pool()\n",
    "    pinned_mempool = cupy.get_default_pinned_memory_pool()\n",
    "\n",
    "    # ==================\n",
    "    # Cupy hessian\n",
    "    # =====================\n",
    "    PART03a_MakeCupyHessian = True\n",
    "    if PART03a_MakeCupyHessian:\n",
    "        # NOTE Nnz neighborhood after cuthill\n",
    "        NnzMinMaxDict, HalfNnz  = InchingLiteInteger.Fuel.Coordinate.T1.X_KdUngappedMinMaxNeighbor(protein_xyz, \n",
    "                                    rc_Gamma = User_rc_Gamma, \n",
    "                                    maxleafsize = User_maxleafsize,\n",
    "                                    CollectStat = False,\n",
    "                                    User_ReturnHalfNnz = True,\n",
    "                                    SliceForm= True)\n",
    "\n",
    "\n",
    "        # NOTE Pyotch tensor spend textra memory when dlpack has to be called and there are mmeleak\n",
    "        #X = torch.tensor(protein_xyz, device=device, requires_grad= False)\n",
    "        X = protein_xyz\n",
    "\n",
    "        Xnumpy_SparseCupyMatrixUngapppedC = Xnumpy_SparseCupyMatrixUngappped(X, batch_head = None,\n",
    "            maxleafsize = User_maxleafsize, rc_Gamma = User_rc_Gamma,\n",
    "            #device  = torch.device(0),\n",
    "            User_PlusI = User_PlusI,\n",
    "            #dtype_temp = torch.float64,\n",
    "            #X_precision = torch.cuda.DoubleTensor,\n",
    "            User_DictCharmmGuiPbc = None, #Dict_Pbc,\n",
    "            NnzMinMaxDict = NnzMinMaxDict)\n",
    "        if User_IntegerOfIndexing == \"INTEGER32\":\n",
    "            A, A_diag = Xnumpy_SparseCupyMatrixUngapppedC.ReturnCupyHLowerTriangleInt32(\n",
    "                            User_MaxHalfNnzBufferSize = HalfNnz)\n",
    "        else:\n",
    "            #print('gagag')\n",
    "            A, A_diag = Xnumpy_SparseCupyMatrixUngapppedC.ReturnCupyHLowerTriangleInt64(\n",
    "                            User_MaxHalfNnzBufferSize = HalfNnz)\n",
    "\n",
    "        print(\"Matrix Index Datatype\", A.indices.dtype)\n",
    "        print(\"Matrix Datatype\",A.data.shape)\n",
    "        \n",
    "        cupy.get_default_memory_pool().free_all_blocks()\n",
    "        cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    PART03b_MakeFreeModes = True\n",
    "    if PART03b_MakeFreeModes:\n",
    "\n",
    "        Q_HotellingDeflation = cp.zeros((6,3*n_atoms), dtype = cp.float64)\n",
    "        # NOTE Translation\n",
    "        for i in range(3):\n",
    "            q1 = cp.zeros((n_atoms,3))\n",
    "            q1[:,i] = 1/np.sqrt(n_atoms)\n",
    "            Q_HotellingDeflation[i,:] = q1.flatten()\n",
    "            q1 = None\n",
    "            del q1\n",
    "            cupy.get_default_memory_pool().free_all_blocks()\n",
    "            cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
    "\n",
    "\n",
    "\n",
    "        # NOTE Rotation\n",
    "        R_x = cp.array([        [0,0,0],\n",
    "                                [0,0,-1],\n",
    "                                [0,1,0]], dtype=cp.float64).T\n",
    "        R_y = cp.array([        [0,0,1],\n",
    "                                [0,0,0],\n",
    "                                [-1,0,0]], dtype=cp.float64).T\n",
    "        R_z = cp.array([        [0,-1,0],\n",
    "                                [1,0,0],\n",
    "                                [0,0,0]], dtype=cp.float64).T\n",
    "        R_x = cupysparse.csr_matrix(R_x, dtype= cp.float64)\n",
    "        R_y = cupysparse.csr_matrix(R_y, dtype= cp.float64)\n",
    "        R_z = cupysparse.csr_matrix(R_z, dtype= cp.float64)\n",
    "        gx = (cp.array(X)@R_x).flatten()\n",
    "        Q_HotellingDeflation[3,:] = gx/ cp.linalg.norm(gx,ord=2)\n",
    "        gy = (cp.array(X)@R_y).flatten()\n",
    "        Q_HotellingDeflation[4,:] = gy/ cp.linalg.norm(gy,ord=2)\n",
    "        gz = (cp.array(X)@R_z).flatten()\n",
    "        Q_HotellingDeflation[5,:] = gz/ cp.linalg.norm(gz,ord=2)\n",
    "\n",
    "\n",
    "\n",
    "        for i_FRO in range(2):\n",
    "            V = Q_HotellingDeflation.T\n",
    "\n",
    "            for ix in range(6):\n",
    "                if ix == 0:\n",
    "                    continue\n",
    "                V[:,ix] -= cp.matmul(V[:,:ix], cp.matmul( V[:, :ix].T,V[:,ix] ))\n",
    "                V[:,ix] /= cp.sqrt(V[:, ix].T @ V[:, ix]) # TODO torch.matmul or mvs\n",
    "                V[:,ix] -= cp.matmul(V[:,:ix], cp.matmul( V[:, :ix].T,V[:,ix] ))\n",
    "                V[:,ix] /= cp.sqrt(V[:, ix].T @ V[:, ix])\n",
    "            Q_HotellingDeflation = V.T\n",
    "\n",
    "        #gx = Q_HotellingDeflation[3]\n",
    "\n",
    "        # NOTE Because of the naiive pbc implemented only 3 translational mode matters.\n",
    "        Q_HotellingDeflation = cupyx.scipy.sparse.csr_matrix(Q_HotellingDeflation, dtype = cp.float64)\n",
    "\n",
    "        gx, gy, gz = None, None, None\n",
    "        del gx, gy, gz\n",
    "        cupy.get_default_memory_pool().free_all_blocks()\n",
    "        cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
    "\n",
    "\n",
    "    \n",
    "    PART04_CalcualteEig = True\n",
    "    if PART04_CalcualteEig:\n",
    "        User_GapEstimate = None # NOTE Not in use.\n",
    "        eigval, eigvec = S_HeigvalJDMHD_HeigvecJDMHD(A, A_diag,\n",
    "                    k = User_n_mode,\n",
    "                    tol = User_EigTolerance,\n",
    "                    maxiter = User_MaxIter,\n",
    "                    User_CorrectionSolverMaxiter = User_SolverMaxIter,\n",
    "                    User_HalfMemMode= True,\n",
    "                    User_IntermediateConvergenceTol=1e-3, # NOTE Do not touch for this problem\n",
    "                    User_GapEstimate = User_GapEstimate, # NOTE This will be used for theta - gap_estimate\n",
    "                    User_FactoringToleranceOnCorrection = 1e-4, # NOTE Do not touch for this problem\n",
    "                    User_Q_HotellingDeflation= Q_HotellingDeflation,\n",
    "                    User_HotellingShift = 40, # NOTE 40 is generally safe for first 64 modes, of course if you want to guarentee it you know a norm\n",
    "\n",
    "                    )\n",
    "        runtime = time.time() - st\n",
    "        print(\"RUNNNTIME %s\" %(runtime))\n",
    "        peak_mem = cupy.get_default_memory_pool().used_bytes() / 1024 / 1024\n",
    "\n",
    "\n",
    "        runtime = time.time() - st\n",
    "        peak_mem = cupy.get_default_memory_pool().used_bytes() / 1024 / 1024\n",
    "        with open(\"%s/Eigval_InchingJDM_%s_%s_%s.pkl\" %(\n",
    "                    Benchmarking_folder, pdbid, User_Platform, \n",
    "                    User_Device.replace(\" \",\"\")),\"wb\") as fn:\n",
    "            pickle.dump(cupy.asnumpy(eigval) - User_PlusI ,fn, protocol=4)\n",
    "        \n",
    "        with open(\"%s/Eigvec_InchingJDM_%s_%s_%s.pkl\" %(\n",
    "                    Benchmarking_folder, pdbid, User_Platform, \n",
    "                    User_Device.replace(\" \",\"\")),\"wb\") as fn:    \n",
    "            tempeigvec = cupy.asnumpy(eigvec)\n",
    "            tempeigvec = tempeigvec.T\n",
    "            tempeigvec = tempeigvec.reshape((int(User_n_mode),int(n_atoms),int(3)))\n",
    "            pickle.dump(tempeigvec[:,cuthill_undoorder,:] ,fn, protocol=4)\n",
    "\n",
    "        \n",
    "        del tempeigvec\n",
    "        gc.collect()\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    PART05_Performance = True\n",
    "    if PART05_Performance:\n",
    "        #===================================\n",
    "        # Check correct\n",
    "        # =====================================\n",
    "\n",
    "        User_HalfMemMode = True\n",
    "        if User_HalfMemMode:\n",
    "            KrylovAv = InchingLiteInteger.Burn.Krylov.T3.OOC2_HalfMemS_v_KrylovAv_VOID(A, A_diag)\n",
    "        else:\n",
    "            KrylovAv = InchingLiteInteger.Burn.Krylov.T3.OOC2_FullMemS_v_KrylovAv_VOID(A, A_diag)\n",
    "        Av = cupy.empty((n_atoms*3,)).astype(A.dtype)\n",
    "\n",
    "\n",
    "        delta_lambda_list = []\n",
    "        for jj in range(User_n_mode):\n",
    "            KrylovAv(A,cupy.ravel(eigvec[:,jj]),Av)\n",
    "            B = Av - eigval[jj]* cupy.ravel(eigvec[:,jj])\n",
    "\n",
    "            delta_lambda_list.append(cupy.asnumpy(cublas.nrm2(B)))\n",
    "            #if jj < 20:\n",
    "            print(eigval[jj], cupy.asnumpy(cublas.nrm2(B)))\n",
    "        \n",
    "        eigval = cupy.asnumpy(eigval)\n",
    "        n_atoms = protein_xyz.shape[0]\n",
    "\n",
    "        GPU = \"%s %s\" %(User_Platform, User_Device.replace(\" GPU\", \"\"))\n",
    "\n",
    "        performance = [\"Inching (JDM %s)\" %(GPU), pdbfn, n_atoms, \n",
    "                        runtime, peak_mem, \n",
    "                        User_Platform, User_Device, \n",
    "                        User_maxleafsize]\n",
    "\n",
    "\n",
    "\n",
    "        longperformance = []\n",
    "        for i in range(len(delta_lambda_list)):\n",
    "            longperformance.append(performance + [i ,delta_lambda_list[i], eigval[i] - User_PlusI])\n",
    "        \n",
    "        with open(\"%s/PerformanceList_InchingJDM_%s_%s_%s.pkl\" %(Benchmarking_folder, \n",
    "            pdbid, User_Platform, User_Device.replace(\" \",\"\")),\"wb\") as fn:   \n",
    "            pickle.dump(longperformance,fn, protocol=4)\n",
    "\n",
    "\n",
    "        del X_df, protein_xyz\n",
    "        gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "        B = None\n",
    "        A.data = None\n",
    "        A.indices = None\n",
    "        A.indptr = None\n",
    "        Q_HotellingDeflation = None\n",
    "        del Q_HotellingDeflation\n",
    "\n",
    "        del A.data, A.indices, A.indptr \n",
    "        del A, B\n",
    "        Xnumpy_SparseCupyMatrixUngapppedC.X, Xnumpy_SparseCupyMatrixUngapppedC.X_unsqueezed = None, None\n",
    "        del Xnumpy_SparseCupyMatrixUngapppedC.X, Xnumpy_SparseCupyMatrixUngapppedC.X_unsqueezed\n",
    "        Xnumpy_SparseCupyMatrixUngapppedC = None\n",
    "        del Xnumpy_SparseCupyMatrixUngapppedC\n",
    "        eigvec, eigval = None, None\n",
    "        del eigvec, eigval\n",
    "\n",
    "\n",
    "        cupy.get_default_memory_pool().free_all_blocks()\n",
    "        cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
    "        del X \n",
    "        torch.cuda.empty_cache()    \n",
    "        torch.cuda.reset_peak_memory_stats(0)\n",
    "        torch.cuda.memory_allocated(0)\n",
    "        torch.cuda.max_memory_allocated(0)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec6c2d9cbfbaa729ccdd92f31e2be6fcbb66830e090159c2cc22789694c7cf7c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('Inching2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
