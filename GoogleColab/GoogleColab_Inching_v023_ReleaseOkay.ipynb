{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "272fcXN8FY2S"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jhmlam/Inching/blob/main/GoogleColab/GoogleColab_Inching_v023_ReleaseOkay.ipynb)\n",
        "\n",
        "# Running Inching on Colaboratory\n",
        "\n",
        "In this notebook, we will illustrate how to use Inching to analyse vibration of biological structures on the Google Colaboratory. In general, a Google Colaboratory free user will have access to the following computing resource\n",
        "\n",
        "* CPU. 2-core Intel(R) Xeon(R) @ 2.20GHz Family 6\n",
        "* System RAM. 12.7GB\n",
        "* GPU. Tesla T4, availability depends.\n",
        "* GPU RAM. 15GB memory.\n",
        "\n",
        "To proceed, click the play button on the top left corner of each cell.\n",
        "\n",
        "# Acknowledgement\n",
        "We would like to thank colleagues from [AlphaFold](https://colab.research.google.com/github/deepmind/alphafold/blob/main/notebooks/AlphaFold.ipynb#scrollTo=VzJ5iMjTtoZw) and [ColabFold](https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/beta/AlphaFold2_advanced.ipynb#scrollTo=woIxeCPygt7K) in formalising routines setting up Google Colab projects! Refer to FAQ in the last cell when question arise.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHBZYbHXFuU5"
      },
      "source": [
        "# Install Conda and Dependencies\n",
        "\n",
        "Here we present a version that runs on Google Colaboratory, a tentative service provided by Google for free GPU resources. To run the software with a strictly controlled version, please refer to `Inching-main/Command8A/README_InstallationOnCarc_20230221.sh` for instruction.\n",
        "\n",
        "* Colaboratory weather report 2023-12-27. The following cell will trigger a restart saying crash, but once restarted, click the next cell, everything's okay.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3_wurgiaIwR",
        "outputId": "95020653-d522-4d7b-96c2-e5e5f588e1a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting condacolab\n",
            "  Downloading condacolab-0.1.9-py3-none-any.whl (7.2 kB)\n",
            "Installing collected packages: condacolab\n",
            "Successfully installed condacolab-0.1.9\n",
            "â¬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:11\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "import google.colab #@markdown Click the play button!\n",
        "!pip install condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Und9luGB59nm"
      },
      "source": [
        "## INSTRUCTION: After Restart, click each of the following cells ONCE. Follow the instruction of each cell.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6FH5o1Ih8-d"
      },
      "source": [
        "# User Options\n",
        "\n",
        "`User_n_mode = 64` is the number of eigenpairs to be output. `User_EED_ = True` determines whether External Explicit Deflation is to be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZad7i9nh9O1"
      },
      "outputs": [],
      "source": [
        "User_n_mode = 32 #@param [32, 64] {type:\"raw\"}\n",
        "User_Eigensolver = \"InchingCTRLM\" #@param [\"InchingJDM\", \"InchingCTRLM\"] {type:\"raw\"}\n",
        "User_EED = True #@param {type:\"boolean\"}\n",
        "User_AnimateMode = 5 #@param [5, 10, 15, 20] {type:\"raw\"}\n",
        "User_IntegerOfIndexing = \"INTEGER32\" # NOTE Indexing. For extremely large system with nnz > 2.1 billion use INTEGER64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raeqczRtOes2"
      },
      "source": [
        "# Upload and Install\n",
        "\n",
        "Upload a pdb/cif file of your choice. Please name it with 4-alphanumerics followed by a suffix, either `.pdb` or `.cif`. For example, `5h2f.pdb`. Also, be reminded that\n",
        "\n",
        "* The default unit of 3-D coordinates in `.pdb` format is angstrom, but for `.cif` format, it is assumed nanometer. For simplicity, the uploaded file will always be renamed as `upload{suffix}`.\n",
        "* By default, we will remove the first 6 rigid modes with zero-eigenvalues by Hotelling deflation. However, if there are disconnected components separate from one another for more than 8 angstrom in the macromolecule (indeed, also when there are less than 3 linkages for an atom, think about the vector space!), there will be more than 6 rigid modes with zero-eigenvalues! See how to check it quickly in our Notebook `Inching-main/Notebook/Application/99_Inching_CheckConnectivity.ipynb`.\n",
        "\n",
        "# Remark\n",
        "`zip -P AAAAA10115 -r Inching-main.zip ./Inching-main/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9w88evBMs59"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload() #@markdown Upload a pdb/cif file of your choice.\n",
        "uploaded_filename = list(uploaded.keys())[0]\n",
        "print(uploaded_filename)\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "uploaded_suffix = uploaded_filename.split(\".\")[-1]\n",
        "shutil.move(uploaded_filename, \"upload.%s\" %(uploaded_suffix))\n",
        "\n",
        "\n",
        "\n",
        "# NOTE Then we install\n",
        "import condacolab\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "condacolab.check()\n",
        "#!conda install -q -y -c conda-forge -c pytorch scipy=1.8.0 pytorch=1.11.0 pandas=1.5.3 openmm=7.7.0 tqdm cupy=11.5.0 python=3.10\n",
        "#!conda install -q -y -c conda-forge openmm=7.7.0 mdtraj=1.9.7 tqdm python=3.10 cudatoolkit=12.2\n",
        "!conda install -q -y -c conda-forge -c nvidia -c pytorch openmm=7.7.0 mdtraj=1.9.7 tqdm python=3.10 cudatoolkit=11.8.0\n",
        "on_colab = True\n",
        "clear_output()\n",
        "\n",
        "# NOTE Fast steps\n",
        "#!wget https://zenodo.org/records/10443729/files/Inching-main.zip?download=1 -O /content/Inching-main.zip\n",
        "!wget https://zenodo.org/records/10645601/files/jhmlam/Inching-zenodov1.0.zip -O /content/Inching-main.zip\n",
        "#!unzip -P AAAAA10115 -o Inching-main.zip\n",
        "!unzip -o Inching-main.zip\n",
        "!cp -r Inching-main/InchingLiteInteger/ .\n",
        "!rm -r Result\n",
        "!mkdir Result\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKNMt3TlTBWz",
        "outputId": "01b16c58-7608-4707-a6e2-375f89986e8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-02-18 03:43:11--  https://zenodo.org/records/10645601/files/jhmlam/Inching-zenodov1.0.zip\n",
            "Resolving zenodo.org (zenodo.org)... 188.184.103.159, 188.184.98.238, 188.185.79.172, ...\n",
            "Connecting to zenodo.org (zenodo.org)|188.184.103.159|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 16354266 (16M) [application/octet-stream]\n",
            "Saving to: â€˜/content/Inching-main.zipâ€™\n",
            "\n",
            "/content/Inching-ma 100%[===================>]  15.60M  7.90MB/s    in 2.0s    \n",
            "\n",
            "2024-02-18 03:43:14 (7.90 MB/s) - â€˜/content/Inching-main.zipâ€™ saved [16354266/16354266]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://zenodo.org/records/10645601/files/jhmlam/Inching-zenodov1.0.zip -O /content/Inching-main.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKCkkUNYRtEZ"
      },
      "source": [
        "# Running the analysis\n",
        "\n",
        "The NVIDIAÂ® T4 is a single-slot, low-profile GPU, but it can still stably deliver analysis for macromolecules containing\n",
        "- [X] 100 thousand atoms, 32 modes in ~1 minute (CTRLM) ~5 minutes (JDM).\n",
        "- [ ] 200 tounsand atoms, 32 modes in ~10 minutes.\n",
        "\n",
        "\n",
        "Note that the time to read/write/download is discounted and may even be longer than the calculation on Colab(!). For performance computing, please use our code locally at a linux workstation. Follow through the notebooks at `https://github.com/jhmlam/Inching/blob/main/Notebook/Application/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrG8IzIiRsKu",
        "outputId": "8447bf7a-56cd-4777-bb63-82e54ad591d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n",
            "Reading structure...\n",
            "On Linux\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:01<00:00, 70.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N_neighbor within 8.0 angstrom Mean 99.25230805766928, Std 22.608807168015954\n",
            "NN search in 1.4604222774505615 s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/101059 [00:07<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start eigsh cupy\n",
            "On Linux\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:00<00:00, 668269.38it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:03<00:00, 287.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean number of Gaps > 100 is 9.77734375. Mean Gap Length Given Gap is 637.5534358769477\n",
            "Max number of Gaps > 100 is 27. Max Gap Length Given Gap is 4450\n",
            "Median number of Gaps > 100 is 10.0. Median Gap Length Given Gap is 322.5\n",
            "Total Entry Savings 630191193 which is 72.35069337742806 percent of a Rectangular Batch\n",
            "Nnz in Hessian (L+D) is 45591291.0. This will occupy 0.3362933211028576 GB for (L+D) data and at max 0.3362933211028576 GB for all indexings. Acceptable?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/InchingLiteInteger/Fuel/T1.py:218: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.frontal_gap_offset[i] = torch.tensor(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1024/1024 [00:12<00:00, 80.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Matrix Index Datatype int32\n",
            "Matrix Datatype (45281051,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:01<00:00, 197.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done Bound\n",
            "WARNING. Binary search begins with user supplied User_DesignatedStart\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kpm Estiamte Mean 5514.2 Std 90.98879051839299\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 19.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kpm Estiamte Mean 2075.0 Std 37.70411118167355\n",
            "Adjusted degree to 9 and Interval to 1.0,3.962416956672132. Estimate number of eigval is 2076\n",
            "Convergence ratio 0.7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 12.12it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kpm Estiamte Mean 490.8 Std 28.3365488371467\n",
            "Adjusted degree to 14 and Interval to 1.0,2.481208478336066. Estimate number of eigval is 492\n",
            "Convergence ratio 0.7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  7.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kpm Estiamte Mean 306.4 Std 36.603824936746705\n",
            "Adjusted degree to 22 and Interval to 1.0,1.740604239168033. Estimate number of eigval is 307\n",
            "Convergence ratio 0.7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  4.92it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kpm Estiamte Mean 177.6 Std 9.393614852653903\n",
            "Adjusted degree to 34 and Interval to 1.0,1.3703021195840166. Estimate number of eigval is 179\n",
            "Convergence ratio 0.7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Kpm Estiamte Mean 81.0 Std 13.520355024924458\n",
            "Adjusted degree to 53 and Interval to 1.0,1.1851510597920083. Estimate number of eigval is 82\n",
            "Convergence ratio 0.7\n",
            "53 (1.0, 1.1851510597920083)\n",
            "There are 64 Ritz vectors, tol = 1e-12\n",
            "Coarse_iter 0 Estimate at 3.3286034143644746e-06. Ritz values follows\n",
            "\n",
            "[  0.77215741   0.77199859   0.77100437   0.76980579   0.76958618\n",
            "   0.7307164    0.65144958   0.64952018   0.64907875   0.63929344\n",
            "   0.5778633    0.57730133   0.57672864   0.55998309   0.55923415\n",
            "   0.53208394   0.53031096   0.5274885    0.50499378   0.49497848\n",
            "   0.49384988   0.49065511   0.44145827   0.39890573   0.34818624\n",
            "   0.34476139   0.33815464   0.33217283   0.32441282   0.2808039\n",
            "   0.25818601   0.24616609   0.1671769    0.12774306   0.28449017\n",
            "   0.29510769   0.21388929   0.26855257   0.30822802 -34.17208412\n",
            "  -4.59912644   0.13288138   0.11799878   0.19771738   0.36519221\n",
            "   0.21105668 -37.11936663  -1.66185619   0.13823399   0.12581789\n",
            "   0.12250073   0.11089621  -0.83144628 -37.98573149   0.18899347\n",
            "   0.13663552   0.117097     0.11255628   0.1134788  -26.1929612\n",
            " -12.70884273   0.10623682   0.11154057   0.13030872] \n",
            "\n",
            "[ 0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.09273821  0.0957411   0.16800809  0.12827617\n",
            "  0.12424038  0.1301087   0.52199079 12.89332095  0.07933831  0.07115996\n",
            "  0.06261441  0.18165101  0.12951698  0.54067216  8.38646946  0.09847452\n",
            "  0.06636204  0.06779139  0.06111119  0.06485862  6.20406034  0.79442022\n",
            "  0.07422772  0.07773019  0.05519135  0.06079468  0.11821914 18.36006956\n",
            "  0.06682408  0.06178318  0.06763153  0.0609849 ] \n",
            "\n",
            "Total number of iterations went through 1 in 41.956435680389404 seconds\n",
            "RUNNNTIME 76.56117415428162\n",
            "1.0227062679362513 1.0550703187916395e-13\n",
            "1.0227247294245514 1.22932000397225e-13\n",
            "1.0228403798450967 1.2838571056116717e-13\n",
            "1.0229799720991815 4.954530755524445e-14\n",
            "1.0230055682269112 9.511407597228076e-14\n",
            "1.0276375277478327 1.1113897749581518e-13\n",
            "1.0377745755919598 5.708929960247089e-14\n",
            "1.0380341375668856 6.588611618965568e-14\n",
            "1.03809361470376 9.378236265886686e-14\n",
            "1.039420974979711 1.8419924935971178e-13\n",
            "1.0481600672499263 6.73610747391985e-14\n",
            "1.0482144554105146 6.436639671012774e-14\n",
            "1.0483328615149772 1.0817581513160938e-13\n",
            "1.0483963162760017 3.7407807542760794e-14\n",
            "1.0508662477542405 5.198359491378416e-14\n",
            "1.055057219489617 5.434490988038103e-14\n",
            "1.055238271426644 6.561607901608364e-14\n",
            "1.0553998693077826 9.255837178577043e-14\n",
            "1.0554826914433122 6.47897960079547e-14\n",
            "1.0555843680206967 6.301990730492702e-14\n",
            "1.0559577026106859 9.955009021957551e-14\n",
            "1.0612908013636058 5.6331686384501677e-14\n",
            "1.0614655706724703 9.124949077185968e-14\n",
            "1.0615565047624433 9.314319533057034e-14\n",
            "1.0617874717868603 9.391918443183903e-14\n",
            "1.0708305510074676 9.696546429396929e-14\n",
            "1.0791083890520539 2.007954391153626e-13\n",
            "1.0899685401564865 2.722801054518588e-13\n",
            "1.0903299607804895 1.739479392471588e-13\n",
            "1.0905515809037023 1.775211483596898e-13\n",
            "1.0908248340008093 1.598729627093138e-13\n",
            "1.0908859137774773 2.461333564509064e-13\n"
          ]
        }
      ],
      "source": [
        "import glob #@markdown Click the play button\n",
        "import platform\n",
        "import cupy as cp\n",
        "import cupyx\n",
        "from cupyx.scipy import sparse as cupysparse\n",
        "# A list of pdb available at different sizes\n",
        "PART00_IO = True\n",
        "if PART00_IO:\n",
        "  pdbavail = [ \"./upload.%s\" %(uploaded_suffix)]\n",
        "  Benchmarking_folder = \"./Result/\"\n",
        "\n",
        "  User_Platform = platform.system() # Windows Darwin Linux\n",
        "\n",
        "  User_rc_Gamma = 8.0\n",
        "  User_maxleafsize = 100\n",
        "\n",
        "  User_tol = 1e-15\n",
        "  User_PlusI = 1.0\n",
        "\n",
        "  if uploaded_suffix == 'cif':\n",
        "    PDBCIF=\"Cif\"\n",
        "  else:\n",
        "    PDBCIF = \"Pdb\"\n",
        "  User_MaxIter = 15000\n",
        "\n",
        "  # JDM Params\n",
        "  User_GapEstimate = 0\n",
        "  User_SolverName = 'gmres'\n",
        "  User_SolverMaxIter = 20\n",
        "  User_EigTolerance = 1e-12\n",
        "\n",
        "PART00_Import = True\n",
        "if PART00_Import:\n",
        "   import os\n",
        "   import gc\n",
        "   import sys\n",
        "   import pickle\n",
        "\n",
        "   import numpy as np\n",
        "   import time\n",
        "   import tqdm\n",
        "\n",
        "   import torch\n",
        "\n",
        "\n",
        "   import platform\n",
        "\n",
        "\n",
        "   import time\n",
        "\n",
        "   import cupy\n",
        "   from cupy import cublas\n",
        "\n",
        "\n",
        "   from scipy.spatial import cKDTree\n",
        "\n",
        "\n",
        "\n",
        "   sys.path.append('.')\n",
        "   sys.path.append('./InchingLiteInteger/Burn/')\n",
        "\n",
        "\n",
        "\n",
        "   import InchingLiteInteger.util\n",
        "   import InchingLiteInteger.Fuel.Coordinate.T1\n",
        "   import InchingLiteInteger.Fuel.Coordinate.T2\n",
        "   import InchingLiteInteger.Burn.Coordinate.T1\n",
        "   import InchingLiteInteger.Burn.Coordinate.T3\n",
        "\n",
        "   from InchingLiteInteger.Fuel.T1 import Xnumpy_SparseCupyMatrixUngappped\n",
        "\n",
        "   import InchingLiteInteger.Burn.Visualisation.T1\n",
        "   import InchingLiteInteger.Burn.Visualisation.T2\n",
        "\n",
        "   # ============================\n",
        "   # Some torch speed up tips\n",
        "   # =============================\n",
        "\n",
        "   # Turn on cuda optimizer\n",
        "   torch.backends.cudnn.is_available()\n",
        "   torch.backends.cudnn.enabled = True\n",
        "   torch.backends.cudnn.benchmark = True\n",
        "   # disable debugs NOTE use only after debugging\n",
        "   torch.autograd.set_detect_anomaly(False)\n",
        "   torch.autograd.profiler.profile(False)\n",
        "   torch.autograd.profiler.emit_nvtx(False)\n",
        "   # Disable gradient tracking\n",
        "   torch.no_grad()\n",
        "   torch.inference_mode()\n",
        "   torch.manual_seed(0)\n",
        "   cupy.random.seed(seed = 0)\n",
        "   os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" # NOTE In case any error showup\n",
        "   # Reset Cuda and Torch\n",
        "   device = torch.device(0)\n",
        "   torch.set_default_dtype(torch.float64)\n",
        "   torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
        "   try:\n",
        "      InchingLiteInteger.util.TorchEmptyCache()\n",
        "   except RuntimeError:\n",
        "      print(\"The GPU is free to use. THere is no existing occupant\")\n",
        "   try:\n",
        "      print(torch.cuda.memory_summary(device = 0, abbreviated=True))\n",
        "   except KeyError:\n",
        "      print(\"The GPU is free to use. THere is no existing occupant\")\n",
        "\n",
        "\n",
        "\n",
        "pdbfn = pdbavail[0]\n",
        "devices_ = [d for d in range(torch.cuda.device_count())]\n",
        "device_names_  = [torch.cuda.get_device_name(d) for d in devices_]\n",
        "User_Device =  device_names_[0]\n",
        "\n",
        "\n",
        "pdbid = pdbfn.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "\n",
        "\n",
        "print(\"Reading structure...\")\n",
        "X_df, X_top = InchingLiteInteger.util.BasicPdbCifLoading(pdbfn)\n",
        "protein_xyz = X_df[['x','y','z']].to_numpy().astype(np.float64)\n",
        "# NOTE PDB format digit decimal do no destroy collinearity!\n",
        "protein_xyz -= np.around(protein_xyz.mean(axis= 0), decimals=4)\n",
        "n_atoms = protein_xyz.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===============================================\n",
        "# K-d Cuthill (NOTE CPU np array)\n",
        "# ===================================\n",
        "PART02_Cuthill = True\n",
        "if PART02_Cuthill:\n",
        "    # NOTE Cuthill Order and Undo\n",
        "    st = time.time()\n",
        "    cuthill_order, cuthill_undoorder = InchingLiteInteger.Fuel.Coordinate.T1.X_KdCuthillMckeeOrder(protein_xyz,\n",
        "                                rc_Gamma = User_rc_Gamma, Reverse = True,\n",
        "                                )\n",
        "    protein_xyz = protein_xyz[cuthill_order,:]\n",
        "    #protein_tree = cKDTree(protein_xyz, leafsize=16, compact_nodes=True, copy_data=False, balanced_tree=True, boxsize=None)\n",
        "\n",
        "\n",
        "    from InchingLiteInteger.Burn.JacobiDavidsonHotellingDeflation.T1 import S_HeigvalJDMHD_HeigvecJDMHD\n",
        "    from InchingLiteInteger.Burn.ThickRestartLanczosHotellingDeflation.T1 import S_HeigvalTRLMHD_HeigvecTRLMHD\n",
        "    from InchingLiteInteger.Burn.ChebyshevDavidsonSubspaceIteration.T1 import S_HeigvalCDSIHD_HeigvecCDSIHD\n",
        "\n",
        "\n",
        "    import InchingLiteInteger.Burn.HermitianLanczos.T2\n",
        "    import InchingLiteInteger.Burn.PolynomialFilters.T0\n",
        "    import InchingLiteInteger.Burn.PolynomialFilters.T2\n",
        "\n",
        "\n",
        "\n",
        "    print('start eigsh cupy')\n",
        "\n",
        "    mempool = cupy.get_default_memory_pool()\n",
        "    pinned_mempool = cupy.get_default_pinned_memory_pool()\n",
        "\n",
        "# ==================\n",
        "# Cupy hessian\n",
        "# =====================\n",
        "\n",
        "\n",
        "PART03a_MakeCupyHessian = True\n",
        "if PART03a_MakeCupyHessian:\n",
        "    # NOTE Nnz neighborhood after cuthill\n",
        "    NnzMinMaxDict, HalfNnz  = InchingLiteInteger.Fuel.Coordinate.T1.X_KdUngappedMinMaxNeighbor(protein_xyz,\n",
        "                                rc_Gamma = User_rc_Gamma,\n",
        "                                maxleafsize = User_maxleafsize,\n",
        "                                CollectStat = False,\n",
        "                                User_ReturnHalfNnz = True,\n",
        "                                SliceForm= True)\n",
        "\n",
        "\n",
        "    # NOTE Pyotch tensor spend textra memory when dlpack has to be called and there are mmeleak\n",
        "    #X = torch.tensor(protein_xyz, device=device, requires_grad= False)\n",
        "    X = protein_xyz\n",
        "\n",
        "    Xnumpy_SparseCupyMatrixUngapppedC = Xnumpy_SparseCupyMatrixUngappped(X, batch_head = None,\n",
        "        maxleafsize = User_maxleafsize, rc_Gamma = User_rc_Gamma,\n",
        "        #device  = torch.device(0),\n",
        "        User_PlusI = User_PlusI,\n",
        "        #dtype_temp = torch.float64,\n",
        "        #X_precision = torch.cuda.DoubleTensor,\n",
        "        User_DictCharmmGuiPbc = None, #Dict_Pbc,\n",
        "        NnzMinMaxDict = NnzMinMaxDict)\n",
        "    if User_IntegerOfIndexing == \"INTEGER32\":\n",
        "        A, A_diag = Xnumpy_SparseCupyMatrixUngapppedC.ReturnCupyHLowerTriangleInt32(\n",
        "                        User_MaxHalfNnzBufferSize = HalfNnz)\n",
        "    else:\n",
        "        #print('gagag')\n",
        "        A, A_diag = Xnumpy_SparseCupyMatrixUngapppedC.ReturnCupyHLowerTriangleInt64(\n",
        "                        User_MaxHalfNnzBufferSize = HalfNnz)\n",
        "\n",
        "    print(\"Matrix Index Datatype\", A.indices.dtype)\n",
        "    print(\"Matrix Datatype\",A.data.shape)\n",
        "\n",
        "    cupy.get_default_memory_pool().free_all_blocks()\n",
        "    cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "PART03b_MakeFreeModes = User_EED\n",
        "if PART03b_MakeFreeModes:\n",
        "\n",
        "    Q_HotellingDeflation = cp.zeros((6,3*n_atoms), dtype = cp.float64)\n",
        "    # NOTE Translation\n",
        "    for i in range(3):\n",
        "        q1 = cp.zeros((n_atoms,3))\n",
        "        q1[:,i] = 1/np.sqrt(n_atoms)\n",
        "        Q_HotellingDeflation[i,:] = q1.flatten()\n",
        "        q1 = None\n",
        "        del q1\n",
        "        cupy.get_default_memory_pool().free_all_blocks()\n",
        "        cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
        "\n",
        "\n",
        "\n",
        "    # NOTE Rotation\n",
        "    R_x = cp.array([        [0,0,0],\n",
        "                            [0,0,-1],\n",
        "                            [0,1,0]], dtype=cp.float64).T\n",
        "    R_y = cp.array([        [0,0,1],\n",
        "                            [0,0,0],\n",
        "                            [-1,0,0]], dtype=cp.float64).T\n",
        "    R_z = cp.array([        [0,-1,0],\n",
        "                            [1,0,0],\n",
        "                            [0,0,0]], dtype=cp.float64).T\n",
        "    R_x = cupysparse.csr_matrix(R_x, dtype= cp.float64)\n",
        "    R_y = cupysparse.csr_matrix(R_y, dtype= cp.float64)\n",
        "    R_z = cupysparse.csr_matrix(R_z, dtype= cp.float64)\n",
        "    gx = (cp.array(X)@R_x).flatten()\n",
        "    Q_HotellingDeflation[3,:] = gx/ cp.linalg.norm(gx,ord=2)\n",
        "    gy = (cp.array(X)@R_y).flatten()\n",
        "    Q_HotellingDeflation[4,:] = gy/ cp.linalg.norm(gy,ord=2)\n",
        "    gz = (cp.array(X)@R_z).flatten()\n",
        "    Q_HotellingDeflation[5,:] = gz/ cp.linalg.norm(gz,ord=2)\n",
        "\n",
        "\n",
        "\n",
        "    for i_FRO in range(2):\n",
        "        V = Q_HotellingDeflation.T\n",
        "\n",
        "        for ix in range(6):\n",
        "            if ix == 0:\n",
        "                continue\n",
        "            V[:,ix] -= cp.matmul(V[:,:ix], cp.matmul( V[:, :ix].T,V[:,ix] ))\n",
        "            V[:,ix] /= cp.sqrt(V[:, ix].T @ V[:, ix]) # TODO torch.matmul or mvs\n",
        "            V[:,ix] -= cp.matmul(V[:,:ix], cp.matmul( V[:, :ix].T,V[:,ix] ))\n",
        "            V[:,ix] /= cp.sqrt(V[:, ix].T @ V[:, ix])\n",
        "        Q_HotellingDeflation = V.T\n",
        "\n",
        "    gx = Q_HotellingDeflation[3]\n",
        "\n",
        "\n",
        "    Q_HotellingDeflation = cupyx.scipy.sparse.csr_matrix(Q_HotellingDeflation, dtype = cp.float64)\n",
        "\n",
        "    gx, gy, gz = None, None, None\n",
        "    del gx, gy, gz\n",
        "    cupy.get_default_memory_pool().free_all_blocks()\n",
        "    cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if User_Eigensolver == \"InchingJDM\":\n",
        "  PART04_CalcualteEigJDM = True\n",
        "else:\n",
        "  PART04_CalcualteEigJDM = False\n",
        "if PART04_CalcualteEigJDM:\n",
        "    if User_EED:\n",
        "\n",
        "        User_GapEstimate = 0 # NOTE Not in use.\n",
        "        eigval, eigvec = S_HeigvalJDMHD_HeigvecJDMHD(A, A_diag,\n",
        "                    k = User_n_mode,\n",
        "                    tol = User_EigTolerance,\n",
        "                    maxiter = User_MaxIter,\n",
        "                    User_CorrectionSolverMaxiter = User_SolverMaxIter,\n",
        "                    User_HalfMemMode= True,\n",
        "                    User_IntermediateConvergenceTol=1e-3, # NOTE Do not touch for this problem\n",
        "                    User_GapEstimate = User_GapEstimate, # NOTE This will be used for theta - gap_estimate\n",
        "                    User_FactoringToleranceOnCorrection = 1e-4, # NOTE Do not touch for this problem\n",
        "                    User_Q_HotellingDeflation= Q_HotellingDeflation,\n",
        "                    User_HotellingShift = 40, # NOTE 40 is generally safe for first 64 modes, of course if you want to guarentee it you know a norm\n",
        "\n",
        "                    )\n",
        "    else:\n",
        "\n",
        "        User_GapEstimate = 0 # NOTE Not in use.\n",
        "        eigval, eigvec = S_HeigvalJDMHD_HeigvecJDMHD(A, A_diag,\n",
        "                    k = User_n_mode,\n",
        "                    tol = User_EigTolerance,\n",
        "                    maxiter = User_MaxIter,\n",
        "                    User_CorrectionSolverMaxiter = User_SolverMaxIter,\n",
        "                    User_HalfMemMode= True,\n",
        "                    User_IntermediateConvergenceTol=1e-3, # NOTE Do not touch for this problem\n",
        "                    User_GapEstimate = User_GapEstimate, # NOTE This will be used for theta - gap_estimate\n",
        "                    User_FactoringToleranceOnCorrection = 1e-4, # NOTE Do not touch for this problem\n",
        "                    User_Q_HotellingDeflation= None,\n",
        "                    User_HotellingShift = 40, # NOTE 40 is generally safe for first 64 modes, of course if you want to guarentee it you know a norm\n",
        "\n",
        "                    )\n",
        "\n",
        "\n",
        "\n",
        "    runtime = time.time() - st\n",
        "    print(\"RUNNNTIME %s\" %(runtime))\n",
        "    peak_mem = cupy.get_default_memory_pool().used_bytes() / 1024 / 1024\n",
        "\n",
        "\n",
        "    runtime = time.time() - st\n",
        "    peak_mem = cupy.get_default_memory_pool().used_bytes() / 1024 / 1024\n",
        "    with open(\"%s/Eigval_InchingJDM_%s_%s_%s.pkl\" %(\n",
        "                Benchmarking_folder, pdbid, User_Platform,\n",
        "                User_Device.replace(\" \",\"\")),\"wb\") as fn:\n",
        "        pickle.dump(cupy.asnumpy(eigval) - User_PlusI ,fn, protocol=4)\n",
        "\n",
        "    with open(\"%s/Eigvec_InchingJDM_%s_%s_%s.pkl\" %(\n",
        "                Benchmarking_folder, pdbid, User_Platform,\n",
        "                User_Device.replace(\" \",\"\")),\"wb\") as fn:\n",
        "        tempeigvec = cupy.asnumpy(eigvec)\n",
        "        tempeigvec = tempeigvec.T\n",
        "        tempeigvec = tempeigvec.reshape((int(User_n_mode),int(n_atoms),int(3)))\n",
        "        pickle.dump(tempeigvec[:,cuthill_undoorder,:] ,fn, protocol=4)\n",
        "\n",
        "\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "if User_Eigensolver == \"InchingCTRLM\":\n",
        "  PART04_CalcualteEigCTRLM = True\n",
        "else:\n",
        "  PART04_CalcualteEigCTRLM = False\n",
        "\n",
        "if PART04_CalcualteEigCTRLM:\n",
        "    User_WantedNumberEigenvalue = User_n_mode\n",
        "    User_SpectrumBound = InchingLiteInteger.Burn.HermitianLanczos.T2.A_Adiag_EstimateSpectrumBound(\n",
        "                            A, A_diag, User_HalfMemMode = True )\n",
        "    #RitzValues = User_SpectrumBound[2]\n",
        "    #print(User_SpectrumBound)\n",
        "    #print(float(np.quantile(RitzValues,0.025)))\n",
        "    User_SpectrumBound = (User_SpectrumBound[0], User_SpectrumBound[1])\n",
        "    User_SpectrumBound = (User_PlusI, User_SpectrumBound[1].get()+1e-12)\n",
        "\n",
        "\n",
        "    User_WantedInterval_ = (1.0, User_SpectrumBound[1]/10)\n",
        "    User_WantedInterval = User_WantedInterval_\n",
        "    # NOTE For the extremal it is empirically unwise to squeeze too hard as many of\n",
        "    #      these eigenvalues are close to 0+1 and the mapped function is in steep decline (with very deep caution here.)\n",
        "    #      I would delibrately make the wanted nubmer of eigval larger, because anyhow the lowest will be the first to converge in this scenairo\n",
        "    User_PolynomialParams, eigval_count_estimate, temp_User_WantedInterval = InchingLiteInteger.Burn.PolynomialFilters.T2.A_Adiag_OptimizePolynomialParamsOnMemory(\n",
        "                                                    A, A_diag,\n",
        "                                                    User_MaximumDegree = 5120,\n",
        "                                                    User_MinimumDegree = 5,\n",
        "                                                    User_DampingKernel = \"Jackson\",\n",
        "                                                    User_ExtremalIntervalDefinition = 1e-10,\n",
        "                                                    User_WantedInterval = User_WantedInterval,\n",
        "                                                    User_SpectrumBound = User_SpectrumBound,\n",
        "                                                    User_DesignatedStart = User_SpectrumBound[1]/10,\n",
        "                                                    # NOTE Make this a underestimate of the actual number.\n",
        "                                                    #      While we will have repeated modes, the risk of having a repeated mode is outweighed by risk of non-convergence!\n",
        "                                                    #\n",
        "                                                    User_WantedNumberEigenvalue = int(User_WantedNumberEigenvalue-5)*3,\n",
        "                                                    User_AffordableMemoryMargin = 5*5,\n",
        "                                                    User_HalfMemMode = True,\n",
        "                                                    User_NumberKpmTrials =  5,\n",
        "                                                    User_ConvergenceRatio = 0.7, # NOTE For extremal this is overrided with 0.1\n",
        "                                                    )\n",
        "    User_WantedInterval = (temp_User_WantedInterval[0], temp_User_WantedInterval[1])\n",
        "    print(User_PolynomialParams.AdjustedDegree, temp_User_WantedInterval)\n",
        "\n",
        "    User_Q_HotellingDeflation_ = Q_HotellingDeflation\n",
        "    eigval, eigvec = S_HeigvalTRLMHD_HeigvecTRLMHD(A, A_diag,\n",
        "\n",
        "\n",
        "                        User_WorkspaceSizeFactor = 2 ,\n",
        "                        k = User_n_mode ,\n",
        "                        tol = User_EigTolerance,\n",
        "                        maxiter = User_MaxIter,\n",
        "                        #User_CorrectionSolverMaxiter = User_SolverMaxIter,\n",
        "                        User_HalfMemMode= True,\n",
        "                        #User_IntermediateConvergenceTol=1e-3, # NOTE Do not touch for this problem\n",
        "                        #User_GapEstimate = User_GapEstimate, # NOTE This will be used for theta - gap_estimate\n",
        "                        #User_FactoringToleranceOnCorrection = 1e-4,#1e-4, # NOTE Do not touch for this problem\n",
        "\n",
        "                        User_Q_HotellingDeflation = User_Q_HotellingDeflation_, #Q_HotellingDeflation,\n",
        "                        User_HotellingShift = -40.0,# NOTE pull to negative, we are on cheb\n",
        "\n",
        "                        User_PolynomialParams = User_PolynomialParams,\n",
        "                        )\n",
        "\n",
        "\n",
        "\n",
        "    runtime = time.time() - st\n",
        "    print(\"RUNNNTIME %s\" %(runtime))\n",
        "    peak_mem = cupy.get_default_memory_pool().used_bytes() / 1024 / 1024\n",
        "\n",
        "\n",
        "    runtime = time.time() - st\n",
        "    peak_mem = cupy.get_default_memory_pool().used_bytes() / 1024 / 1024\n",
        "    with open(\"%s/Eigval_InchingJDM_%s_%s_%s.pkl\" %(\n",
        "                Benchmarking_folder, pdbid, User_Platform,\n",
        "                User_Device.replace(\" \",\"\")),\"wb\") as fn:\n",
        "        pickle.dump(cupy.asnumpy(eigval) - User_PlusI ,fn, protocol=4)\n",
        "\n",
        "    with open(\"%s/Eigvec_InchingJDM_%s_%s_%s.pkl\" %(\n",
        "                Benchmarking_folder, pdbid, User_Platform,\n",
        "                User_Device.replace(\" \",\"\")),\"wb\") as fn:\n",
        "        tempeigvec = cupy.asnumpy(eigvec)\n",
        "        tempeigvec = tempeigvec.T\n",
        "        tempeigvec = tempeigvec.reshape((int(User_n_mode),int(n_atoms),int(3)))\n",
        "        pickle.dump(tempeigvec[:,cuthill_undoorder,:] ,fn, protocol=4)\n",
        "\n",
        "\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "PART05_Performance = True\n",
        "if PART05_Performance:\n",
        "    #===================================\n",
        "    # Check correct\n",
        "    # =====================================\n",
        "    #print(eigval)\n",
        "    #print(eigvec.shape)\n",
        "\n",
        "    User_HalfMemMode = True\n",
        "    if User_HalfMemMode:\n",
        "        KrylovAv = InchingLiteInteger.Burn.Krylov.T3.OOC2_HalfMemS_v_KrylovAv_VOID(A, A_diag)\n",
        "    else:\n",
        "        KrylovAv = InchingLiteInteger.Burn.Krylov.T3.OOC2_FullMemS_v_KrylovAv_VOID(A, A_diag)\n",
        "    Av = cupy.empty((n_atoms*3,)).astype(A.dtype)\n",
        "\n",
        "\n",
        "    delta_lambda_list = []\n",
        "    for jj in range(User_n_mode):\n",
        "        KrylovAv(A,cupy.ravel(eigvec[:,jj]),Av)\n",
        "        B = Av - eigval[jj]* cupy.ravel(eigvec[:,jj])\n",
        "\n",
        "        delta_lambda_list.append(cupy.asnumpy(cublas.nrm2(B)))\n",
        "        #if jj < 20:\n",
        "        print(eigval[jj], cupy.asnumpy(cublas.nrm2(B)))\n",
        "\n",
        "\n",
        "    eigval = cupy.asnumpy(eigval)\n",
        "    n_atoms = protein_xyz.shape[0]\n",
        "\n",
        "    GPU = \"%s %s\" %(User_Platform, User_Device.replace(\" GPU\", \"\"))\n",
        "\n",
        "    performance = [\"Inching (JDM %s)\" %(GPU), pdbfn, n_atoms,\n",
        "                    runtime, peak_mem,\n",
        "                    User_Platform, User_Device,\n",
        "                    User_maxleafsize]\n",
        "\n",
        "\n",
        "\n",
        "    longperformance = []\n",
        "    for i in range(len(delta_lambda_list)):\n",
        "        longperformance.append(performance + [i ,delta_lambda_list[i], eigval[i] - User_PlusI])\n",
        "\n",
        "    with open(\"%s/PerformanceList_InchingJDM_%s_%s_%s.pkl\" %(Benchmarking_folder,\n",
        "        pdbid, User_Platform, User_Device.replace(\" \",\"\")),\"wb\") as fn:\n",
        "        pickle.dump(longperformance,fn, protocol=4)\n",
        "\n",
        "\n",
        "    #del X_df#, protein_xyz\n",
        "    #gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "    B = None\n",
        "    A.data = None\n",
        "    A.indices = None\n",
        "    A.indptr = None\n",
        "    Q_HotellingDeflation = None\n",
        "    del Q_HotellingDeflation\n",
        "\n",
        "    del A.data, A.indices, A.indptr\n",
        "    del A, B\n",
        "    Xnumpy_SparseCupyMatrixUngapppedC.X, Xnumpy_SparseCupyMatrixUngapppedC.X_unsqueezed = None, None\n",
        "    del Xnumpy_SparseCupyMatrixUngapppedC.X, Xnumpy_SparseCupyMatrixUngapppedC.X_unsqueezed\n",
        "    Xnumpy_SparseCupyMatrixUngapppedC = None\n",
        "    del Xnumpy_SparseCupyMatrixUngapppedC\n",
        "    eigvec, eigval = None, None\n",
        "    del eigvec, eigval\n",
        "\n",
        "\n",
        "    cupy.get_default_memory_pool().free_all_blocks()\n",
        "    cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
        "    del X\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats(0)\n",
        "    torch.cuda.memory_allocated(0)\n",
        "    torch.cuda.max_memory_allocated(0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOYGTv8-Dycs"
      },
      "source": [
        "## Generate Animation and Download\n",
        "\n",
        "This writes the linearized motion as a `cif` file for each mode. Unfortunately, the I/O can often take much longer than the calculation itself. After downloading the `InchingResult.zip`, decompress it, open the cif file in pymol and load the corresponding `.pml` script. Enjoy!\n",
        "\n",
        "* By default, the `save_to_google_drive` check box is activated; it will ask for your permission to upload the result to your google drive. If `save_to_google_drive` check box is deactivated, you can directly download the file, but it can take very long.\n",
        "* To indicate the mode shape, for each mode, a black arrow is placed on 10000 randomly chosen atoms with top 50% of diplacement magnitude. Thickness of the arrow can be tuned by checking `User_ThickerArrowForDisplay`. It is suggested to use thicker arrows for structures with >100 thousand atoms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "8Nq_DUjXBrtm",
        "outputId": "a3ea1cc7-585a-45cb-f396-c5ae441fa8be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Printing animations...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 80.64it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 85.14it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 83.98it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 61.39it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 84.01it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 88.91it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 55.92it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 86.40it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 55.96it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 83.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compressing as zip...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "File size: 239.00692081451416 MB\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Preparing Google link address...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<a href=https://drive.google.com/file/d/1--YEZ_TzzEQPoDmTmBB7HV4FBYpnQ2bu target=_blank>Click HERE to download the InchingResult.zip file from your drive. Enjoy!</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "save_to_google_drive = True #@param {type:\"boolean\"}\n",
        "User_ThickerArrowForDisplay = True #@param {type:\"boolean\"}\n",
        "# =======================\n",
        "# Linearize\n",
        "# ==========================\n",
        "pdbfn = pdbavail[0]#@markdown The zip file will be downloaded as `InchingResult_{time}.zip`. Size is printed below\n",
        "\n",
        "User_QuantileDisplay = 0.5\n",
        "User_RandomPickArrows = 10000\n",
        "User_EigenvectorTwinDirection = 1\n",
        "\n",
        "User_BigClusterArrowFloatingFactor = 0.5\n",
        "User_DBscanMinDist = 1.5 # NOTE THis roughly cluster the 90% percentile arrows. largerr the less arrows\n",
        "\n",
        "print(\"Printing animations...\")\n",
        "import sklearn.cluster\n",
        "from InchingLiteInteger.Fuel.Coordinate.T1 import HeigvecOne_BoxCoxMagnitude\n",
        "protein_xyz_ = protein_xyz\n",
        "PART06_Animate = True\n",
        "if PART06_Animate:\n",
        "    eigvec = tempeigvec[:,cuthill_undoorder,:]\n",
        "    protein_xyz = protein_xyz[cuthill_undoorder,:]\n",
        "    if User_EED:\n",
        "      pass\n",
        "    else:\n",
        "      User_AnimateMode +=6\n",
        "\n",
        "    i_mode = 0\n",
        "    for User_TheModeToShow in range(User_AnimateMode):\n",
        "\n",
        "        if User_EED:\n",
        "          pass\n",
        "        else:\n",
        "          if User_TheModeToShow <=5:\n",
        "              continue\n",
        "\n",
        "        if pdbfn.split(\".\")[-1] == 'pdb':\n",
        "            nmfactor = 0.1\n",
        "        else:\n",
        "            nmfactor = 1\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "        PART06b_Logistic = True\n",
        "        if PART06b_Logistic:\n",
        "\n",
        "            #if os.path.exists(\"%s/%s_Animated_%s_%s.cif\" %(Benchmarking_folder, pdbid, pdbid, i_mode)):\n",
        "            #    continue\n",
        "\n",
        "            # NOTE Kerneled eigvec\n",
        "            deltaX_magnitude = HeigvecOne_BoxCoxMagnitude( eigvec[User_TheModeToShow,:,:],\n",
        "                    User_WinsorizingWindow = (0.025, 0.975),\n",
        "                    User_LogisticParam = (0.05, 1.0),\n",
        "                    )\n",
        "\n",
        "            deltaX_magnitude = np.clip(deltaX_magnitude, 0.1, 1.0)\n",
        "            eigvec_unit = eigvec[User_TheModeToShow] / np.linalg.norm(eigvec[User_TheModeToShow], axis=1)[:,None]\n",
        "            deltaX = deltaX_magnitude[:,None] * eigvec_unit\n",
        "\n",
        "\n",
        "            InchingLiteInteger.util.SaveOneModeLinearisedAnime(\n",
        "                    deltaX,\n",
        "                    protein_xyz*nmfactor,\n",
        "                    n_timestep = 16,\n",
        "                    DIR_ReferenceStructure = pdbfn,#[:-4] + \"trial.cif\",\n",
        "                    DIR_SaveFolder = Benchmarking_folder,\n",
        "                    SaveFormat = 'cif',\n",
        "                    outputlabel = 'Animated_%s_%s'%(pdbid, i_mode),\n",
        "                    max_abs_deviation = 3.0*nmfactor,\n",
        "                    stepsize = 1.0*nmfactor,\n",
        "                    UnitMovement = False,\n",
        "                    max_n_output = 32,\n",
        "                    SaveSeparate = False,\n",
        "                    RemoveOrig = False, # NOTE This flag remove the unmoved structure from the trajectory produce\n",
        "                    User_Bfactor=deltaX_magnitude\n",
        "                    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        PART06c_Arrows = True\n",
        "        if PART06c_Arrows:\n",
        "          PART02_DecideWhatArrowsToPlot = True\n",
        "          if PART02_DecideWhatArrowsToPlot:\n",
        "              where_CaOrP = X_df.loc[X_df['name'].isin([\"CA\", \"P\"]) & ~X_df['element'].isin([\"Ca\"])].index.values\n",
        "              where_larger = np.where((deltaX_magnitude > np.quantile(deltaX_magnitude, q = User_QuantileDisplay)))[0]\n",
        "              # a ball with large displacement TODO Show the stacked detail\n",
        "              where_larger_CaOrP = np.intersect1d(where_larger, where_CaOrP, assume_unique=False, return_indices=False)\n",
        "              where_random = np.random.choice(where_larger_CaOrP,\n",
        "                                                  size= min(User_RandomPickArrows, where_larger_CaOrP.shape[0]), replace = False)\n",
        "\n",
        "              # TODO Make  a big arrow for those large ones only! Cluster the coordinate by dbscan.\n",
        "              #      average the arrow put it in center and floating in air.\n",
        "              #      Make the arrow obvious enough to indicate the direction.\n",
        "              where_CaOrP_subset = where_CaOrP[::max(1, int(protein_xyz.shape[0]/User_RandomPickArrows))]\n",
        "\n",
        "\n",
        "              # ======================\n",
        "              # Big Arrow\n",
        "              # =========================\n",
        "\n",
        "              clustering = sklearn.cluster.DBSCAN(eps=User_DBscanMinDist, min_samples=10, metric='euclidean',\n",
        "                                                  metric_params=None, algorithm='kd_tree',\n",
        "                                                  leaf_size=100, p=2, n_jobs=1).fit(protein_xyz[where_larger_CaOrP,:])\n",
        "              unique_clusters = np.unique(clustering.labels_)\n",
        "              DBSCAN_Coord = np.zeros((unique_clusters.shape[0],3))\n",
        "              DBSCAN_UnitEigvec = np.zeros((unique_clusters.shape[0],3))\n",
        "              DBSCAN_UnitEigvecmag = np.zeros((unique_clusters.shape[0],1))\n",
        "              for i_cluster in unique_clusters:\n",
        "                  if i_cluster == -1:\n",
        "                      continue\n",
        "                  same_cluster = where_larger_CaOrP[np.where(clustering.labels_ == i_cluster)[0]]\n",
        "                  DBSCAN_Coord[i_cluster,:] = np.mean(protein_xyz[same_cluster,:], axis=0)\n",
        "                  DBSCAN_UnitEigvec[i_cluster,:] = np.mean(eigvec_unit[same_cluster,:], axis=0)\n",
        "                  DBSCAN_UnitEigvecmag[i_cluster,:] = np.mean(deltaX_magnitude[same_cluster])\n",
        "\n",
        "          #print(\"dbscan done\")\n",
        "          # ========================\n",
        "          # Print arrwo\n",
        "          # ==========================\n",
        "          PART03_PrintCgoArrows = True\n",
        "          if PART03_PrintCgoArrows:\n",
        "              # NOTE Pymol...\n",
        "              if pdbfn.split(\".\")[-1] == 'pdb':\n",
        "                  nmfactor_ = 10.0\n",
        "              else:\n",
        "                  nmfactor_ = 10.0\n",
        "\n",
        "\n",
        "              #print(deltaX_magnitude)\n",
        "              percentilescore_all =  np.argsort(np.argsort(deltaX_magnitude, axis=0), axis=0) / float(len(deltaX_magnitude)) # NOTE Assumed that each has a unique float\n",
        "              print_cgoarrows = []\n",
        "\n",
        "              # =================================\n",
        "              # NOTE THe Big Clustered Arrow\n",
        "              # ==================================\n",
        "              \"\"\"\n",
        "              for i_cluster in range(unique_clusters.shape[0]):\n",
        "\n",
        "                  # NOTE Point to point\n",
        "                  position_source = DBSCAN_Coord[i_cluster] * nmfactor_\n",
        "                  direction_size = 99 * DBSCAN_UnitEigvecmag[i_cluster]\n",
        "                  direction_= (User_EigenvectorTwinDirection * DBSCAN_UnitEigvec[i_cluster] *direction_size) #* deltaX_magnitude[atomindex_]*50)\n",
        "                  gap = direction_* User_BigClusterArrowFloatingFactor\n",
        "\n",
        "                  position_source += gap\n",
        "                  #position_source += direction_*User_BigClusterArrowFloatingFactor\n",
        "                  position_target = position_source + direction_\n",
        "\n",
        "                  x_s, y_s, z_s = position_source[0], position_source[1], position_source[2]\n",
        "                  x_t, y_t, z_t = position_target[0], position_target[1], position_target[2]\n",
        "                  thickness_ = 5 # percentilescore_all[atomindex_]\n",
        "                  print_cgoarrows.append(\"cgo_arrow [%.3f, %.3f, %.3f], [%.3f, %.3f, %.3f] \" %(\n",
        "                      x_s, y_s, z_s, x_t, y_t, z_t) + ', name = \\\"' + \"ClusterArrow%s\" %(i_cluster+1)+'\\\",' + \" radius = %s, hradius = %s, hlength = %s, \" %(thickness_, thickness_*2, direction_size[0]/2 ) + ' color = hotpink')\n",
        "                      # hotpink black\n",
        "              \"\"\"\n",
        "              # ===========================\n",
        "              # NOTE every n CA\n",
        "              # ==============================\n",
        "              choice_where =  where_random # where_CaOrP_subset\n",
        "              for i_whererand in range(len(choice_where)):\n",
        "                  atomindex_ = choice_where[i_whererand]\n",
        "                  # NOTE Point to point\n",
        "                  position_source = protein_xyz[atomindex_]*nmfactor_\n",
        "                  direction_= (eigvec_unit[atomindex_] * User_EigenvectorTwinDirection *25 * deltaX_magnitude[atomindex_]) #* deltaX_magnitude[atomindex_]*50)\n",
        "                  position_target = position_source + direction_\n",
        "\n",
        "                  x_s, y_s, z_s = position_source[0], position_source[1], position_source[2]\n",
        "                  x_t, y_t, z_t = position_target[0], position_target[1], position_target[2]\n",
        "                  if User_ThickerArrowForDisplay:\n",
        "                    thickness_ = 0.5\n",
        "                  else:\n",
        "                    thickness_ = 0.1 # percentilescore_all[atomindex_]\n",
        "                  print_cgoarrows.append(\"cgo_arrow [%.3f, %.3f, %.3f], [%.3f, %.3f, %.3f] \" %(\n",
        "                      x_s, y_s, z_s, x_t, y_t, z_t) + ', name = \\\"' + \"Index%s\" %(atomindex_+1)+'\\\",' + \" radius = %s, hradius = %s, hlength = 10.23, \" %(thickness_*1, thickness_ * 4) + ' color = black')\n",
        "                      # hotpink black\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          with open('./Inching-main/Notebook/Application/ArrowTemplate.pml', 'r') as f :\n",
        "                  filedata = f.read()\n",
        "\n",
        "          filedata = filedata.replace('REPLACE_WITH_FILENAME', \"%s/%s_Animated_%s_%s.cif\" %(\"./\", pdbid, pdbid, i_mode))\n",
        "          filedata = filedata.replace('REPLACE_WITH_ID', '%s' %(pdbid))\n",
        "          filedata = filedata.replace('REPLACE_WITH_CGOARROWS', \"\\n\".join(print_cgoarrows))\n",
        "          #print(filedata)\n",
        "          with open('%s/PymolSession_%s_%s.pml'%(Benchmarking_folder, pdbid, i_mode), 'w+') as f:\n",
        "                  f.write(filedata)\n",
        "          shutil.copy(\"./Inching-main/Notebook/Application/cgo_arrow.py\", \"%s/cgo_arrow.py\" %(Benchmarking_folder))\n",
        "          i_mode+=1\n",
        "\n",
        "\n",
        "protein_xyz = protein_xyz_\n",
        "\n",
        "# --- Download the predictions ---\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "\n",
        "import os\n",
        "timestamp = str(time.time()).split(\".\")[0]\n",
        "print('Compressing as zip...')\n",
        "os.system(f\"zip -q -r /content/InchingResult_%s.zip /content/Result/\" %(timestamp))\n",
        "print(\"File size: %s MB\" %(os.path.getsize(\"/content/InchingResult_%s.zip\"%(timestamp))/1024/1024))\n",
        "\n",
        "\n",
        "if save_to_google_drive:\n",
        "\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  #print(\"You are logged into Google Drive and are good to go!\")\n",
        "\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  import shutil\n",
        "\n",
        "  shutil.copy2(\"InchingResult_%s.zip\" %(timestamp),\"/content/gdrive/MyDrive/InchingResult_%s.zip\"%(timestamp))\n",
        "\n",
        "  from subprocess import getoutput\n",
        "  from IPython.display import HTML, display\n",
        "  !apt-get install xattr > /dev/null\n",
        "\n",
        "  #!xattr -p 'user.drive.id' '/content/gdrive/MyDrive/'\n",
        "  # NOTE There can be a time lag to upload to gdrive? We need to listen for finish...\n",
        "\n",
        "\n",
        "  def get_shareable_link(file_path, return_URL = False):\n",
        "    fid = getoutput(\"xattr -p 'user.drive.id' \" + \"'\" + file_path + \"'\")\n",
        "    #print(fid, file_path)\n",
        "    if return_URL:\n",
        "      return HTML(f\"<a href=https://drive.google.com/file/d/{fid} target=_blank>Click HERE to download the InchingResult.zip file from your drive. Enjoy!</a>\")\n",
        "    else:\n",
        "      return fid\n",
        "\n",
        "  print(\"Preparing Google link address...\")\n",
        "  shareable_link = get_shareable_link(\"/content/gdrive/MyDrive/InchingResult_%s.zip\" %(timestamp))\n",
        "  while \"local-\" in shareable_link:\n",
        "    time.sleep(2)\n",
        "    shareable_link = get_shareable_link(\"/content/gdrive/MyDrive/InchingResult_%s.zip\" %(timestamp))\n",
        "    time.sleep(2)\n",
        "  display(get_shareable_link(\"/content/gdrive/MyDrive/InchingResult_%s.zip\" %(timestamp), return_URL = True))\n",
        "  #print(\"/content/gdrive/MyDrive/InchingResult_%s.zip\" %(timestamp))\n",
        "\n",
        "else:\n",
        "  files.download(\"/content/InchingResult_%s.zip\" %(timestamp))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M15Xq0bE8G4e"
      },
      "source": [
        "# Download the source code\n",
        "\n",
        "We will be offering Inching and its associated eigensolvers as an open-source software once the publication is solid. Meanwhile, reviewers can download the zipped source code with a password `AAAAA10115`, but please do not distribute it before publication. Cite us if you find anything useful or inspirational!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8T6PdaO_8HBE",
        "outputId": "ebdbc08a-ae19-4267-deb5-12832716af57"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_7604592a-8352-46be-bfea-5edfabf1d5ab\", \"Inching-main.zip\", 7129333)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "files.download(f'/content/Inching-main.zip')#@markdown Click play button to Download. Remember the password `AAAAA10115`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G47DnqTOsNqF"
      },
      "source": [
        "## FAQ & Troubleshooting\n",
        "\n",
        "\n",
        "\n",
        "*   How long will this take?\n",
        "    *   Downloading the Inching source code can take up to a few minutes.\n",
        "    *   Downloading and installing through Conda can take up to a few minutes.\n",
        "    *   Calculation of modes can take minutes to hours, depending on the length of your protein and on which GPU-type Colab has assigned you.\n",
        "*   My Colab no longer seems to be doing anything, what should I do?\n",
        "    *   Some steps may take minutes to hours to complete.\n",
        "    *   If nothing happens or if you receive an error message, try restarting your Colab runtime via _Runtime_ > _Restart runtime_.\n",
        "    *   If this doesnâ€™t help, try resetting your Colab runtime via _Runtime_ > _Factory reset runtime_.\n",
        "*   How does this compare to a desktop version of Inching?\n",
        "    *   The eigenpair should be within error bound as long as conda did its version control.\n",
        "*   What is a Colab?\n",
        "    *   See the [Colab FAQ](https://research.google.com/colaboratory/faq.html).\n",
        "*   I received a warning â€œNotebook requires high RAMâ€, what do I do?\n",
        "    *   The resources allocated to your Colab vary. See the [Colab FAQ](https://research.google.com/colaboratory/faq.html) for more details.\n",
        "    *   You can execute the Colab nonetheless.\n",
        "*   I received an error â€œColab CPU runtime not supportedâ€ or â€œNo GPU/TPU foundâ€, what do I do?\n",
        "    *   Colab CPU runtime is not supported. Try changing your runtime via _Runtime_ > _Change runtime type_ > _Hardware accelerator_ > _GPU_.\n",
        "    *   The type of GPU allocated to your Colab varies. See the [Colab FAQ](https://research.google.com/colaboratory/faq.html) for more details.\n",
        "    *   If you receive â€œCannot connect to GPU backendâ€, you can try again later to see if Colab allocates you a GPU.\n",
        "    *   [Colab Pro](https://colab.research.google.com/signup) offers priority access to GPUs.\n",
        "*   I received an error â€œModuleNotFoundError: No module named ...â€, even though I ran the cell that imports it, what do I do?\n",
        "    *   Colab notebooks on the free tier time out after a certain amount of time. See the [Colab FAQ](https://research.google.com/colaboratory/faq.html#idle-timeouts). Try rerunning the whole notebook from the beginning.\n",
        "*   Does this tool install anything on my computer?\n",
        "    *   No, everything happens in the cloud on Google Colab.\n",
        "    *   At the end of the Colab execution a zip-archive with the obtained prediction will be automatically downloaded to your computer.\n",
        "*   How should I share feedback and bug reports?\n",
        "    *   Please share any feedback and bug reports as an [issue](https://github.com/jhmlam/Inching/issues) on Github.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
