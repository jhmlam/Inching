{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "272fcXN8FY2S"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jhmlam/Inching/blob/main/GoogleColab/GoogleColab_Inching_v023_ReleaseOkay.ipynb)\n",
        "\n",
        "# Running Inching on Colaboratory\n",
        "\n",
        "In this notebook, we will illustrate how to use Inching to analyse vibration of biological structures on the Google Colaboratory. In general, a Google Colaboratory free user will have access to the following computing resource\n",
        "\n",
        "* CPU. 2-core Intel(R) Xeon(R) @ 2.20GHz Family 6\n",
        "* System RAM. 12.7GB\n",
        "* GPU. Tesla T4, availability depends.\n",
        "* GPU RAM. 15GB memory.\n",
        "\n",
        "To proceed, click the play button on the top left corner of each cell.\n",
        "\n",
        "# Acknowledgement\n",
        "We would like to thank colleagues from [AlphaFold](https://colab.research.google.com/github/deepmind/alphafold/blob/main/notebooks/AlphaFold.ipynb#scrollTo=VzJ5iMjTtoZw) and [ColabFold](https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/beta/AlphaFold2_advanced.ipynb#scrollTo=woIxeCPygt7K) in formalising routines setting up Google Colab projects! Refer to FAQ in the last cell when question arise.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHBZYbHXFuU5"
      },
      "source": [
        "# Install Conda and Dependencies\n",
        "\n",
        "Here we present a version that runs on Google Colaboratory, a tentative service provided by Google for free GPU resources. To run the software with a strictly controlled version, please refer to `Inching-main/Command8A/README_InstallationOnCarc_20230221.sh` for instruction.\n",
        "\n",
        "* Colaboratory weather report 2023-12-27. The following cell will trigger a restart saying crash, but once restarted, click the next cell, everything's okay.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3_wurgiaIwR",
        "outputId": "638b3590-0f32-449b-cb1d-11cf243ed5a1",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting condacolab\n",
            "  Downloading condacolab-0.1.9-py3-none-any.whl (7.2 kB)\n",
            "Installing collected packages: condacolab\n",
            "Successfully installed condacolab-0.1.9\n",
            "â¬ Downloading https://github.com/conda-forge/miniforge/releases/download/23.11.0-0/Mambaforge-23.11.0-0-Linux-x86_64.sh...\n",
            "ðŸ“¦ Installing...\n",
            "ðŸ“Œ Adjusting configuration...\n",
            "ðŸ©¹ Patching environment...\n",
            "â² Done in 0:00:14\n",
            "ðŸ” Restarting kernel...\n"
          ]
        }
      ],
      "source": [
        "import google.colab #@markdown Click the play button!\n",
        "!pip install condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Und9luGB59nm"
      },
      "source": [
        "## INSTRUCTION: After Restart, click each of the following cells ONCE. Follow the instruction of each cell.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6FH5o1Ih8-d"
      },
      "source": [
        "# User Options\n",
        "\n",
        "`User_n_mode = 64` is the number of eigenpairs to be output. `User_EED_ = True` determines whether External Explicit Deflation is to be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZad7i9nh9O1",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "User_n_mode = 32 #@param [32, 64] {type:\"raw\"}\n",
        "User_Eigensolver = \"InchingCTRLM\" #@param [\"InchingJDM\", \"InchingCTRLM\"] {type:\"raw\"}\n",
        "User_EED = True #@param {type:\"boolean\"}\n",
        "User_AnimateMode = 5 #@param [5, 10, 15, 20] {type:\"raw\"}\n",
        "User_IntegerOfIndexing = \"INTEGER32\" # NOTE Indexing. For extremely large system with nnz > 2.1 billion use INTEGER64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raeqczRtOes2"
      },
      "source": [
        "# Upload and Install\n",
        "\n",
        "Upload a pdb/cif file of your choice. Please name it with 4-alphanumerics followed by a suffix, either `.pdb` or `.cif`. For example, `5h2f.pdb`. Also, be reminded that\n",
        "\n",
        "* The default unit of 3-D coordinates in `.pdb` format is angstrom, but for `.cif` format, it is assumed nanometer. For simplicity, the uploaded file will always be renamed as `upload{suffix}`.\n",
        "* By default, we will remove the first 6 rigid modes with zero-eigenvalues by Hotelling deflation. However, if there are disconnected components separate from one another for more than 8 angstrom in the macromolecule, there will be more than 6 rigid modes with zero-eigenvalues! See how to check it quickly in our Notebook `Inching-main/Notebook/Application/99_Inching_CheckConnectivity.ipynb`.\n",
        "\n",
        "# Remark\n",
        "`zip -P AAAAA10115 -r Inching-main.zip ./Inching-main/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e9w88evBMs59",
        "outputId": "ce187360-335c-488e-e2bc-2ebcadea9c8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f235f23d-65c1-4dde-9752-a0b4bbcc62d9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f235f23d-65c1-4dde-9752-a0b4bbcc62d9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-8a2eec50b692>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#@markdown Upload a pdb/cif file of your choice.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0muploaded_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muploaded_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload() #@markdown Upload a pdb/cif file of your choice.\n",
        "uploaded_filename = list(uploaded.keys())[0]\n",
        "print(uploaded_filename)\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "uploaded_suffix = uploaded_filename.split(\".\")[-1]\n",
        "shutil.move(uploaded_filename, \"upload.%s\" %(uploaded_suffix))\n",
        "\n",
        "\n",
        "\n",
        "# NOTE Then we install\n",
        "import condacolab\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "condacolab.check()\n",
        "#!conda install -q -y -c conda-forge -c pytorch scipy=1.8.0 pytorch=1.11.0 pandas=1.5.3 openmm=7.7.0 tqdm cupy=11.5.0 python=3.10\n",
        "#!conda install -q -y -c conda-forge openmm=7.7.0 mdtraj=1.9.7 tqdm python=3.10 cudatoolkit=12.2\n",
        "!conda install -q -y -c conda-forge -c nvidia -c pytorch openmm=7.7.0 mdtraj=1.9.7 tqdm python=3.10 cudatoolkit=11.8.0\n",
        "on_colab = True\n",
        "clear_output()\n",
        "\n",
        "# NOTE Fast steps\n",
        "#!wget https://zenodo.org/records/10443729/files/Inching-main.zip?download=1 -O /content/Inching-main.zip\n",
        "!wget https://zenodo.org/records/10645601/files/jhmlam/Inching-zenodov1.0.zip -O /content/Inching-main.zip\n",
        "#!unzip -P AAAAA10115 -o Inching-main.zip\n",
        "!unzip -o Inching-main.zip\n",
        "!cp -r jhmlam-Inching-933f839/InchingLiteInteger/ .\n",
        "!rm -r Result\n",
        "!mkdir Result\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKCkkUNYRtEZ"
      },
      "source": [
        "# Running the analysis\n",
        "\n",
        "The NVIDIAÂ® T4 is a single-slot, low-profile GPU, but it can still stably deliver analysis for macromolecules containing\n",
        "- [X] 100 thousand atoms, 32 modes in ~5 minutes.\n",
        "- [ ] 200 tounsand atoms, 32 modes in ~10 minutes.\n",
        "\n",
        "\n",
        "Note that the time to read/write/download is discounted and may even be longer than the calculation on Colab(!). For performance computing, please use our code locally at a linux workstation. Follow through the notebooks at `https://github.com/jhmlam/Inching/blob/main/Notebook/Application/`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrG8IzIiRsKu",
        "outputId": "861aa960-4717-4d8f-cb09-cb9a01e73f1e",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:125: UserWarning: Decorating classes is deprecated and will be disabled in future versions. You should only decorate functions or methods. To preserve the current behavior of class decoration, you can directly decorate the `__init__` method and nothing else.\n",
            "  warnings.warn(\"Decorating classes is deprecated and will be disabled in \"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/__init__.py:614: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)\n",
            "  _C._set_default_tensor_type(t)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The GPU is free to use. THere is no existing occupant\n",
            "The GPU is free to use. THere is no existing occupant\n",
            "Reading structure...\n",
            "On Linux\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 152/152 [00:02<00:00, 58.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N_neighbor within 8.0 angstrom Mean 91.66226264728547, Std 23.711226761684024\n",
            "NN search in 2.6058661937713623 s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/151831 [00:10<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start eigsh cupy\n",
            "On Linux\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:00<00:00, 1491826.08it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:06<00:00, 311.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean number of Gaps > 100 is 17.2255859375. Mean Gap Length Given Gap is 549.855802483134\n",
            "Max number of Gaps > 100 is 37. Max Gap Length Given Gap is 5681\n",
            "Median number of Gaps > 100 is 17.0. Median Gap Length Given Gap is 336.0\n",
            "Total Entry Savings 1438796716 which is 80.30246670680903 percent of a Rectangular Batch\n",
            "Nnz in Hessian (L+D) is 63310518.0. This will occupy 0.4666095860302448 GB for (L+D) data and at max 0.4666095860302448 GB for all indexings. Acceptable?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/InchingLiteInteger/Fuel/T1.py:218: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.frontal_gap_offset[i] = torch.tensor(\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2048/2048 [00:41<00:00, 49.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix Index Datatype int32\n",
            "Matrix Datatype (62844725,)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:02<00:00, 133.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done Bound\n",
            "WARNING. Binary search begins with user supplied User_DesignatedStart\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kpm Estiamte Mean 10072.2 Std 167.2703201407829\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 14.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kpm Estiamte Mean 5331.4 Std 132.05695740853642\n",
            "Adjusted degree to 9 and Interval to 1.0,4.364174112664313. Estimate number of eigval is 5332\n",
            "Convergence ratio 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  8.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kpm Estiamte Mean 2311.4 Std 69.93883041630022\n",
            "Adjusted degree to 14 and Interval to 1.0,2.6820870563321564. Estimate number of eigval is 2313\n",
            "Convergence ratio 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00,  6.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kpm Estiamte Mean 960.0 Std 30.364452901377952\n",
            "Adjusted degree to 21 and Interval to 1.0,1.8410435281660782. Estimate number of eigval is 961\n",
            "Convergence ratio 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kpm Estiamte Mean 467.6 Std 21.105449533236673\n",
            "Adjusted degree to 33 and Interval to 1.0,1.420521764083039. Estimate number of eigval is 469\n",
            "Convergence ratio 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kpm Estiamte Mean 255.2 Std 24.194214184387143\n",
            "Adjusted degree to 53 and Interval to 1.0,1.2102608820415195. Estimate number of eigval is 256\n",
            "Convergence ratio 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:03<00:00,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kpm Estiamte Mean 145.8 Std 13.181805642627264\n",
            "Adjusted degree to 84 and Interval to 1.0,1.1051304410207599. Estimate number of eigval is 147\n",
            "Convergence ratio 0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:05<00:00,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kpm Estiamte Mean 78.4 Std 11.909659944767524\n",
            "Adjusted degree to 136 and Interval to 1.0,1.05256522051038. Estimate number of eigval is 79\n",
            "Convergence ratio 0.7\n",
            "136 (1.0, 1.05256522051038)\n",
            "There are 64 Ritz vectors, tol = 1e-12\n",
            "Coarse_iter 0 Estimate at 7.383804768371553e-07. Ritz values follows\n",
            "\n",
            "[  0.87953603   0.87042884   0.85773009   0.85481088   0.81719735\n",
            "   0.80715763   0.8000678    0.75171336   0.73224811   0.72197768\n",
            "   0.72050719   0.70022293   0.67612713   0.64993303   0.62425965\n",
            "   0.58660809   0.58358883   0.55845117   0.53021621   0.49425734\n",
            "   0.48043344   0.47530666   0.44619414   0.41914286   0.40375565\n",
            "   0.38996362   0.37060972   0.35468943   0.33734035   0.32444119\n",
            "   0.31287002   0.28944584   0.19212887   0.1700562    0.1514901\n",
            "   0.20776515   0.20847292   0.17943964   0.16080298 -38.67207979\n",
            "  -0.12934543   0.21978016   0.14034219   0.13692881   0.13176089\n",
            "  -0.13987678 -38.66974258   0.13565679   0.1725776    0.2007276\n",
            "   0.17231042   0.16228474 -14.91233464 -23.95789556   0.14089966\n",
            "   0.15351365   0.12779583   0.14105884   0.13112741 -37.78445465\n",
            "  -1.07477109   0.14709848   0.12150289   0.1119579 ] \n",
            "\n",
            "[ 0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.12059923  0.09132908  0.08406056  0.10802516\n",
            "  0.10356563  0.0911101   0.9787429   3.46422849  0.11453488  0.0847998\n",
            "  0.07103214  0.06984377  0.07908689  3.49829617  0.89816746  0.08450635\n",
            "  0.08944052  0.11555508  0.07605279  0.09768886 19.04005905  0.10400866\n",
            "  0.08184628  0.07407358  0.06273138  0.07961379  0.38547746  6.79416555\n",
            "  0.07769262  0.07524358  0.05214734  0.06949769] \n",
            "\n",
            "Total number of iterations went through 1 in 151.33388090133667 seconds\n",
            "RUNNNTIME 237.2630364894867\n",
            "1.003059110747559 5.577365465724125e-14\n",
            "1.0033162375623954 3.1060118406087576e-14\n",
            "1.0036788912538166 2.2739867864744144e-14\n",
            "1.0037629498972345 5.143558307176334e-14\n",
            "1.004870097332357 5.309421929454891e-14\n",
            "1.0051734610768623 9.75573878527358e-14\n",
            "1.0053897674605388 1.320017202943447e-13\n",
            "1.0069133623724156 7.352960266748904e-14\n",
            "1.0075519983765435 2.369512858305673e-14\n",
            "1.0078952101366203 1.517177376122612e-14\n",
            "1.0079447130646635 3.8361531925661196e-14\n",
            "1.0086371080293608 7.356280337453557e-14\n",
            "1.0094837025135137 6.735323932142428e-14\n",
            "1.010435693837941 5.929555970591945e-14\n",
            "1.0114031833671684 5.791733307412694e-14\n",
            "1.0128894629285785 1.0223308490777575e-13\n",
            "1.013012362903893 3.22605625818934e-14\n",
            "1.0140585751417375 8.236854766892263e-14\n",
            "1.0152858169001056 8.272329890076164e-14\n",
            "1.0169373967636914 4.8312517027707666e-14\n",
            "1.0176013721490498 6.886810306773105e-14\n",
            "1.017852007891699 6.415244073736956e-14\n",
            "1.019323330494404 1.6142178299970258e-13\n",
            "1.020770221889438 7.477665573948533e-14\n",
            "1.0216284310037418 7.001459209200658e-14\n",
            "1.0224189980163203 1.546486919816226e-13\n",
            "1.022968511957202 4.8660236317056867e-14\n",
            "1.023562436149352 1.1307090069078882e-13\n",
            "1.0241484424602443 4.112428444392273e-14\n",
            "1.0246014296725365 1.2323979822793048e-13\n",
            "1.0246989138184137 1.2977332899916061e-13\n",
            "1.0248635322088235 4.535469456830461e-14\n"
          ]
        }
      ],
      "source": [
        "import glob #@markdown Click the play button\n",
        "import platform\n",
        "import cupy as cp\n",
        "import cupyx\n",
        "from cupyx.scipy import sparse as cupysparse\n",
        "# A list of pdb available at different sizes\n",
        "PART00_IO = True\n",
        "if PART00_IO:\n",
        "  pdbavail = [ \"./upload.%s\" %(uploaded_suffix)]\n",
        "  Benchmarking_folder = \"./Result/\"\n",
        "\n",
        "  User_Platform = platform.system() # Windows Darwin Linux\n",
        "\n",
        "  User_rc_Gamma = 8.0\n",
        "  User_maxleafsize = 100\n",
        "\n",
        "  User_tol = 1e-15\n",
        "  User_PlusI = 1.0\n",
        "\n",
        "  if uploaded_suffix == 'cif':\n",
        "    PDBCIF=\"Cif\"\n",
        "  else:\n",
        "    PDBCIF = \"Pdb\"\n",
        "  User_MaxIter = 15000\n",
        "\n",
        "  # JDM Params\n",
        "  User_GapEstimate = 0\n",
        "  User_SolverName = 'gmres'\n",
        "  User_SolverMaxIter = 20\n",
        "  User_EigTolerance = 1e-12\n",
        "\n",
        "PART00_Import = True\n",
        "if PART00_Import:\n",
        "   import os\n",
        "   import gc\n",
        "   import sys\n",
        "   import pickle\n",
        "\n",
        "   import numpy as np\n",
        "   import time\n",
        "   import tqdm\n",
        "\n",
        "   import torch\n",
        "\n",
        "\n",
        "   import platform\n",
        "\n",
        "\n",
        "   import time\n",
        "\n",
        "   import cupy\n",
        "   from cupy import cublas\n",
        "\n",
        "\n",
        "   from scipy.spatial import cKDTree\n",
        "\n",
        "\n",
        "\n",
        "   sys.path.append('.')\n",
        "   sys.path.append('./InchingLiteInteger/Burn/')\n",
        "\n",
        "\n",
        "\n",
        "   import InchingLiteInteger.util\n",
        "   import InchingLiteInteger.Fuel.Coordinate.T1\n",
        "   import InchingLiteInteger.Fuel.Coordinate.T2\n",
        "   import InchingLiteInteger.Burn.Coordinate.T1\n",
        "   import InchingLiteInteger.Burn.Coordinate.T3\n",
        "\n",
        "   from InchingLiteInteger.Fuel.T1 import Xnumpy_SparseCupyMatrixUngappped\n",
        "\n",
        "   import InchingLiteInteger.Burn.Visualisation.T1\n",
        "   import InchingLiteInteger.Burn.Visualisation.T2\n",
        "\n",
        "   # ============================\n",
        "   # Some torch speed up tips\n",
        "   # =============================\n",
        "\n",
        "   # Turn on cuda optimizer\n",
        "   torch.backends.cudnn.is_available()\n",
        "   torch.backends.cudnn.enabled = True\n",
        "   torch.backends.cudnn.benchmark = True\n",
        "   # disable debugs NOTE use only after debugging\n",
        "   torch.autograd.set_detect_anomaly(False)\n",
        "   torch.autograd.profiler.profile(False)\n",
        "   torch.autograd.profiler.emit_nvtx(False)\n",
        "   # Disable gradient tracking\n",
        "   torch.no_grad()\n",
        "   torch.inference_mode()\n",
        "   torch.manual_seed(0)\n",
        "   cupy.random.seed(seed = 0)\n",
        "   os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" # NOTE In case any error showup\n",
        "   # Reset Cuda and Torch\n",
        "   device = torch.device(0)\n",
        "   torch.set_default_dtype(torch.float64)\n",
        "   torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
        "   try:\n",
        "      InchingLiteInteger.util.TorchEmptyCache()\n",
        "   except RuntimeError:\n",
        "      print(\"The GPU is free to use. THere is no existing occupant\")\n",
        "   try:\n",
        "      print(torch.cuda.memory_summary(device = 0, abbreviated=True))\n",
        "   except KeyError:\n",
        "      print(\"The GPU is free to use. THere is no existing occupant\")\n",
        "\n",
        "\n",
        "\n",
        "pdbfn = pdbavail[0]\n",
        "devices_ = [d for d in range(torch.cuda.device_count())]\n",
        "device_names_  = [torch.cuda.get_device_name(d) for d in devices_]\n",
        "User_Device =  device_names_[0]\n",
        "\n",
        "\n",
        "pdbid = pdbfn.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "\n",
        "\n",
        "print(\"Reading structure...\")\n",
        "X_df, X_top = InchingLiteInteger.util.BasicPdbCifLoading(pdbfn)\n",
        "protein_xyz = X_df[['x','y','z']].to_numpy().astype(np.float64)\n",
        "# NOTE PDB format digit decimal do no destroy collinearity!\n",
        "protein_xyz -= np.around(protein_xyz.mean(axis= 0), decimals=4)\n",
        "n_atoms = protein_xyz.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===============================================\n",
        "# K-d Cuthill (NOTE CPU np array)\n",
        "# ===================================\n",
        "PART02_Cuthill = True\n",
        "if PART02_Cuthill:\n",
        "    # NOTE Cuthill Order and Undo\n",
        "    st = time.time()\n",
        "    cuthill_order, cuthill_undoorder = InchingLiteInteger.Fuel.Coordinate.T1.X_KdCuthillMckeeOrder(protein_xyz,\n",
        "                                rc_Gamma = User_rc_Gamma, Reverse = True,\n",
        "                                )\n",
        "    protein_xyz = protein_xyz[cuthill_order,:]\n",
        "    #protein_tree = cKDTree(protein_xyz, leafsize=16, compact_nodes=True, copy_data=False, balanced_tree=True, boxsize=None)\n",
        "\n",
        "\n",
        "    from InchingLiteInteger.Burn.JacobiDavidsonHotellingDeflation.T1 import S_HeigvalJDMHD_HeigvecJDMHD\n",
        "    from InchingLiteInteger.Burn.ThickRestartLanczosHotellingDeflation.T1 import S_HeigvalTRLMHD_HeigvecTRLMHD\n",
        "    from InchingLiteInteger.Burn.ChebyshevDavidsonSubspaceIteration.T1 import S_HeigvalCDSIHD_HeigvecCDSIHD\n",
        "\n",
        "\n",
        "    import InchingLiteInteger.Burn.HermitianLanczos.T2\n",
        "    import InchingLiteInteger.Burn.PolynomialFilters.T0\n",
        "    import InchingLiteInteger.Burn.PolynomialFilters.T2\n",
        "\n",
        "\n",
        "\n",
        "    print('start eigsh cupy')\n",
        "\n",
        "    mempool = cupy.get_default_memory_pool()\n",
        "    pinned_mempool = cupy.get_default_pinned_memory_pool()\n",
        "\n",
        "# ==================\n",
        "# Cupy hessian\n",
        "# =====================\n",
        "\n",
        "\n",
        "PART03a_MakeCupyHessian = True\n",
        "if PART03a_MakeCupyHessian:\n",
        "    # NOTE Nnz neighborhood after cuthill\n",
        "    NnzMinMaxDict, HalfNnz  = InchingLiteInteger.Fuel.Coordinate.T1.X_KdUngappedMinMaxNeighbor(protein_xyz,\n",
        "                                rc_Gamma = User_rc_Gamma,\n",
        "                                maxleafsize = User_maxleafsize,\n",
        "                                CollectStat = False,\n",
        "                                User_ReturnHalfNnz = True,\n",
        "                                SliceForm= True)\n",
        "\n",
        "\n",
        "    # NOTE Pyotch tensor spend textra memory when dlpack has to be called and there are mmeleak\n",
        "    #X = torch.tensor(protein_xyz, device=device, requires_grad= False)\n",
        "    X = protein_xyz\n",
        "\n",
        "    Xnumpy_SparseCupyMatrixUngapppedC = Xnumpy_SparseCupyMatrixUngappped(X, batch_head = None,\n",
        "        maxleafsize = User_maxleafsize, rc_Gamma = User_rc_Gamma,\n",
        "        #device  = torch.device(0),\n",
        "        User_PlusI = User_PlusI,\n",
        "        #dtype_temp = torch.float64,\n",
        "        #X_precision = torch.cuda.DoubleTensor,\n",
        "        User_DictCharmmGuiPbc = None, #Dict_Pbc,\n",
        "        NnzMinMaxDict = NnzMinMaxDict)\n",
        "    if User_IntegerOfIndexing == \"INTEGER32\":\n",
        "        A, A_diag = Xnumpy_SparseCupyMatrixUngapppedC.ReturnCupyHLowerTriangleInt32(\n",
        "                        User_MaxHalfNnzBufferSize = HalfNnz)\n",
        "    else:\n",
        "        #print('gagag')\n",
        "        A, A_diag = Xnumpy_SparseCupyMatrixUngapppedC.ReturnCupyHLowerTriangleInt64(\n",
        "                        User_MaxHalfNnzBufferSize = HalfNnz)\n",
        "\n",
        "    print(\"Matrix Index Datatype\", A.indices.dtype)\n",
        "    print(\"Matrix Datatype\",A.data.shape)\n",
        "\n",
        "    cupy.get_default_memory_pool().free_all_blocks()\n",
        "    cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "PART03b_MakeFreeModes = User_EED\n",
        "if PART03b_MakeFreeModes:\n",
        "\n",
        "    Q_HotellingDeflation = cp.zeros((6,3*n_atoms), dtype = cp.float64)\n",
        "    # NOTE Translation\n",
        "    for i in range(3):\n",
        "        q1 = cp.zeros((n_atoms,3))\n",
        "        q1[:,i] = 1/np.sqrt(n_atoms)\n",
        "        Q_HotellingDeflation[i,:] = q1.flatten()\n",
        "        q1 = None\n",
        "        del q1\n",
        "        cupy.get_default_memory_pool().free_all_blocks()\n",
        "        cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
        "\n",
        "\n",
        "\n",
        "    # NOTE Rotation\n",
        "    R_x = cp.array([        [0,0,0],\n",
        "                            [0,0,-1],\n",
        "                            [0,1,0]], dtype=cp.float64).T\n",
        "    R_y = cp.array([        [0,0,1],\n",
        "                            [0,0,0],\n",
        "                            [-1,0,0]], dtype=cp.float64).T\n",
        "    R_z = cp.array([        [0,-1,0],\n",
        "                            [1,0,0],\n",
        "                            [0,0,0]], dtype=cp.float64).T\n",
        "    R_x = cupysparse.csr_matrix(R_x, dtype= cp.float64)\n",
        "    R_y = cupysparse.csr_matrix(R_y, dtype= cp.float64)\n",
        "    R_z = cupysparse.csr_matrix(R_z, dtype= cp.float64)\n",
        "    gx = (cp.array(X)@R_x).flatten()\n",
        "    Q_HotellingDeflation[3,:] = gx/ cp.linalg.norm(gx,ord=2)\n",
        "    gy = (cp.array(X)@R_y).flatten()\n",
        "    Q_HotellingDeflation[4,:] = gy/ cp.linalg.norm(gy,ord=2)\n",
        "    gz = (cp.array(X)@R_z).flatten()\n",
        "    Q_HotellingDeflation[5,:] = gz/ cp.linalg.norm(gz,ord=2)\n",
        "\n",
        "\n",
        "\n",
        "    for i_FRO in range(2):\n",
        "        V = Q_HotellingDeflation.T\n",
        "\n",
        "        for ix in range(6):\n",
        "            if ix == 0:\n",
        "                continue\n",
        "            V[:,ix] -= cp.matmul(V[:,:ix], cp.matmul( V[:, :ix].T,V[:,ix] ))\n",
        "            V[:,ix] /= cp.sqrt(V[:, ix].T @ V[:, ix]) # TODO torch.matmul or mvs\n",
        "            V[:,ix] -= cp.matmul(V[:,:ix], cp.matmul( V[:, :ix].T,V[:,ix] ))\n",
        "            V[:,ix] /= cp.sqrt(V[:, ix].T @ V[:, ix])\n",
        "        Q_HotellingDeflation = V.T\n",
        "\n",
        "    gx = Q_HotellingDeflation[3]\n",
        "\n",
        "\n",
        "    Q_HotellingDeflation = cupyx.scipy.sparse.csr_matrix(Q_HotellingDeflation, dtype = cp.float64)\n",
        "\n",
        "    gx, gy, gz = None, None, None\n",
        "    del gx, gy, gz\n",
        "    cupy.get_default_memory_pool().free_all_blocks()\n",
        "    cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if User_Eigensolver == \"InchingJDM\":\n",
        "  PART04_CalcualteEigJDM = True\n",
        "else:\n",
        "  PART04_CalcualteEigJDM = False\n",
        "if PART04_CalcualteEigJDM:\n",
        "    if User_EED:\n",
        "\n",
        "        User_GapEstimate = 0 # NOTE Not in use.\n",
        "        eigval, eigvec = S_HeigvalJDMHD_HeigvecJDMHD(A, A_diag,\n",
        "                    k = User_n_mode,\n",
        "                    tol = User_EigTolerance,\n",
        "                    maxiter = User_MaxIter,\n",
        "                    User_CorrectionSolverMaxiter = User_SolverMaxIter,\n",
        "                    User_HalfMemMode= True,\n",
        "                    User_IntermediateConvergenceTol=1e-3, # NOTE Do not touch for this problem\n",
        "                    User_GapEstimate = User_GapEstimate, # NOTE This will be used for theta - gap_estimate\n",
        "                    User_FactoringToleranceOnCorrection = 1e-4, # NOTE Do not touch for this problem\n",
        "                    User_Q_HotellingDeflation= Q_HotellingDeflation,\n",
        "                    User_HotellingShift = 40, # NOTE 40 is generally safe for first 64 modes, of course if you want to guarentee it you know a norm\n",
        "\n",
        "                    )\n",
        "    else:\n",
        "\n",
        "        User_GapEstimate = 0 # NOTE Not in use.\n",
        "        eigval, eigvec = S_HeigvalJDMHD_HeigvecJDMHD(A, A_diag,\n",
        "                    k = User_n_mode,\n",
        "                    tol = User_EigTolerance,\n",
        "                    maxiter = User_MaxIter,\n",
        "                    User_CorrectionSolverMaxiter = User_SolverMaxIter,\n",
        "                    User_HalfMemMode= True,\n",
        "                    User_IntermediateConvergenceTol=1e-3, # NOTE Do not touch for this problem\n",
        "                    User_GapEstimate = User_GapEstimate, # NOTE This will be used for theta - gap_estimate\n",
        "                    User_FactoringToleranceOnCorrection = 1e-4, # NOTE Do not touch for this problem\n",
        "                    User_Q_HotellingDeflation= None,\n",
        "                    User_HotellingShift = 40, # NOTE 40 is generally safe for first 64 modes, of course if you want to guarentee it you know a norm\n",
        "\n",
        "                    )\n",
        "\n",
        "\n",
        "\n",
        "    runtime = time.time() - st\n",
        "    print(\"RUNNNTIME %s\" %(runtime))\n",
        "    peak_mem = cupy.get_default_memory_pool().used_bytes() / 1024 / 1024\n",
        "\n",
        "\n",
        "    runtime = time.time() - st\n",
        "    peak_mem = cupy.get_default_memory_pool().used_bytes() / 1024 / 1024\n",
        "    with open(\"%s/Eigval_InchingJDM_%s_%s_%s.pkl\" %(\n",
        "                Benchmarking_folder, pdbid, User_Platform,\n",
        "                User_Device.replace(\" \",\"\")),\"wb\") as fn:\n",
        "        pickle.dump(cupy.asnumpy(eigval) - User_PlusI ,fn, protocol=4)\n",
        "\n",
        "    with open(\"%s/Eigvec_InchingJDM_%s_%s_%s.pkl\" %(\n",
        "                Benchmarking_folder, pdbid, User_Platform,\n",
        "                User_Device.replace(\" \",\"\")),\"wb\") as fn:\n",
        "        tempeigvec = cupy.asnumpy(eigvec)\n",
        "        tempeigvec = tempeigvec.T\n",
        "        tempeigvec = tempeigvec.reshape((int(User_n_mode),int(n_atoms),int(3)))\n",
        "        pickle.dump(tempeigvec[:,cuthill_undoorder,:] ,fn, protocol=4)\n",
        "\n",
        "\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "if User_Eigensolver == \"InchingCTRLM\":\n",
        "  PART04_CalcualteEigCTRLM = True\n",
        "else:\n",
        "  PART04_CalcualteEigCTRLM = False\n",
        "\n",
        "if PART04_CalcualteEigCTRLM:\n",
        "    User_WantedNumberEigenvalue = User_n_mode\n",
        "    User_SpectrumBound = InchingLiteInteger.Burn.HermitianLanczos.T2.A_Adiag_EstimateSpectrumBound(\n",
        "                            A, A_diag, User_HalfMemMode = True )\n",
        "    #RitzValues = User_SpectrumBound[2]\n",
        "    #print(User_SpectrumBound)\n",
        "    #print(float(np.quantile(RitzValues,0.025)))\n",
        "    User_SpectrumBound = (User_SpectrumBound[0], User_SpectrumBound[1])\n",
        "    User_SpectrumBound = (User_PlusI, User_SpectrumBound[1].get()+1e-12)\n",
        "\n",
        "\n",
        "    User_WantedInterval_ = (1.0, User_SpectrumBound[1]/10)\n",
        "    User_WantedInterval = User_WantedInterval_\n",
        "    # NOTE For the extremal it is empirically unwise to squeeze too hard as many of\n",
        "    #      these eigenvalues are close to 0+1 and the mapped function is in steep decline (with very deep caution here.)\n",
        "    #      I would delibrately make the wanted nubmer of eigval larger, because anyhow the lowest will be the first to converge in this scenairo\n",
        "    User_PolynomialParams, eigval_count_estimate, temp_User_WantedInterval = InchingLiteInteger.Burn.PolynomialFilters.T2.A_Adiag_OptimizePolynomialParamsOnMemory(\n",
        "                                                    A, A_diag,\n",
        "                                                    User_MaximumDegree = 5120,\n",
        "                                                    User_MinimumDegree = 5,\n",
        "                                                    User_DampingKernel = \"Jackson\",\n",
        "                                                    User_ExtremalIntervalDefinition = 1e-10,\n",
        "                                                    User_WantedInterval = User_WantedInterval,\n",
        "                                                    User_SpectrumBound = User_SpectrumBound,\n",
        "                                                    User_DesignatedStart = User_SpectrumBound[1]/10,\n",
        "                                                    # NOTE Make this a underestimate of the actual number.\n",
        "                                                    #      While we will have repeated modes, the risk of having a repeated mode is outweighed by risk of non-convergence!\n",
        "                                                    #\n",
        "                                                    User_WantedNumberEigenvalue = int(User_WantedNumberEigenvalue-5)*3,\n",
        "                                                    User_AffordableMemoryMargin = 5*5,\n",
        "                                                    User_HalfMemMode = True,\n",
        "                                                    User_NumberKpmTrials =  5,\n",
        "                                                    User_ConvergenceRatio = 0.7, # NOTE For extremal this is overrided with 0.1\n",
        "                                                    )\n",
        "    User_WantedInterval = (temp_User_WantedInterval[0], temp_User_WantedInterval[1])\n",
        "    print(User_PolynomialParams.AdjustedDegree, temp_User_WantedInterval)\n",
        "\n",
        "    User_Q_HotellingDeflation_ = Q_HotellingDeflation\n",
        "    eigval, eigvec = S_HeigvalTRLMHD_HeigvecTRLMHD(A, A_diag,\n",
        "\n",
        "\n",
        "                        User_WorkspaceSizeFactor = 2 ,\n",
        "                        k = User_n_mode ,\n",
        "                        tol = User_EigTolerance,\n",
        "                        maxiter = User_MaxIter,\n",
        "                        #User_CorrectionSolverMaxiter = User_SolverMaxIter,\n",
        "                        User_HalfMemMode= True,\n",
        "                        #User_IntermediateConvergenceTol=1e-3, # NOTE Do not touch for this problem\n",
        "                        #User_GapEstimate = User_GapEstimate, # NOTE This will be used for theta - gap_estimate\n",
        "                        #User_FactoringToleranceOnCorrection = 1e-4,#1e-4, # NOTE Do not touch for this problem\n",
        "\n",
        "                        User_Q_HotellingDeflation = User_Q_HotellingDeflation_, #Q_HotellingDeflation,\n",
        "                        User_HotellingShift = -40.0,# NOTE pull to negative, we are on cheb\n",
        "\n",
        "                        User_PolynomialParams = User_PolynomialParams,\n",
        "                        )\n",
        "\n",
        "\n",
        "\n",
        "    runtime = time.time() - st\n",
        "    print(\"RUNNNTIME %s\" %(runtime))\n",
        "    peak_mem = cupy.get_default_memory_pool().used_bytes() / 1024 / 1024\n",
        "\n",
        "\n",
        "    runtime = time.time() - st\n",
        "    peak_mem = cupy.get_default_memory_pool().used_bytes() / 1024 / 1024\n",
        "    with open(\"%s/Eigval_InchingJDM_%s_%s_%s.pkl\" %(\n",
        "                Benchmarking_folder, pdbid, User_Platform,\n",
        "                User_Device.replace(\" \",\"\")),\"wb\") as fn:\n",
        "        pickle.dump(cupy.asnumpy(eigval) - User_PlusI ,fn, protocol=4)\n",
        "\n",
        "    with open(\"%s/Eigvec_InchingJDM_%s_%s_%s.pkl\" %(\n",
        "                Benchmarking_folder, pdbid, User_Platform,\n",
        "                User_Device.replace(\" \",\"\")),\"wb\") as fn:\n",
        "        tempeigvec = cupy.asnumpy(eigvec)\n",
        "        tempeigvec = tempeigvec.T\n",
        "        tempeigvec = tempeigvec.reshape((int(User_n_mode),int(n_atoms),int(3)))\n",
        "        pickle.dump(tempeigvec[:,cuthill_undoorder,:] ,fn, protocol=4)\n",
        "\n",
        "\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "PART05_Performance = True\n",
        "if PART05_Performance:\n",
        "    #===================================\n",
        "    # Check correct\n",
        "    # =====================================\n",
        "    #print(eigval)\n",
        "    #print(eigvec.shape)\n",
        "\n",
        "    User_HalfMemMode = True\n",
        "    if User_HalfMemMode:\n",
        "        KrylovAv = InchingLiteInteger.Burn.Krylov.T3.OOC2_HalfMemS_v_KrylovAv_VOID(A, A_diag)\n",
        "    else:\n",
        "        KrylovAv = InchingLiteInteger.Burn.Krylov.T3.OOC2_FullMemS_v_KrylovAv_VOID(A, A_diag)\n",
        "    Av = cupy.empty((n_atoms*3,)).astype(A.dtype)\n",
        "\n",
        "\n",
        "    delta_lambda_list = []\n",
        "    for jj in range(User_n_mode):\n",
        "        KrylovAv(A,cupy.ravel(eigvec[:,jj]),Av)\n",
        "        B = Av - eigval[jj]* cupy.ravel(eigvec[:,jj])\n",
        "\n",
        "        delta_lambda_list.append(cupy.asnumpy(cublas.nrm2(B)))\n",
        "        #if jj < 20:\n",
        "        print(eigval[jj], cupy.asnumpy(cublas.nrm2(B)))\n",
        "\n",
        "\n",
        "    eigval = cupy.asnumpy(eigval)\n",
        "    n_atoms = protein_xyz.shape[0]\n",
        "\n",
        "    GPU = \"%s %s\" %(User_Platform, User_Device.replace(\" GPU\", \"\"))\n",
        "\n",
        "    performance = [\"Inching (JDM %s)\" %(GPU), pdbfn, n_atoms,\n",
        "                    runtime, peak_mem,\n",
        "                    User_Platform, User_Device,\n",
        "                    User_maxleafsize]\n",
        "\n",
        "\n",
        "\n",
        "    longperformance = []\n",
        "    for i in range(len(delta_lambda_list)):\n",
        "        longperformance.append(performance + [i ,delta_lambda_list[i], eigval[i] - User_PlusI])\n",
        "\n",
        "    with open(\"%s/PerformanceList_InchingJDM_%s_%s_%s.pkl\" %(Benchmarking_folder,\n",
        "        pdbid, User_Platform, User_Device.replace(\" \",\"\")),\"wb\") as fn:\n",
        "        pickle.dump(longperformance,fn, protocol=4)\n",
        "\n",
        "\n",
        "    #del X_df#, protein_xyz\n",
        "    #gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "    B = None\n",
        "    A.data = None\n",
        "    A.indices = None\n",
        "    A.indptr = None\n",
        "    Q_HotellingDeflation = None\n",
        "    del Q_HotellingDeflation\n",
        "\n",
        "    del A.data, A.indices, A.indptr\n",
        "    del A, B\n",
        "    Xnumpy_SparseCupyMatrixUngapppedC.X, Xnumpy_SparseCupyMatrixUngapppedC.X_unsqueezed = None, None\n",
        "    del Xnumpy_SparseCupyMatrixUngapppedC.X, Xnumpy_SparseCupyMatrixUngapppedC.X_unsqueezed\n",
        "    Xnumpy_SparseCupyMatrixUngapppedC = None\n",
        "    del Xnumpy_SparseCupyMatrixUngapppedC\n",
        "    eigvec, eigval = None, None\n",
        "    del eigvec, eigval\n",
        "\n",
        "\n",
        "    cupy.get_default_memory_pool().free_all_blocks()\n",
        "    cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
        "    del X\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats(0)\n",
        "    torch.cuda.memory_allocated(0)\n",
        "    torch.cuda.max_memory_allocated(0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOYGTv8-Dycs"
      },
      "source": [
        "## Generate Animation and Download\n",
        "\n",
        "This writes the linearized motion as a `cif` file for each mode. Unfortunately, the I/O can often take much longer than the calculation itself. After downloading the `InchingResult.zip`, decompress it, open the cif file in pymol and load the corresponding `.pml` script. Enjoy!\n",
        "\n",
        "* By default, the `save_to_google_drive` check box is activated; it will ask for your permission to upload the result to your google drive. If `save_to_google_drive` check box is deactivated, you can directly download the file, but it can take very long.\n",
        "* To indicate the mode shape, for each mode, a black arrow is placed on 10000 randomly chosen atoms with top 50% of diplacement magnitude. Thickness of the arrow can be tuned by checking `User_ThickerArrowForDisplay`. It is suggested to use thicker arrows for structures with >100 thousand atoms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "8Nq_DUjXBrtm",
        "outputId": "4995c3c7-6d12-4ca6-cf6d-aff0e43f1f3c",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Printing animations...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 56.12it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 41.05it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 56.41it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 52.21it/s]\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:00<00:00, 52.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compressing as zip...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:pydrive is deprecated and no longer maintained. We recommend that you migrate your projects to pydrive2, the maintained fork of pydrive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size: 231.99533081054688 MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
            "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
            "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "Preparing Google link address...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<a href=https://drive.google.com/file/d/1fiOu_ZwTY3PDSEWwby8VRMuI6YelaETV target=_blank>Click HERE to download the InchingResult.zip file from your drive. Enjoy!</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "save_to_google_drive = True #@param {type:\"boolean\"}\n",
        "User_ThickerArrowForDisplay = True #@param {type:\"boolean\"}\n",
        "# =======================\n",
        "# Linearize\n",
        "# ==========================\n",
        "pdbfn = pdbavail[0]#@markdown The zip file will be downloaded as `InchingResult_{time}.zip`. Size is printed below\n",
        "\n",
        "User_QuantileDisplay = 0.5\n",
        "User_RandomPickArrows = 10000\n",
        "User_EigenvectorTwinDirection = 1\n",
        "\n",
        "User_BigClusterArrowFloatingFactor = 0.5\n",
        "User_DBscanMinDist = 1.5 # NOTE THis roughly cluster the 90% percentile arrows. largerr the less arrows\n",
        "\n",
        "print(\"Printing animations...\")\n",
        "import sklearn.cluster\n",
        "from InchingLiteInteger.Fuel.Coordinate.T1 import HeigvecOne_BoxCoxMagnitude\n",
        "protein_xyz_ = protein_xyz\n",
        "PART06_Animate = True\n",
        "if PART06_Animate:\n",
        "    eigvec = tempeigvec[:,cuthill_undoorder,:]\n",
        "    protein_xyz = protein_xyz[cuthill_undoorder,:]\n",
        "    if User_EED:\n",
        "      pass\n",
        "    else:\n",
        "      User_AnimateMode +=6\n",
        "\n",
        "    i_mode = 0\n",
        "    for User_TheModeToShow in range(User_AnimateMode):\n",
        "\n",
        "        if User_EED:\n",
        "          pass\n",
        "        else:\n",
        "          if User_TheModeToShow <=5:\n",
        "              continue\n",
        "\n",
        "        if pdbfn.split(\".\")[-1] == 'pdb':\n",
        "            nmfactor = 0.1\n",
        "        else:\n",
        "            nmfactor = 1\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "        PART06b_Logistic = True\n",
        "        if PART06b_Logistic:\n",
        "\n",
        "            #if os.path.exists(\"%s/%s_Animated_%s_%s.cif\" %(Benchmarking_folder, pdbid, pdbid, i_mode)):\n",
        "            #    continue\n",
        "\n",
        "            # NOTE Kerneled eigvec\n",
        "            deltaX_magnitude = HeigvecOne_BoxCoxMagnitude( eigvec[User_TheModeToShow,:,:],\n",
        "                    User_WinsorizingWindow = (0.025, 0.975),\n",
        "                    User_LogisticParam = (0.05, 1.0),\n",
        "                    )\n",
        "\n",
        "            deltaX_magnitude = np.clip(deltaX_magnitude, 0.1, 1.0)\n",
        "            eigvec_unit = eigvec[User_TheModeToShow] / np.linalg.norm(eigvec[User_TheModeToShow], axis=1)[:,None]\n",
        "            deltaX = deltaX_magnitude[:,None] * eigvec_unit\n",
        "\n",
        "\n",
        "            InchingLiteInteger.util.SaveOneModeLinearisedAnime(\n",
        "                    deltaX,\n",
        "                    protein_xyz*nmfactor,\n",
        "                    n_timestep = 16,\n",
        "                    DIR_ReferenceStructure = pdbfn,#[:-4] + \"trial.cif\",\n",
        "                    DIR_SaveFolder = Benchmarking_folder,\n",
        "                    SaveFormat = 'cif',\n",
        "                    outputlabel = 'Animated_%s_%s'%(pdbid, i_mode),\n",
        "                    max_abs_deviation = 3.0*nmfactor,\n",
        "                    stepsize = 1.0*nmfactor,\n",
        "                    UnitMovement = False,\n",
        "                    max_n_output = 32,\n",
        "                    SaveSeparate = False,\n",
        "                    RemoveOrig = False, # NOTE This flag remove the unmoved structure from the trajectory produce\n",
        "                    User_Bfactor=deltaX_magnitude\n",
        "                    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        PART06c_Arrows = True\n",
        "        if PART06c_Arrows:\n",
        "          PART02_DecideWhatArrowsToPlot = True\n",
        "          if PART02_DecideWhatArrowsToPlot:\n",
        "              where_CaOrP = X_df.loc[X_df['name'].isin([\"CA\", \"P\"]) & ~X_df['element'].isin([\"Ca\"])].index.values\n",
        "              where_larger = np.where((deltaX_magnitude > np.quantile(deltaX_magnitude, q = User_QuantileDisplay)))[0]\n",
        "              # a ball with large displacement TODO Show the stacked detail\n",
        "              where_larger_CaOrP = np.intersect1d(where_larger, where_CaOrP, assume_unique=False, return_indices=False)\n",
        "              where_random = np.random.choice(where_larger_CaOrP,\n",
        "                                                  size= min(User_RandomPickArrows, where_larger_CaOrP.shape[0]), replace = False)\n",
        "\n",
        "              # TODO Make  a big arrow for those large ones only! Cluster the coordinate by dbscan.\n",
        "              #      average the arrow put it in center and floating in air.\n",
        "              #      Make the arrow obvious enough to indicate the direction.\n",
        "              where_CaOrP_subset = where_CaOrP[::max(1, int(protein_xyz.shape[0]/User_RandomPickArrows))]\n",
        "\n",
        "\n",
        "              # ======================\n",
        "              # Big Arrow\n",
        "              # =========================\n",
        "\n",
        "              clustering = sklearn.cluster.DBSCAN(eps=User_DBscanMinDist, min_samples=10, metric='euclidean',\n",
        "                                                  metric_params=None, algorithm='kd_tree',\n",
        "                                                  leaf_size=100, p=2, n_jobs=1).fit(protein_xyz[where_larger_CaOrP,:])\n",
        "              unique_clusters = np.unique(clustering.labels_)\n",
        "              DBSCAN_Coord = np.zeros((unique_clusters.shape[0],3))\n",
        "              DBSCAN_UnitEigvec = np.zeros((unique_clusters.shape[0],3))\n",
        "              DBSCAN_UnitEigvecmag = np.zeros((unique_clusters.shape[0],1))\n",
        "              for i_cluster in unique_clusters:\n",
        "                  if i_cluster == -1:\n",
        "                      continue\n",
        "                  same_cluster = where_larger_CaOrP[np.where(clustering.labels_ == i_cluster)[0]]\n",
        "                  DBSCAN_Coord[i_cluster,:] = np.mean(protein_xyz[same_cluster,:], axis=0)\n",
        "                  DBSCAN_UnitEigvec[i_cluster,:] = np.mean(eigvec_unit[same_cluster,:], axis=0)\n",
        "                  DBSCAN_UnitEigvecmag[i_cluster,:] = np.mean(deltaX_magnitude[same_cluster])\n",
        "\n",
        "          #print(\"dbscan done\")\n",
        "          # ========================\n",
        "          # Print arrwo\n",
        "          # ==========================\n",
        "          PART03_PrintCgoArrows = True\n",
        "          if PART03_PrintCgoArrows:\n",
        "              # NOTE Pymol...\n",
        "              if pdbfn.split(\".\")[-1] == 'pdb':\n",
        "                  nmfactor_ = 10.0\n",
        "              else:\n",
        "                  nmfactor_ = 10.0\n",
        "\n",
        "\n",
        "              #print(deltaX_magnitude)\n",
        "              percentilescore_all =  np.argsort(np.argsort(deltaX_magnitude, axis=0), axis=0) / float(len(deltaX_magnitude)) # NOTE Assumed that each has a unique float\n",
        "              print_cgoarrows = []\n",
        "\n",
        "              # =================================\n",
        "              # NOTE THe Big Clustered Arrow\n",
        "              # ==================================\n",
        "              \"\"\"\n",
        "              for i_cluster in range(unique_clusters.shape[0]):\n",
        "\n",
        "                  # NOTE Point to point\n",
        "                  position_source = DBSCAN_Coord[i_cluster] * nmfactor_\n",
        "                  direction_size = 99 * DBSCAN_UnitEigvecmag[i_cluster]\n",
        "                  direction_= (User_EigenvectorTwinDirection * DBSCAN_UnitEigvec[i_cluster] *direction_size) #* deltaX_magnitude[atomindex_]*50)\n",
        "                  gap = direction_* User_BigClusterArrowFloatingFactor\n",
        "\n",
        "                  position_source += gap\n",
        "                  #position_source += direction_*User_BigClusterArrowFloatingFactor\n",
        "                  position_target = position_source + direction_\n",
        "\n",
        "                  x_s, y_s, z_s = position_source[0], position_source[1], position_source[2]\n",
        "                  x_t, y_t, z_t = position_target[0], position_target[1], position_target[2]\n",
        "                  thickness_ = 5 # percentilescore_all[atomindex_]\n",
        "                  print_cgoarrows.append(\"cgo_arrow [%.3f, %.3f, %.3f], [%.3f, %.3f, %.3f] \" %(\n",
        "                      x_s, y_s, z_s, x_t, y_t, z_t) + ', name = \\\"' + \"ClusterArrow%s\" %(i_cluster+1)+'\\\",' + \" radius = %s, hradius = %s, hlength = %s, \" %(thickness_, thickness_*2, direction_size[0]/2 ) + ' color = hotpink')\n",
        "                      # hotpink black\n",
        "              \"\"\"\n",
        "              # ===========================\n",
        "              # NOTE every n CA\n",
        "              # ==============================\n",
        "              choice_where =  where_random # where_CaOrP_subset\n",
        "              for i_whererand in range(len(choice_where)):\n",
        "                  atomindex_ = choice_where[i_whererand]\n",
        "                  # NOTE Point to point\n",
        "                  position_source = protein_xyz[atomindex_]*nmfactor_\n",
        "                  direction_= (eigvec_unit[atomindex_] * User_EigenvectorTwinDirection *25 * deltaX_magnitude[atomindex_]) #* deltaX_magnitude[atomindex_]*50)\n",
        "                  position_target = position_source + direction_\n",
        "\n",
        "                  x_s, y_s, z_s = position_source[0], position_source[1], position_source[2]\n",
        "                  x_t, y_t, z_t = position_target[0], position_target[1], position_target[2]\n",
        "                  if User_ThickerArrowForDisplay:\n",
        "                    thickness_ = 0.5\n",
        "                  else:\n",
        "                    thickness_ = 0.1 # percentilescore_all[atomindex_]\n",
        "                  print_cgoarrows.append(\"cgo_arrow [%.3f, %.3f, %.3f], [%.3f, %.3f, %.3f] \" %(\n",
        "                      x_s, y_s, z_s, x_t, y_t, z_t) + ', name = \\\"' + \"Index%s\" %(atomindex_+1)+'\\\",' + \" radius = %s, hradius = %s, hlength = 10.23, \" %(thickness_*1, thickness_ * 4) + ' color = black')\n",
        "                      # hotpink black\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          with open('./jhmlam-Inching-933f839/Notebook/Application/ArrowTemplate.pml', 'r') as f :\n",
        "                  filedata = f.read()\n",
        "\n",
        "          filedata = filedata.replace('REPLACE_WITH_FILENAME', \"%s/%s_Animated_%s_%s.cif\" %(\"./\", pdbid, pdbid, i_mode))\n",
        "          filedata = filedata.replace('REPLACE_WITH_ID', '%s' %(pdbid))\n",
        "          filedata = filedata.replace('REPLACE_WITH_CGOARROWS', \"\\n\".join(print_cgoarrows))\n",
        "          #print(filedata)\n",
        "          with open('%s/PymolSession_%s_%s.pml'%(Benchmarking_folder, pdbid, i_mode), 'w+') as f:\n",
        "                  f.write(filedata)\n",
        "          shutil.copy(\"./jhmlam-Inching-933f839/Notebook/Application/cgo_arrow.py\", \"%s/cgo_arrow.py\" %(Benchmarking_folder))\n",
        "          i_mode+=1\n",
        "\n",
        "\n",
        "protein_xyz = protein_xyz_\n",
        "\n",
        "# --- Download the predictions ---\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "\n",
        "import os\n",
        "timestamp = str(time.time()).split(\".\")[0]\n",
        "print('Compressing as zip...')\n",
        "os.system(f\"zip -q -r /content/InchingResult_%s.zip /content/Result/\" %(timestamp))\n",
        "print(\"File size: %s MB\" %(os.path.getsize(\"/content/InchingResult_%s.zip\"%(timestamp))/1024/1024))\n",
        "\n",
        "\n",
        "if save_to_google_drive:\n",
        "\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  #print(\"You are logged into Google Drive and are good to go!\")\n",
        "\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  import shutil\n",
        "\n",
        "  shutil.copy2(\"InchingResult_%s.zip\" %(timestamp),\"/content/gdrive/MyDrive/InchingResult_%s.zip\"%(timestamp))\n",
        "\n",
        "  from subprocess import getoutput\n",
        "  from IPython.display import HTML, display\n",
        "  !apt-get install xattr > /dev/null\n",
        "\n",
        "  #!xattr -p 'user.drive.id' '/content/gdrive/MyDrive/'\n",
        "  # NOTE There can be a time lag to upload to gdrive? We need to listen for finish...\n",
        "\n",
        "\n",
        "  def get_shareable_link(file_path, return_URL = False):\n",
        "    fid = getoutput(\"xattr -p 'user.drive.id' \" + \"'\" + file_path + \"'\")\n",
        "    #print(fid, file_path)\n",
        "    if return_URL:\n",
        "      return HTML(f\"<a href=https://drive.google.com/file/d/{fid} target=_blank>Click HERE to download the InchingResult.zip file from your drive. Enjoy!</a>\")\n",
        "    else:\n",
        "      return fid\n",
        "\n",
        "  print(\"Preparing Google link address...\")\n",
        "  shareable_link = get_shareable_link(\"/content/gdrive/MyDrive/InchingResult_%s.zip\" %(timestamp))\n",
        "  while \"local-\" in shareable_link:\n",
        "    time.sleep(2)\n",
        "    shareable_link = get_shareable_link(\"/content/gdrive/MyDrive/InchingResult_%s.zip\" %(timestamp))\n",
        "    time.sleep(2)\n",
        "  display(get_shareable_link(\"/content/gdrive/MyDrive/InchingResult_%s.zip\" %(timestamp), return_URL = True))\n",
        "  #print(\"/content/gdrive/MyDrive/InchingResult_%s.zip\" %(timestamp))\n",
        "\n",
        "else:\n",
        "  files.download(\"/content/InchingResult_%s.zip\" %(timestamp))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M15Xq0bE8G4e"
      },
      "source": [
        "# Download the source code\n",
        "\n",
        "We will be offering Inching and its associated eigensolvers as an open-source software once the publication is solid. Meanwhile, reviewers can download the zipped source code with a password `AAAAA10115`, but please do not distribute it before publication. Cite us if you find anything useful or inspirational!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8T6PdaO_8HBE",
        "outputId": "ebdbc08a-ae19-4267-deb5-12832716af57"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_7604592a-8352-46be-bfea-5edfabf1d5ab\", \"Inching-main.zip\", 7129333)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "files.download(f'/content/Inching-main.zip')#@markdown Click play button to Download. Remember the password `AAAAA10115`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G47DnqTOsNqF"
      },
      "source": [
        "## FAQ & Troubleshooting\n",
        "\n",
        "\n",
        "\n",
        "*   How long will this take?\n",
        "    *   Downloading the Inching source code can take up to a few minutes.\n",
        "    *   Downloading and installing through Conda can take up to a few minutes.\n",
        "    *   Calculation of modes can take minutes to hours, depending on the length of your protein and on which GPU-type Colab has assigned you.\n",
        "*   My Colab no longer seems to be doing anything, what should I do?\n",
        "    *   Some steps may take minutes to hours to complete.\n",
        "    *   If nothing happens or if you receive an error message, try restarting your Colab runtime via _Runtime_ > _Restart runtime_.\n",
        "    *   If this doesnâ€™t help, try resetting your Colab runtime via _Runtime_ > _Factory reset runtime_.\n",
        "*   How does this compare to a desktop version of Inching?\n",
        "    *   The eigenpair should be within error bound as long as conda did its version control.\n",
        "*   What is a Colab?\n",
        "    *   See the [Colab FAQ](https://research.google.com/colaboratory/faq.html).\n",
        "*   I received a warning â€œNotebook requires high RAMâ€, what do I do?\n",
        "    *   The resources allocated to your Colab vary. See the [Colab FAQ](https://research.google.com/colaboratory/faq.html) for more details.\n",
        "    *   You can execute the Colab nonetheless.\n",
        "*   I received an error â€œColab CPU runtime not supportedâ€ or â€œNo GPU/TPU foundâ€, what do I do?\n",
        "    *   Colab CPU runtime is not supported. Try changing your runtime via _Runtime_ > _Change runtime type_ > _Hardware accelerator_ > _GPU_.\n",
        "    *   The type of GPU allocated to your Colab varies. See the [Colab FAQ](https://research.google.com/colaboratory/faq.html) for more details.\n",
        "    *   If you receive â€œCannot connect to GPU backendâ€, you can try again later to see if Colab allocates you a GPU.\n",
        "    *   [Colab Pro](https://colab.research.google.com/signup) offers priority access to GPUs.\n",
        "*   I received an error â€œModuleNotFoundError: No module named ...â€, even though I ran the cell that imports it, what do I do?\n",
        "    *   Colab notebooks on the free tier time out after a certain amount of time. See the [Colab FAQ](https://research.google.com/colaboratory/faq.html#idle-timeouts). Try rerunning the whole notebook from the beginning.\n",
        "*   Does this tool install anything on my computer?\n",
        "    *   No, everything happens in the cloud on Google Colab.\n",
        "    *   At the end of the Colab execution a zip-archive with the obtained prediction will be automatically downloaded to your computer.\n",
        "*   How should I share feedback and bug reports?\n",
        "    *   Please share any feedback and bug reports as an [issue](https://github.com/jhmlam/Inching/issues) on Github.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}