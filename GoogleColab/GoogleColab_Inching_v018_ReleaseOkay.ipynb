{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "272fcXN8FY2S"
      },
      "source": [
        "# Running Inching on Colaboratory\n",
        "\n",
        "In this notebook, we will illustrate how to use Inching to analyse vibration of biological structures on the Google Colaboratory. In general, a Google Colaboratory free user will have access to the following computing resource\n",
        "\n",
        "* CPU. 2-core Intel(R) Xeon(R) @ 2.20GHz Family 6\n",
        "* System RAM. 12.7GB\n",
        "* GPU. Tesla T4, availability depends.\n",
        "* GPU RAM. 15GB memory.\n",
        "\n",
        "To proceed, click the play button on the top left corner of each cell.\n",
        "\n",
        "# Acknowledgement\n",
        "We would like to thank colleagues from [AlphaFold](https://colab.research.google.com/github/deepmind/alphafold/blob/main/notebooks/AlphaFold.ipynb#scrollTo=VzJ5iMjTtoZw) and [ColabFold](https://colab.research.google.com/github/sokrypton/ColabFold/blob/main/beta/AlphaFold2_advanced.ipynb#scrollTo=woIxeCPygt7K) in formalising routines setting up Google Colab projects! Refer to FAQ in the last cell when question arise.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHBZYbHXFuU5"
      },
      "source": [
        "# Install Conda and Dependencies\n",
        "\n",
        "Here we present a version that runs on Google Colaboratory, a tentative service provided by Google for free GPU resources. To run the software with a strictly controlled version, please refer to `Inching-main/Command8A/README_InstallationOnCarc_20230221.sh` for instruction.\n",
        "\n",
        "* Colaboratory weather report 2023-12-27. The following cell will trigger a restart saying crash, but once restarted, click the next cell, everything's okay.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3_wurgiaIwR",
        "outputId": "e28bce32-d3bb-4d57-ecbc-849aa2509788"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: condacolab in /usr/local/lib/python3.10/site-packages (0.1.7)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m✨🍰✨ Everything looks OK!\n"
          ]
        }
      ],
      "source": [
        "import google.colab #@markdown Click the play button!\n",
        "!pip install condacolab\n",
        "import condacolab\n",
        "condacolab.install()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Und9luGB59nm"
      },
      "source": [
        "## INSTRUCTION: After Restart, click each of the following cells ONCE. Follow the instruction of each cell.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6FH5o1Ih8-d"
      },
      "source": [
        "# User Options\n",
        "\n",
        "`User_n_mode = 64` is the number of eigenpairs to be output. `User_EED_ = True` determines whether External Explicit Deflation is to be used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "cellView": "form",
        "id": "MZad7i9nh9O1"
      },
      "outputs": [],
      "source": [
        "User_n_mode = 64 #@param [32, 64] {type:\"raw\"}\n",
        "User_EED = True #@param {type:\"boolean\"}\n",
        "User_AnimateMode = 10 #@param [5, 10, 15, 20] {type:\"raw\"}\n",
        "User_IntegerOfIndexing = \"INTEGER32\" # NOTE Indexing. For extremely large system with nnz > 2.1 billion use INTEGER64"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raeqczRtOes2"
      },
      "source": [
        "# Upload and Install\n",
        "\n",
        "Upload a pdb/cif file of your choice. Please name it with 4-alphanumerics followed by a suffix, either `.pdb` or `.cif`. For example, `5h2f.pdb`. Also, be reminded that\n",
        "\n",
        "* The default unit of 3-D coordinates in `.pdb` format is angstrom, but for `.cif` format, it is assumed nanometer. For simplicity, the uploaded file will always be renamed as `upload{suffix}`.\n",
        "* By default, we will remove the first 6 rigid modes with zero-eigenvalues by Hotelling deflation. However, if there are disconnected components separate from one another for more than 8 angstrom in the macromolecule (indeed, also when there are less than 3 linkages for an atom, think about the vector space!), there will be more than 6 rigid modes with zero-eigenvalues! See how to check it quickly in our Notebook `Inching-main/Notebook/Application/99_Inching_CheckConnectivity.ipynb`.\n",
        "\n",
        "# Remark\n",
        "`zip -P AAAAA10115 -r Inching-main.zip ./Inching-main/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "cellView": "form",
        "id": "e9w88evBMs59"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "uploaded = files.upload() #@markdown Upload a pdb/cif file of your choice.\n",
        "uploaded_filename = list(uploaded.keys())[0]\n",
        "print(uploaded_filename)\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "uploaded_suffix = uploaded_filename.split(\".\")[-1]\n",
        "shutil.move(uploaded_filename, \"upload.%s\" %(uploaded_suffix))\n",
        "\n",
        "\n",
        "\n",
        "# NOTE Then we install\n",
        "import condacolab\n",
        "from google.colab import files\n",
        "from IPython.display import clear_output\n",
        "condacolab.check()\n",
        "#!conda install -q -y -c conda-forge -c pytorch scipy=1.8.0 pytorch=1.11.0 pandas=1.5.3 openmm=7.7.0 tqdm cupy=11.5.0 python=3.10\n",
        "#!conda install -q -y -c conda-forge openmm=7.7.0 mdtraj=1.9.7 tqdm python=3.10 cudatoolkit=12.2\n",
        "!conda install -q -y -c conda-forge -c nvidia -c pytorch openmm=7.7.0 mdtraj=1.9.7 tqdm python=3.10 cudatoolkit=11.8.0\n",
        "on_colab = True\n",
        "clear_output()\n",
        "\n",
        "# NOTE Fast steps\n",
        "!wget https://zenodo.org/records/10443729/files/Inching-main.zip?download=1 -O /content/Inching-main.zip\n",
        "!unzip -P AAAAA10115 -o Inching-main.zip\n",
        "!cp -r Inching-main/InchingLiteInteger/ .\n",
        "!rm -r Result\n",
        "!mkdir Result\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKCkkUNYRtEZ"
      },
      "source": [
        "# Running the analysis\n",
        "\n",
        "The NVIDIA® T4 is a single-slot, low-profile GPU, but it can still stably deliver analysis for macromolecules containing ~300 thousand atoms in 20-30 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrG8IzIiRsKu",
        "outputId": "169bd8a9-c0f8-42c5-dc62-4cf1ceedef93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 116/116 [00:03<00:00, 32.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "N_neighbor within 8.0 angstrom Mean 132.0199317217835, Std 36.462781928942476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/115996 [00:09<?, ?it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "start eigsh cupy\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2048/2048 [00:00<00:00, 1103679.12it/s]\n",
            "100%|██████████| 2048/2048 [00:09<00:00, 220.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean number of Gaps > 100 is 15.75927734375. Mean Gap Length Given Gap is 615.6526413632843\n",
            "Max number of Gaps > 100 is 44. Max Gap Length Given Gap is 7130\n",
            "Median number of Gaps > 100 is 15.0. Median Gap Length Given Gap is 292.0\n",
            "Total Entry Savings 1125034098 which is 80.52278292526474 percent of a Rectangular Batch\n",
            "Nnz in Hessian (L+D) is 69434010.0. This will occupy 0.5134346187114716 GB for (L+D) data and at max 0.5134346187114716 GB for all indexings. Acceptable?\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/content/InchingLite/Fuel/T1.py:210: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  self.frontal_gap_offset[i] = torch.tensor(frontal_gap_offset,dtype=torch.int32, device='cpu')#.clone().detach().cpu().requires_grad_(False) #hare_memory_()\n",
            "100%|██████████| 2048/2048 [00:30<00:00, 67.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(69075102,)\n",
            "Start JDM Coarse Iter\n",
            "0, 17.418987008901595, 44.69880000060909, 1e-06, 0\n",
            "100, 0.001839094680705494, 1.0002436375595474, 1e-06, 0\n",
            "200, 6.691629027945932e-07, 1.0001254133911568, 1e-06, 0\n",
            "300, 1.5274894031730855e-10, 1.001895149053449, 1e-06, 3\n",
            "400, 5.233529116519236e-13, 1.0041791658721395, 1e-06, 7\n",
            "400, 0.0001843627714177775, 1.0046490893820748, 1e-06, 8\n",
            "500, 5.320346587061665e-07, 1.0101573233076244, 1e-06, 13\n",
            "600, 1.6298588758031338e-06, 1.0146865838641668, 1e-06, 18\n",
            "700, 2.8144324786676063e-05, 1.0186766531508378, 1e-06, 23\n",
            "800, 1.9015506917672442e-06, 1.0255443677962812, 1e-06, 28\n",
            "900, 3.896470308177579e-06, 1.030505820220462, 1e-06, 33\n",
            "1000, 7.413517265958896e-08, 1.0351674951919425, 1e-06, 38\n",
            "1100, 1.595967168449536e-07, 1.0399328519876458, 1e-06, 43\n",
            "1200, 1.3746445316138614e-07, 1.0434080854075025, 1e-06, 48\n",
            "1300, 1.9182752427541567e-10, 1.0492474130741947, 1e-06, 53\n",
            "1400, 4.4994635373334937e-13, 1.056464185226886, 1e-06, 58\n",
            "1400, 0.0038146562992306832, 1.0566762404880379, 1e-06, 59\n",
            "DONE. We went through 1493 coarse iter, 64 eigval converged\n",
            "RUNNNTIME 552.5923924446106\n",
            "1.0001254133889128 8.737861908340936e-13\n",
            "1.000208157898533 9.184267270972858e-13\n",
            "1.0010152677185962 6.00376181781498e-13\n",
            "1.0018951490534487 5.839137577992145e-13\n",
            "1.0026607794453548 8.223961456673368e-13\n",
            "1.003364637118865 7.040576960835128e-13\n",
            "1.004054195726416 9.81274122092299e-13\n",
            "1.0041791658721395 5.224747423030113e-13\n",
            "1.0046490874888119 5.168030887932094e-13\n",
            "1.0061155314413393 7.909009116358509e-13\n",
            "1.0074508755495628 7.115832679777769e-13\n",
            "1.009393235202628 7.745773925792848e-13\n",
            "1.0096187759526876 9.99407779144035e-13\n",
            "1.01015732330674 4.761598400841019e-13\n",
            "1.011258548224201 8.620451172201528e-13\n",
            "1.0123659354391343 5.388180674605476e-13\n",
            "1.0138171174510697 8.557395771665586e-13\n",
            "1.0145004415442138 7.47241518896728e-13\n",
            "1.0146865838580819 5.312673119700562e-13\n",
            "1.0155474457955191 8.805560441721282e-13\n",
            "1.0163463345267456 5.493819928655454e-13\n",
            "1.0177267877046852 8.024986135407952e-13\n",
            "1.018411282319828 5.409339016664713e-13\n",
            "1.0186766521815738 6.59403123322968e-13\n",
            "1.0194330022071287 4.695990487081563e-13\n",
            "1.020651573413601 4.105719718184836e-13\n",
            "1.021901743478353 5.567101615819425e-13\n",
            "1.0232067789896069 5.200476519732493e-13\n",
            "1.02554436778459 4.574509208957406e-13\n",
            "1.0257380557040106 3.984194350586269e-13\n",
            "1.027164279149658 6.116419215908916e-13\n",
            "1.0282818443870216 6.296744025740552e-13\n",
            "1.029676846504461 5.280707310665334e-13\n",
            "1.0305058201705162 4.586179054524036e-13\n",
            "1.0311566985785463 9.882963470311198e-13\n",
            "1.0317894849755926 7.868642862930066e-13\n",
            "1.0326630212902028 5.634136365790684e-13\n",
            "1.033711398854176 6.445585240996379e-13\n",
            "1.0351674951919345 5.819624683465581e-13\n",
            "1.036242362539067 5.518928870918036e-13\n",
            "1.0371541968804758 7.846115668204526e-13\n",
            "1.0375913243929296 6.060456650582738e-13\n",
            "1.0396080492067052 5.910198156720404e-13\n",
            "1.0399328519876287 6.17483756578383e-13\n",
            "1.0401763536788466 5.64041247375049e-13\n",
            "1.0413467263054559 7.252999778247647e-13\n",
            "1.0418250634737045 4.728194791738404e-13\n",
            "1.0418868361200213 4.087222357896513e-13\n",
            "1.043408085407441 6.746397006819241e-13\n",
            "1.0447996890209033 6.087260906276837e-13\n",
            "1.045608700580182 6.322583399331939e-13\n",
            "1.0468008070472423 7.311575829511637e-13\n",
            "1.0482595170280002 3.775221243086317e-13\n",
            "1.0492474130741947 7.479126094434294e-13\n",
            "1.0501678647594321 6.437711578825027e-13\n",
            "1.051508528069082 7.50296994335161e-13\n",
            "1.0532909655448555 4.324936892657325e-13\n",
            "1.0538319852343783 4.99163857203658e-13\n",
            "1.056464185226886 4.4931051055337616e-13\n",
            "1.0566758596895698 9.518691486951595e-13\n",
            "1.0579250820743071 7.806755118341486e-13\n",
            "1.05918559228154 5.94247055121311e-13\n",
            "1.060118504262638 8.338173226610357e-13\n",
            "1.060807991597772 7.935849119525898e-13\n"
          ]
        }
      ],
      "source": [
        "import glob #@markdown Click the play button\n",
        "import platform\n",
        "import cupy as cp\n",
        "import cupyx\n",
        "from cupyx.scipy import sparse as cupysparse\n",
        "# A list of pdb available at different sizes\n",
        "PART00_IO = True\n",
        "if PART00_IO:\n",
        "  pdbavail = [ \"./upload.%s\" %(uploaded_suffix)]\n",
        "  Benchmarking_folder = \"./Result/\"\n",
        "\n",
        "  User_Platform = platform.system() # Windows Darwin Linux\n",
        "\n",
        "  User_rc_Gamma = 8.0\n",
        "  User_maxleafsize = 100\n",
        "\n",
        "  User_tol = 1e-15\n",
        "  User_PlusI = 1.0\n",
        "\n",
        "  if uploaded_suffix == 'cif':\n",
        "    PDBCIF=\"Cif\"\n",
        "  else:\n",
        "    PDBCIF = \"Pdb\"\n",
        "  User_MaxIter = 15000\n",
        "\n",
        "  # JDM Params\n",
        "  User_GapEstimate = 0\n",
        "  User_SolverName = 'gmres'\n",
        "  User_SolverMaxIter = 20\n",
        "  User_EigTolerance = 1e-12\n",
        "\n",
        "PART00_Import = True\n",
        "if PART00_Import:\n",
        "   import os\n",
        "   import gc\n",
        "   import sys\n",
        "   import pickle\n",
        "\n",
        "   import numpy as np\n",
        "   import time\n",
        "   import tqdm\n",
        "\n",
        "   import torch\n",
        "\n",
        "\n",
        "   import platform\n",
        "\n",
        "\n",
        "   import time\n",
        "\n",
        "   import cupy\n",
        "   from cupy import cublas\n",
        "\n",
        "\n",
        "   from scipy.spatial import cKDTree\n",
        "\n",
        "\n",
        "\n",
        "   sys.path.append('.')\n",
        "   sys.path.append('./InchingLiteInteger/Burn/')\n",
        "\n",
        "\n",
        "\n",
        "   import InchingLiteInteger.util\n",
        "   import InchingLiteInteger.Fuel.Coordinate.T1\n",
        "   import InchingLiteInteger.Fuel.Coordinate.T2\n",
        "   import InchingLiteInteger.Burn.Coordinate.T1\n",
        "   import InchingLiteInteger.Burn.Coordinate.T3\n",
        "\n",
        "   from InchingLiteInteger.Fuel.T1 import Xnumpy_SparseCupyMatrixUngappped\n",
        "\n",
        "   import InchingLiteInteger.Burn.Visualisation.T1\n",
        "   import InchingLiteInteger.Burn.Visualisation.T2\n",
        "\n",
        "   # ============================\n",
        "   # Some torch speed up tips\n",
        "   # =============================\n",
        "\n",
        "   # Turn on cuda optimizer\n",
        "   torch.backends.cudnn.is_available()\n",
        "   torch.backends.cudnn.enabled = True\n",
        "   torch.backends.cudnn.benchmark = True\n",
        "   # disable debugs NOTE use only after debugging\n",
        "   torch.autograd.set_detect_anomaly(False)\n",
        "   torch.autograd.profiler.profile(False)\n",
        "   torch.autograd.profiler.emit_nvtx(False)\n",
        "   # Disable gradient tracking\n",
        "   torch.no_grad()\n",
        "   torch.inference_mode()\n",
        "   torch.manual_seed(0)\n",
        "   cupy.random.seed(seed = 0)\n",
        "   os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\" # NOTE In case any error showup\n",
        "   # Reset Cuda and Torch\n",
        "   device = torch.device(0)\n",
        "   torch.set_default_dtype(torch.float64)\n",
        "   torch.set_default_tensor_type(torch.cuda.DoubleTensor)\n",
        "   try:\n",
        "      InchingLiteInteger.util.TorchEmptyCache()\n",
        "   except RuntimeError:\n",
        "      print(\"The GPU is free to use. THere is no existing occupant\")\n",
        "   try:\n",
        "      print(torch.cuda.memory_summary(device = 0, abbreviated=True))\n",
        "   except KeyError:\n",
        "      print(\"The GPU is free to use. THere is no existing occupant\")\n",
        "\n",
        "\n",
        "\n",
        "pdbfn = pdbavail[0]\n",
        "devices_ = [d for d in range(torch.cuda.device_count())]\n",
        "device_names_  = [torch.cuda.get_device_name(d) for d in devices_]\n",
        "User_Device =  device_names_[0]\n",
        "\n",
        "\n",
        "pdbid = pdbfn.split(\"/\")[-1].split(\".\")[0]\n",
        "\n",
        "\n",
        "\n",
        "print(\"Reading structure...\")\n",
        "X_df, X_top = InchingLiteInteger.util.BasicPdbCifLoading(pdbfn)\n",
        "protein_xyz = X_df[['x','y','z']].to_numpy().astype(np.float64)\n",
        "# NOTE PDB format digit decimal do no destroy collinearity!\n",
        "protein_xyz -= np.around(protein_xyz.mean(axis= 0), decimals=4)\n",
        "n_atoms = protein_xyz.shape[0]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ===============================================\n",
        "# K-d Cuthill (NOTE CPU np array)\n",
        "# ===================================\n",
        "PART02_Cuthill = True\n",
        "if PART02_Cuthill:\n",
        "    # NOTE Cuthill Order and Undo\n",
        "    st = time.time()\n",
        "    cuthill_order, cuthill_undoorder = InchingLiteInteger.Fuel.Coordinate.T1.X_KdCuthillMckeeOrder(protein_xyz,\n",
        "                                rc_Gamma = User_rc_Gamma, Reverse = True,\n",
        "                                )\n",
        "    protein_xyz = protein_xyz[cuthill_order,:]\n",
        "    #protein_tree = cKDTree(protein_xyz, leafsize=16, compact_nodes=True, copy_data=False, balanced_tree=True, boxsize=None)\n",
        "\n",
        "\n",
        "    from InchingLiteInteger.Burn.JacobiDavidsonHotellingDeflation.T1 import S_HeigvalJDMHD_HeigvecJDMHD\n",
        "    print('start eigsh cupy')\n",
        "\n",
        "    mempool = cupy.get_default_memory_pool()\n",
        "    pinned_mempool = cupy.get_default_pinned_memory_pool()\n",
        "\n",
        "# ==================\n",
        "# Cupy hessian\n",
        "# =====================\n",
        "\n",
        "\n",
        "PART03a_MakeCupyHessian = True\n",
        "if PART03a_MakeCupyHessian:\n",
        "    # NOTE Nnz neighborhood after cuthill\n",
        "    NnzMinMaxDict, HalfNnz  = InchingLiteInteger.Fuel.Coordinate.T1.X_KdUngappedMinMaxNeighbor(protein_xyz, \n",
        "                                rc_Gamma = User_rc_Gamma, \n",
        "                                maxleafsize = User_maxleafsize,\n",
        "                                CollectStat = False,\n",
        "                                User_ReturnHalfNnz = True,\n",
        "                                SliceForm= True)\n",
        "\n",
        "\n",
        "    # NOTE Pyotch tensor spend textra memory when dlpack has to be called and there are mmeleak\n",
        "    #X = torch.tensor(protein_xyz, device=device, requires_grad= False)\n",
        "    X = protein_xyz\n",
        "\n",
        "    Xnumpy_SparseCupyMatrixUngapppedC = Xnumpy_SparseCupyMatrixUngappped(X, batch_head = None,\n",
        "        maxleafsize = User_maxleafsize, rc_Gamma = User_rc_Gamma,\n",
        "        #device  = torch.device(0),\n",
        "        User_PlusI = User_PlusI,\n",
        "        #dtype_temp = torch.float64,\n",
        "        #X_precision = torch.cuda.DoubleTensor,\n",
        "        User_DictCharmmGuiPbc = None, #Dict_Pbc,\n",
        "        NnzMinMaxDict = NnzMinMaxDict)\n",
        "    if User_IntegerOfIndexing == \"INTEGER32\":\n",
        "        A, A_diag = Xnumpy_SparseCupyMatrixUngapppedC.ReturnCupyHLowerTriangleInt32(\n",
        "                        User_MaxHalfNnzBufferSize = HalfNnz)\n",
        "    else:\n",
        "        #print('gagag')\n",
        "        A, A_diag = Xnumpy_SparseCupyMatrixUngapppedC.ReturnCupyHLowerTriangleInt64(\n",
        "                        User_MaxHalfNnzBufferSize = HalfNnz)\n",
        "\n",
        "    print(\"Matrix Index Datatype\", A.indices.dtype)\n",
        "    print(\"Matrix Datatype\",A.data.shape)\n",
        "    \n",
        "    cupy.get_default_memory_pool().free_all_blocks()\n",
        "    cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "PART03b_MakeFreeModes = User_EED\n",
        "if PART03b_MakeFreeModes:\n",
        "\n",
        "    Q_HotellingDeflation = cp.zeros((6,3*n_atoms), dtype = cp.float64)\n",
        "    # NOTE Translation\n",
        "    for i in range(3):\n",
        "        q1 = cp.zeros((n_atoms,3))\n",
        "        q1[:,i] = 1/np.sqrt(n_atoms)\n",
        "        Q_HotellingDeflation[i,:] = q1.flatten()\n",
        "        q1 = None\n",
        "        del q1\n",
        "        cupy.get_default_memory_pool().free_all_blocks()\n",
        "        cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
        "\n",
        "\n",
        "\n",
        "    # NOTE Rotation\n",
        "    R_x = cp.array([        [0,0,0],\n",
        "                            [0,0,-1],\n",
        "                            [0,1,0]], dtype=cp.float64).T\n",
        "    R_y = cp.array([        [0,0,1],\n",
        "                            [0,0,0],\n",
        "                            [-1,0,0]], dtype=cp.float64).T\n",
        "    R_z = cp.array([        [0,-1,0],\n",
        "                            [1,0,0],\n",
        "                            [0,0,0]], dtype=cp.float64).T\n",
        "    R_x = cupysparse.csr_matrix(R_x, dtype= cp.float64)\n",
        "    R_y = cupysparse.csr_matrix(R_y, dtype= cp.float64)\n",
        "    R_z = cupysparse.csr_matrix(R_z, dtype= cp.float64)\n",
        "    gx = (cp.array(X)@R_x).flatten()\n",
        "    Q_HotellingDeflation[3,:] = gx/ cp.linalg.norm(gx,ord=2)\n",
        "    gy = (cp.array(X)@R_y).flatten()\n",
        "    Q_HotellingDeflation[4,:] = gy/ cp.linalg.norm(gy,ord=2)\n",
        "    gz = (cp.array(X)@R_z).flatten()\n",
        "    Q_HotellingDeflation[5,:] = gz/ cp.linalg.norm(gz,ord=2)\n",
        "\n",
        "\n",
        "\n",
        "    for i_FRO in range(2):\n",
        "        V = Q_HotellingDeflation.T\n",
        "\n",
        "        for ix in range(6):\n",
        "            if ix == 0:\n",
        "                continue\n",
        "            V[:,ix] -= cp.matmul(V[:,:ix], cp.matmul( V[:, :ix].T,V[:,ix] ))\n",
        "            V[:,ix] /= cp.sqrt(V[:, ix].T @ V[:, ix]) # TODO torch.matmul or mvs\n",
        "            V[:,ix] -= cp.matmul(V[:,:ix], cp.matmul( V[:, :ix].T,V[:,ix] ))\n",
        "            V[:,ix] /= cp.sqrt(V[:, ix].T @ V[:, ix])\n",
        "        Q_HotellingDeflation = V.T\n",
        "\n",
        "    gx = Q_HotellingDeflation[3]\n",
        "\n",
        "\n",
        "    Q_HotellingDeflation = cupyx.scipy.sparse.csr_matrix(Q_HotellingDeflation, dtype = cp.float64)\n",
        "\n",
        "    gx, gy, gz = None, None, None\n",
        "    del gx, gy, gz\n",
        "    cupy.get_default_memory_pool().free_all_blocks()\n",
        "    cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "PART04_CalcualteEig = True\n",
        "if PART04_CalcualteEig:\n",
        "    if User_EED:\n",
        "\n",
        "        User_GapEstimate = 0 # NOTE Not in use.\n",
        "        eigval, eigvec = S_HeigvalJDMHD_HeigvecJDMHD(A, A_diag,\n",
        "                    k = User_n_mode,\n",
        "                    tol = User_EigTolerance,\n",
        "                    maxiter = User_MaxIter,\n",
        "                    User_CorrectionSolverMaxiter = User_SolverMaxIter,\n",
        "                    User_HalfMemMode= True,\n",
        "                    User_IntermediateConvergenceTol=1e-3, # NOTE Do not touch for this problem\n",
        "                    User_GapEstimate = User_GapEstimate, # NOTE This will be used for theta - gap_estimate\n",
        "                    User_FactoringToleranceOnCorrection = 1e-4, # NOTE Do not touch for this problem\n",
        "                    User_Q_HotellingDeflation= Q_HotellingDeflation,\n",
        "                    User_HotellingShift = 40, # NOTE 40 is generally safe for first 64 modes, of course if you want to guarentee it you know a norm\n",
        "\n",
        "                    )\n",
        "    else:\n",
        "\n",
        "        User_GapEstimate = 0 # NOTE Not in use.\n",
        "        eigval, eigvec = S_HeigvalJDMHD_HeigvecJDMHD(A, A_diag,\n",
        "                    k = User_n_mode,\n",
        "                    tol = User_EigTolerance,\n",
        "                    maxiter = User_MaxIter,\n",
        "                    User_CorrectionSolverMaxiter = User_SolverMaxIter,\n",
        "                    User_HalfMemMode= True,\n",
        "                    User_IntermediateConvergenceTol=1e-3, # NOTE Do not touch for this problem\n",
        "                    User_GapEstimate = User_GapEstimate, # NOTE This will be used for theta - gap_estimate\n",
        "                    User_FactoringToleranceOnCorrection = 1e-4, # NOTE Do not touch for this problem\n",
        "                    User_Q_HotellingDeflation= None,\n",
        "                    User_HotellingShift = 40, # NOTE 40 is generally safe for first 64 modes, of course if you want to guarentee it you know a norm\n",
        "\n",
        "                    )\n",
        "\n",
        "\n",
        "\n",
        "    runtime = time.time() - st\n",
        "    print(\"RUNNNTIME %s\" %(runtime))\n",
        "    peak_mem = cupy.get_default_memory_pool().used_bytes() / 1024 / 1024\n",
        "\n",
        "\n",
        "    runtime = time.time() - st\n",
        "    peak_mem = cupy.get_default_memory_pool().used_bytes() / 1024 / 1024\n",
        "    with open(\"%s/Eigval_InchingJDM_%s_%s_%s.pkl\" %(\n",
        "                Benchmarking_folder, pdbid, User_Platform,\n",
        "                User_Device.replace(\" \",\"\")),\"wb\") as fn:\n",
        "        pickle.dump(cupy.asnumpy(eigval) - User_PlusI ,fn, protocol=4)\n",
        "\n",
        "    with open(\"%s/Eigvec_InchingJDM_%s_%s_%s.pkl\" %(\n",
        "                Benchmarking_folder, pdbid, User_Platform,\n",
        "                User_Device.replace(\" \",\"\")),\"wb\") as fn:\n",
        "        tempeigvec = cupy.asnumpy(eigvec)\n",
        "        tempeigvec = tempeigvec.T\n",
        "        tempeigvec = tempeigvec.reshape((int(User_n_mode),int(n_atoms),int(3)))\n",
        "        pickle.dump(tempeigvec[:,cuthill_undoorder,:] ,fn, protocol=4)\n",
        "\n",
        "\n",
        "\n",
        "    gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "PART05_Performance = True\n",
        "if PART05_Performance:\n",
        "    #===================================\n",
        "    # Check correct\n",
        "    # =====================================\n",
        "    #print(eigval)\n",
        "    #print(eigvec.shape)\n",
        "\n",
        "    User_HalfMemMode = True\n",
        "    if User_HalfMemMode:\n",
        "        KrylovAv = InchingLiteInteger.Burn.Krylov.T3.OOC2_HalfMemS_v_KrylovAv_VOID(A, A_diag)\n",
        "    else:\n",
        "        KrylovAv = InchingLiteInteger.Burn.Krylov.T3.OOC2_FullMemS_v_KrylovAv_VOID(A, A_diag)\n",
        "    Av = cupy.empty((n_atoms*3,)).astype(A.dtype)\n",
        "\n",
        "\n",
        "    delta_lambda_list = []\n",
        "    for jj in range(User_n_mode):\n",
        "        KrylovAv(A,cupy.ravel(eigvec[:,jj]),Av)\n",
        "        B = Av - eigval[jj]* cupy.ravel(eigvec[:,jj])\n",
        "\n",
        "        delta_lambda_list.append(cupy.asnumpy(cublas.nrm2(B)))\n",
        "        #if jj < 20:\n",
        "        print(eigval[jj], cupy.asnumpy(cublas.nrm2(B)))\n",
        "\n",
        "\n",
        "    eigval = cupy.asnumpy(eigval)\n",
        "    n_atoms = protein_xyz.shape[0]\n",
        "\n",
        "    GPU = \"%s %s\" %(User_Platform, User_Device.replace(\" GPU\", \"\"))\n",
        "\n",
        "    performance = [\"Inching (JDM %s)\" %(GPU), pdbfn, n_atoms,\n",
        "                    runtime, peak_mem,\n",
        "                    User_Platform, User_Device,\n",
        "                    User_maxleafsize]\n",
        "\n",
        "\n",
        "\n",
        "    longperformance = []\n",
        "    for i in range(len(delta_lambda_list)):\n",
        "        longperformance.append(performance + [i ,delta_lambda_list[i], eigval[i] - User_PlusI])\n",
        "\n",
        "    with open(\"%s/PerformanceList_InchingJDM_%s_%s_%s.pkl\" %(Benchmarking_folder,\n",
        "        pdbid, User_Platform, User_Device.replace(\" \",\"\")),\"wb\") as fn:\n",
        "        pickle.dump(longperformance,fn, protocol=4)\n",
        "\n",
        "\n",
        "    #del X_df#, protein_xyz\n",
        "    #gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "    B = None\n",
        "    A.data = None\n",
        "    A.indices = None\n",
        "    A.indptr = None\n",
        "    Q_HotellingDeflation = None\n",
        "    del Q_HotellingDeflation\n",
        "\n",
        "    del A.data, A.indices, A.indptr\n",
        "    del A, B\n",
        "    Xnumpy_SparseCupyMatrixUngapppedC.X, Xnumpy_SparseCupyMatrixUngapppedC.X_unsqueezed = None, None\n",
        "    del Xnumpy_SparseCupyMatrixUngapppedC.X, Xnumpy_SparseCupyMatrixUngapppedC.X_unsqueezed\n",
        "    Xnumpy_SparseCupyMatrixUngapppedC = None\n",
        "    del Xnumpy_SparseCupyMatrixUngapppedC\n",
        "    eigvec, eigval = None, None\n",
        "    del eigvec, eigval\n",
        "\n",
        "\n",
        "    cupy.get_default_memory_pool().free_all_blocks()\n",
        "    cupy.get_default_pinned_memory_pool().free_all_blocks()\n",
        "    del X\n",
        "    torch.cuda.empty_cache()\n",
        "    torch.cuda.reset_peak_memory_stats(0)\n",
        "    torch.cuda.memory_allocated(0)\n",
        "    torch.cuda.max_memory_allocated(0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOYGTv8-Dycs"
      },
      "source": [
        "## Generate Animation and Download\n",
        "\n",
        "This writes the linearized motion as a `cif` file for each mode. Unfortunately, the I/O can often take much longer than the calculation itself. After downloading the `InchingResult.zip`, decompress it, open the cif file in pymol and load the corresponding `.pml` script. Enjoy!\n",
        "\n",
        "* By default, the `save_to_google_drive` check box is activated; it will ask for your permission to upload the result to your google drive. If `save_to_google_drive` check box is deactivated, you can directly download the file, but it can take very long.\n",
        "* To indicate the mode shape, for each mode, a black arrow is placed on 10000 randomly chosen atoms with top 50% of diplacement magnitude. Thickness of the arrow can be tuned by checking `User_ThickerArrowForDisplay`. It is suggested to use thicker arrows for structures with >100 thousand atoms."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "id": "8Nq_DUjXBrtm",
        "outputId": "2574387c-b2b0-4581-d726-90ffb3016f52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Printing animations...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7/7 [00:00<00:00, 72.38it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 72.06it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 50.60it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 79.36it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 71.97it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 47.51it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 53.89it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 77.71it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 65.84it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 38.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compressing as zip...\n",
            "File size: 340.32586002349854 MB\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Preparing Google link address...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<a href=https://drive.google.com/file/d/1-exGYAVn2VY3leus35RBoxjbbOkVhYiW target=_blank>Click HERE to download the InchingResult.zip file from your drive. Enjoy!</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "save_to_google_drive = True #@param {type:\"boolean\"}\n",
        "User_ThickerArrowForDisplay = False #@param {type:\"boolean\"}\n",
        "# =======================\n",
        "# Linearize\n",
        "# ==========================\n",
        "pdbfn = pdbavail[0]#@markdown The zip file will be downloaded as `InchingResult_{time}.zip`. Size is printed below\n",
        "\n",
        "User_QuantileDisplay = 0.5\n",
        "User_RandomPickArrows = 10000\n",
        "User_EigenvectorTwinDirection = 1\n",
        "\n",
        "User_BigClusterArrowFloatingFactor = 0.5\n",
        "User_DBscanMinDist = 1.5 # NOTE THis roughly cluster the 90% percentile arrows. largerr the less arrows\n",
        "\n",
        "print(\"Printing animations...\")\n",
        "import sklearn.cluster\n",
        "from InchingLiteInteger.Fuel.Coordinate.T1 import HeigvecOne_BoxCoxMagnitude\n",
        "protein_xyz_ = protein_xyz\n",
        "PART06_Animate = True\n",
        "if PART06_Animate:\n",
        "    eigvec = tempeigvec[:,cuthill_undoorder,:]\n",
        "    protein_xyz = protein_xyz[cuthill_undoorder,:]\n",
        "    if User_EED:\n",
        "      pass\n",
        "    else:\n",
        "      User_AnimateMode +=6\n",
        "\n",
        "    i_mode = 0\n",
        "    for User_TheModeToShow in range(User_AnimateMode):\n",
        "\n",
        "        if User_EED:\n",
        "          pass\n",
        "        else:\n",
        "          if User_TheModeToShow <=5:\n",
        "              continue\n",
        "\n",
        "        if pdbfn.split(\".\")[-1] == 'pdb':\n",
        "            nmfactor = 0.1\n",
        "        else:\n",
        "            nmfactor = 1\n",
        "\n",
        "        gc.collect()\n",
        "\n",
        "        PART06b_Logistic = True\n",
        "        if PART06b_Logistic:\n",
        "\n",
        "            #if os.path.exists(\"%s/%s_Animated_%s_%s.cif\" %(Benchmarking_folder, pdbid, pdbid, i_mode)):\n",
        "            #    continue\n",
        "\n",
        "            # NOTE Kerneled eigvec\n",
        "            deltaX_magnitude = HeigvecOne_BoxCoxMagnitude( eigvec[User_TheModeToShow,:,:],\n",
        "                    User_WinsorizingWindow = (0.025, 0.975),\n",
        "                    User_LogisticParam = (0.05, 1.0),\n",
        "                    )\n",
        "\n",
        "            deltaX_magnitude = np.clip(deltaX_magnitude, 0.1, 1.0)\n",
        "            eigvec_unit = eigvec[User_TheModeToShow] / np.linalg.norm(eigvec[User_TheModeToShow], axis=1)[:,None]\n",
        "            deltaX = deltaX_magnitude[:,None] * eigvec_unit\n",
        "\n",
        "\n",
        "            InchingLiteInteger.util.SaveOneModeLinearisedAnime(\n",
        "                    deltaX,\n",
        "                    protein_xyz*nmfactor,\n",
        "                    n_timestep = 16,\n",
        "                    DIR_ReferenceStructure = pdbfn,#[:-4] + \"trial.cif\",\n",
        "                    DIR_SaveFolder = Benchmarking_folder,\n",
        "                    SaveFormat = 'cif',\n",
        "                    outputlabel = 'Animated_%s_%s'%(pdbid, i_mode),\n",
        "                    max_abs_deviation = 3.0*nmfactor,\n",
        "                    stepsize = 1.0*nmfactor,\n",
        "                    UnitMovement = False,\n",
        "                    max_n_output = 32,\n",
        "                    SaveSeparate = False,\n",
        "                    RemoveOrig = False, # NOTE This flag remove the unmoved structure from the trajectory produce\n",
        "                    User_Bfactor=deltaX_magnitude\n",
        "                    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        PART06c_Arrows = True\n",
        "        if PART06c_Arrows:\n",
        "          PART02_DecideWhatArrowsToPlot = True\n",
        "          if PART02_DecideWhatArrowsToPlot:\n",
        "              where_CaOrP = X_df.loc[X_df['name'].isin([\"CA\", \"P\"]) & ~X_df['element'].isin([\"Ca\"])].index.values\n",
        "              where_larger = np.where((deltaX_magnitude > np.quantile(deltaX_magnitude, q = User_QuantileDisplay)))[0]\n",
        "              # a ball with large displacement TODO Show the stacked detail\n",
        "              where_larger_CaOrP = np.intersect1d(where_larger, where_CaOrP, assume_unique=False, return_indices=False)\n",
        "              where_random = np.random.choice(where_larger_CaOrP,\n",
        "                                                  size= min(User_RandomPickArrows, where_larger_CaOrP.shape[0]), replace = False)\n",
        "\n",
        "              # TODO Make  a big arrow for those large ones only! Cluster the coordinate by dbscan.\n",
        "              #      average the arrow put it in center and floating in air.\n",
        "              #      Make the arrow obvious enough to indicate the direction.\n",
        "              where_CaOrP_subset = where_CaOrP[::max(1, int(protein_xyz.shape[0]/User_RandomPickArrows))]\n",
        "\n",
        "\n",
        "              # ======================\n",
        "              # Big Arrow\n",
        "              # =========================\n",
        "\n",
        "              clustering = sklearn.cluster.DBSCAN(eps=User_DBscanMinDist, min_samples=10, metric='euclidean',\n",
        "                                                  metric_params=None, algorithm='kd_tree',\n",
        "                                                  leaf_size=100, p=2, n_jobs=1).fit(protein_xyz[where_larger_CaOrP,:])\n",
        "              unique_clusters = np.unique(clustering.labels_)\n",
        "              DBSCAN_Coord = np.zeros((unique_clusters.shape[0],3))\n",
        "              DBSCAN_UnitEigvec = np.zeros((unique_clusters.shape[0],3))\n",
        "              DBSCAN_UnitEigvecmag = np.zeros((unique_clusters.shape[0],1))\n",
        "              for i_cluster in unique_clusters:\n",
        "                  if i_cluster == -1:\n",
        "                      continue\n",
        "                  same_cluster = where_larger_CaOrP[np.where(clustering.labels_ == i_cluster)[0]]\n",
        "                  DBSCAN_Coord[i_cluster,:] = np.mean(protein_xyz[same_cluster,:], axis=0)\n",
        "                  DBSCAN_UnitEigvec[i_cluster,:] = np.mean(eigvec_unit[same_cluster,:], axis=0)\n",
        "                  DBSCAN_UnitEigvecmag[i_cluster,:] = np.mean(deltaX_magnitude[same_cluster])\n",
        "\n",
        "          #print(\"dbscan done\")\n",
        "          # ========================\n",
        "          # Print arrwo\n",
        "          # ==========================\n",
        "          PART03_PrintCgoArrows = True\n",
        "          if PART03_PrintCgoArrows:\n",
        "              # NOTE Pymol...\n",
        "              if pdbfn.split(\".\")[-1] == 'pdb':\n",
        "                  nmfactor_ = 10.0\n",
        "              else:\n",
        "                  nmfactor_ = 10.0\n",
        "\n",
        "\n",
        "              #print(deltaX_magnitude)\n",
        "              percentilescore_all =  np.argsort(np.argsort(deltaX_magnitude, axis=0), axis=0) / float(len(deltaX_magnitude)) # NOTE Assumed that each has a unique float\n",
        "              print_cgoarrows = []\n",
        "\n",
        "              # =================================\n",
        "              # NOTE THe Big Clustered Arrow\n",
        "              # ==================================\n",
        "              \"\"\"\n",
        "              for i_cluster in range(unique_clusters.shape[0]):\n",
        "\n",
        "                  # NOTE Point to point\n",
        "                  position_source = DBSCAN_Coord[i_cluster] * nmfactor_\n",
        "                  direction_size = 99 * DBSCAN_UnitEigvecmag[i_cluster]\n",
        "                  direction_= (User_EigenvectorTwinDirection * DBSCAN_UnitEigvec[i_cluster] *direction_size) #* deltaX_magnitude[atomindex_]*50)\n",
        "                  gap = direction_* User_BigClusterArrowFloatingFactor\n",
        "\n",
        "                  position_source += gap\n",
        "                  #position_source += direction_*User_BigClusterArrowFloatingFactor\n",
        "                  position_target = position_source + direction_\n",
        "\n",
        "                  x_s, y_s, z_s = position_source[0], position_source[1], position_source[2]\n",
        "                  x_t, y_t, z_t = position_target[0], position_target[1], position_target[2]\n",
        "                  thickness_ = 5 # percentilescore_all[atomindex_]\n",
        "                  print_cgoarrows.append(\"cgo_arrow [%.3f, %.3f, %.3f], [%.3f, %.3f, %.3f] \" %(\n",
        "                      x_s, y_s, z_s, x_t, y_t, z_t) + ', name = \\\"' + \"ClusterArrow%s\" %(i_cluster+1)+'\\\",' + \" radius = %s, hradius = %s, hlength = %s, \" %(thickness_, thickness_*2, direction_size[0]/2 ) + ' color = hotpink')\n",
        "                      # hotpink black\n",
        "              \"\"\"\n",
        "              # ===========================\n",
        "              # NOTE every n CA\n",
        "              # ==============================\n",
        "              choice_where =  where_random # where_CaOrP_subset\n",
        "              for i_whererand in range(len(choice_where)):\n",
        "                  atomindex_ = choice_where[i_whererand]\n",
        "                  # NOTE Point to point\n",
        "                  position_source = protein_xyz[atomindex_]*nmfactor_\n",
        "                  direction_= (eigvec_unit[atomindex_] * User_EigenvectorTwinDirection *25 * deltaX_magnitude[atomindex_]) #* deltaX_magnitude[atomindex_]*50)\n",
        "                  position_target = position_source + direction_\n",
        "\n",
        "                  x_s, y_s, z_s = position_source[0], position_source[1], position_source[2]\n",
        "                  x_t, y_t, z_t = position_target[0], position_target[1], position_target[2]\n",
        "                  if User_ThickerArrowForDisplay:\n",
        "                    thickness_ = 0.5\n",
        "                  else:\n",
        "                    thickness_ = 0.1 # percentilescore_all[atomindex_]\n",
        "                  print_cgoarrows.append(\"cgo_arrow [%.3f, %.3f, %.3f], [%.3f, %.3f, %.3f] \" %(\n",
        "                      x_s, y_s, z_s, x_t, y_t, z_t) + ', name = \\\"' + \"Index%s\" %(atomindex_+1)+'\\\",' + \" radius = %s, hradius = %s, hlength = 10.23, \" %(thickness_*1, thickness_ * 4) + ' color = black')\n",
        "                      # hotpink black\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "          with open('./Inching-main/Notebook/Application/ArrowTemplate.pml', 'r') as f :\n",
        "                  filedata = f.read()\n",
        "\n",
        "          filedata = filedata.replace('REPLACE_WITH_FILENAME', \"%s/%s_Animated_%s_%s.cif\" %(\"./\", pdbid, pdbid, i_mode))\n",
        "          filedata = filedata.replace('REPLACE_WITH_ID', '%s' %(pdbid))\n",
        "          filedata = filedata.replace('REPLACE_WITH_CGOARROWS', \"\\n\".join(print_cgoarrows))\n",
        "          #print(filedata)\n",
        "          with open('%s/PymolSession_%s_%s.pml'%(Benchmarking_folder, pdbid, i_mode), 'w+') as f:\n",
        "                  f.write(filedata)\n",
        "          shutil.copy(\"./Inching-main/Notebook/Application/cgo_arrow.py\", \"%s/cgo_arrow.py\" %(Benchmarking_folder))\n",
        "          i_mode+=1\n",
        "\n",
        "\n",
        "protein_xyz = protein_xyz_\n",
        "\n",
        "# --- Download the predictions ---\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "\n",
        "import os\n",
        "timestamp = str(time.time()).split(\".\")[0]\n",
        "print('Compressing as zip...')\n",
        "os.system(f\"zip -q -r /content/InchingResult_%s.zip /content/Result/\" %(timestamp))\n",
        "print(\"File size: %s MB\" %(os.path.getsize(\"/content/InchingResult_%s.zip\"%(timestamp))/1024/1024))\n",
        "\n",
        "\n",
        "if save_to_google_drive:\n",
        "\n",
        "  from pydrive.drive import GoogleDrive\n",
        "  from pydrive.auth import GoogleAuth\n",
        "  from google.colab import auth\n",
        "  from oauth2client.client import GoogleCredentials\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  #print(\"You are logged into Google Drive and are good to go!\")\n",
        "\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  import shutil\n",
        "\n",
        "  shutil.copy2(\"InchingResult_%s.zip\" %(timestamp),\"/content/gdrive/MyDrive/InchingResult_%s.zip\"%(timestamp))\n",
        "\n",
        "  from subprocess import getoutput\n",
        "  from IPython.display import HTML, display\n",
        "  !apt-get install xattr > /dev/null\n",
        "\n",
        "  #!xattr -p 'user.drive.id' '/content/gdrive/MyDrive/'\n",
        "  # NOTE There can be a time lag to upload to gdrive? We need to listen for finish...\n",
        "\n",
        "\n",
        "  def get_shareable_link(file_path, return_URL = False):\n",
        "    fid = getoutput(\"xattr -p 'user.drive.id' \" + \"'\" + file_path + \"'\")\n",
        "    #print(fid, file_path)\n",
        "    if return_URL:\n",
        "      return HTML(f\"<a href=https://drive.google.com/file/d/{fid} target=_blank>Click HERE to download the InchingResult.zip file from your drive. Enjoy!</a>\")\n",
        "    else:\n",
        "      return fid\n",
        "\n",
        "  print(\"Preparing Google link address...\")\n",
        "  shareable_link = get_shareable_link(\"/content/gdrive/MyDrive/InchingResult_%s.zip\" %(timestamp))\n",
        "  while \"local-\" in shareable_link:\n",
        "    time.sleep(2)\n",
        "    shareable_link = get_shareable_link(\"/content/gdrive/MyDrive/InchingResult_%s.zip\" %(timestamp))\n",
        "    time.sleep(2)\n",
        "  display(get_shareable_link(\"/content/gdrive/MyDrive/InchingResult_%s.zip\" %(timestamp), return_URL = True))\n",
        "  #print(\"/content/gdrive/MyDrive/InchingResult_%s.zip\" %(timestamp))\n",
        "\n",
        "else:\n",
        "  files.download(\"/content/InchingResult_%s.zip\" %(timestamp))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M15Xq0bE8G4e"
      },
      "source": [
        "# Download the source code\n",
        "\n",
        "We will be offering Inching and its associated eigensolvers as an open-source software once the publication is solid. Meanwhile, reviewers can download the zipped source code with a password `AAAAA10115`, but please do not distribute it before publication. Cite us if you find anything useful or inspirational!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "8T6PdaO_8HBE",
        "outputId": "ebdbc08a-ae19-4267-deb5-12832716af57"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_7604592a-8352-46be-bfea-5edfabf1d5ab\", \"Inching-main.zip\", 7129333)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "files.download(f'/content/Inching-main.zip')#@markdown Click play button to Download. Remember the password `AAAAA10115`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G47DnqTOsNqF"
      },
      "source": [
        "## FAQ & Troubleshooting\n",
        "\n",
        "\n",
        "\n",
        "*   How long will this take?\n",
        "    *   Downloading the Inching source code can take up to a few minutes.\n",
        "    *   Downloading and installing through Conda can take up to a few minutes.\n",
        "    *   Calculation of modes can take minutes to hours, depending on the length of your protein and on which GPU-type Colab has assigned you.\n",
        "*   My Colab no longer seems to be doing anything, what should I do?\n",
        "    *   Some steps may take minutes to hours to complete.\n",
        "    *   If nothing happens or if you receive an error message, try restarting your Colab runtime via _Runtime_ > _Restart runtime_.\n",
        "    *   If this doesn’t help, try resetting your Colab runtime via _Runtime_ > _Factory reset runtime_.\n",
        "*   How does this compare to a desktop version of Inching?\n",
        "    *   The eigenpair should be within error bound as long as conda did its version control.\n",
        "*   What is a Colab?\n",
        "    *   See the [Colab FAQ](https://research.google.com/colaboratory/faq.html).\n",
        "*   I received a warning “Notebook requires high RAM”, what do I do?\n",
        "    *   The resources allocated to your Colab vary. See the [Colab FAQ](https://research.google.com/colaboratory/faq.html) for more details.\n",
        "    *   You can execute the Colab nonetheless.\n",
        "*   I received an error “Colab CPU runtime not supported” or “No GPU/TPU found”, what do I do?\n",
        "    *   Colab CPU runtime is not supported. Try changing your runtime via _Runtime_ > _Change runtime type_ > _Hardware accelerator_ > _GPU_.\n",
        "    *   The type of GPU allocated to your Colab varies. See the [Colab FAQ](https://research.google.com/colaboratory/faq.html) for more details.\n",
        "    *   If you receive “Cannot connect to GPU backend”, you can try again later to see if Colab allocates you a GPU.\n",
        "    *   [Colab Pro](https://colab.research.google.com/signup) offers priority access to GPUs.\n",
        "*   I received an error “ModuleNotFoundError: No module named ...”, even though I ran the cell that imports it, what do I do?\n",
        "    *   Colab notebooks on the free tier time out after a certain amount of time. See the [Colab FAQ](https://research.google.com/colaboratory/faq.html#idle-timeouts). Try rerunning the whole notebook from the beginning.\n",
        "*   Does this tool install anything on my computer?\n",
        "    *   No, everything happens in the cloud on Google Colab.\n",
        "    *   At the end of the Colab execution a zip-archive with the obtained prediction will be automatically downloaded to your computer.\n",
        "*   How should I share feedback and bug reports?\n",
        "    *   Please share any feedback and bug reports as an [issue](https://github.com/jhmlam/Inching/issues) on Github.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
